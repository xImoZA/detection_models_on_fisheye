{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Скачиваем набор данных WoodScape**"
   ],
   "metadata": {
    "id": "Dad5Fy4ahvOF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir WoodScape\n",
    "!pip install gdown"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YAYzN80zx9yC",
    "outputId": "8ffa88b6-c8e4-4d9f-a0ee-25d8daa20dbc"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import gdown\n",
    "\n",
    "file_id = \"1xQ5J4huNmyK9WPoipHTnuZ7lw_J0xhvL\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"rgb_images.zip\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "fvmF9hcHwg5M",
    "outputId": "ebb287c6-a3f9-491e-9845-0cd663bd24e4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1xQ5J4huNmyK9WPoipHTnuZ7lw_J0xhvL\n",
      "From (redirected): https://drive.google.com/uc?id=1xQ5J4huNmyK9WPoipHTnuZ7lw_J0xhvL&confirm=t&uuid=8ba96eb9-3cfa-44b5-b4ef-c544bb363199\n",
      "To: /content/rgb_images.zip\n",
      "100%|██████████| 15.2G/15.2G [04:00<00:00, 63.2MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'rgb_images.zip'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "eDrU3TlnRb7-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "archive_path = \"/content/rgb_images.zip\"\n",
    "output_dir = \"/content/WoodScape/\"\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(archive_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_dir)"
   ],
   "metadata": {
    "id": "hXLYWSIGyue4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/content/WoodScape/rgb_images\"\n",
    "output_file = \"/content/WoodScape/images_list.txt\"\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "files = [f for f in files if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for file_name in files:\n",
    "        f.write(\"/content/WoodScape/rgb_images/\" + file_name + \"\\n\")"
   ],
   "metadata": {
    "id": "ikEgU3bTBcVR"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Скачиваем калибровки изображений**"
   ],
   "metadata": {
    "id": "hEQaJuZHh5CB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import gdown\n",
    "\n",
    "file_id = \"1o7KBl1QzTkugMDOadvJFSbN87njuajYc\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "output = \"calibration.zip\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "SUPt-mwniFAl",
    "outputId": "5d2a3855-0557-4660-8b52-2bfa761f4e60"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1o7KBl1QzTkugMDOadvJFSbN87njuajYc\n",
      "To: /content/calibration.zip\n",
      "100%|██████████| 3.33M/3.33M [00:00<00:00, 24.0MB/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'calibration.zip'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "archive_path = \"/content/calibration.zip\"\n",
    "output_dir = \"/content/WoodScape/\"\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(archive_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(output_dir)"
   ],
   "metadata": {
    "id": "QKcupN6Zi2Nx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Загружаем YOLOv4**"
   ],
   "metadata": {
    "id": "v3d6tU3PiM1s"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "68eMertgIxaB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c1827c89-69a6-4ff8-b95b-2d1bbd3ba511"
   },
   "source": [
    "!git clone https://github.com/AlexeyAB/darknet"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'darknet'...\n",
      "remote: Enumerating objects: 15873, done.\u001b[K\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "remote: Total 15873 (delta 12), reused 7 (delta 7), pack-reused 15850 (from 3)\u001b[K\n",
      "Receiving objects: 100% (15873/15873), 14.50 MiB | 14.44 MiB/s, done.\n",
      "Resolving deltas: 100% (10679/10679), done.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xym8_m8CIyXK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7105afc1-a87b-4190-84df-acaf896b42d1"
   },
   "source": [
    "%cd darknet\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/darknet\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5uloUwmUKF05",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "186e9be0-a384-4eac-c1d6-0512673a168f"
   },
   "source": [
    "!/usr/local/cuda/bin/nvcc --version"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q2Jjv0yRKLPe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "69375b00-699b-46b6-df8e-5c232cab2fac"
   },
   "source": [
    "!make"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir -p ./obj/\n",
      "mkdir -p backup\n",
      "mkdir -p results\n",
      "chmod +x *.sh\n",
      "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_detections_cv_v3(void**, detection*, int, float, char**, image**, int, int)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:945:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Krgb\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  945 |                 float \u001b[01;35m\u001b[Krgb\u001b[m\u001b[K[3];\n",
      "      |                       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cv_draw_object(image, float*, int, int, int*, float*, int*, int, char**)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:1443:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuff\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1443 |         char \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K[100];\n",
      "      |              \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:1419:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kit_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1419 |     int \u001b[01;35m\u001b[Kit_tb_res\u001b[m\u001b[K = cv::createTrackbar(it_trackbar_name, window_name, &it_trackbar_value, 1000);\n",
      "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:1423:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klr_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1423 |     int \u001b[01;35m\u001b[Klr_tb_res\u001b[m\u001b[K = cv::createTrackbar(lr_trackbar_name, window_name, &lr_trackbar_value, 20);\n",
      "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:1427:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcl_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1427 |     int \u001b[01;35m\u001b[Kcl_tb_res\u001b[m\u001b[K = cv::createTrackbar(cl_trackbar_name, window_name, &cl_trackbar_value, classes-1);\n",
      "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/image_opencv.cpp:1430:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbo_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1430 |     int \u001b[01;35m\u001b[Kbo_tb_res\u001b[m\u001b[K = cv::createTrackbar(bo_trackbar_name, window_name, boxonly, 1);\n",
      "      |         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/http_stream.cpp -o obj/http_stream.o\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:253:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  253 |                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
      "      |                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid set_track_id(detection*, int, float, float, float, int, int, int)\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:866:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<detection_t>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  866 |         for (int i = 0; \u001b[01;35m\u001b[Ki < v.size()\u001b[m\u001b[K; ++i) {\n",
      "      |                         \u001b[01;35m\u001b[K~~^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:874:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<detection_t>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  874 |     for (int old_id = 0; \u001b[01;35m\u001b[Kold_id < old_dets.size()\u001b[m\u001b[K; ++old_id) {\n",
      "      |                          \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:893:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kstd::vector<detection_t>::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  893 |     for (int index = 0; \u001b[01;35m\u001b[Kindex < new_dets_num*old_dets.size()\u001b[m\u001b[K; ++index) {\n",
      "      |                         \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/http_stream.cpp:929:28:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison of integer expressions of different signedness: ‘\u001b[01m\u001b[Kstd::deque<std::vector<detection_t> >::size_type\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wsign-compare\u0007-Wsign-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  929 |     if (\u001b[01;35m\u001b[Kold_dets_dq.size() > deque_size\u001b[m\u001b[K) old_dets_dq.pop_front();\n",
      "      |         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gemm.c -o obj/gemm.o\n",
      "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/gemm.c:2042:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 2042 |     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
      "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/gemm.c:2041:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 2041 |     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
      "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/utils.c -o obj/utils.o\n",
      "\u001b[01m\u001b[K./src/utils.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcustom_hash\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/utils.c:1093:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around assignment used as truth value [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wparentheses\u0007-Wparentheses\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1093 |     while (\u001b[01;35m\u001b[Kc\u001b[m\u001b[K = *str++)\n",
      "      |            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/string.h:535\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:14\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/utils.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/utils.c:4\u001b[m\u001b[K:\n",
      "In function ‘\u001b[01m\u001b[Kstrncpy\u001b[m\u001b[K’,\n",
      "    inlined from ‘\u001b[01m\u001b[Kcopy_string\u001b[m\u001b[K’ at \u001b[01m\u001b[K./src/utils.c:563:5\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/string_fortified.h:95:10:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin_strncpy\u001b[m\u001b[K’ specified bound depends on the length of the source argument [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wstringop-truncation\u0007-Wstringop-truncation\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   95 |   return \u001b[01;35m\u001b[K__builtin___strncpy_chk (__dest, __src, __len,\u001b[m\u001b[K\n",
      "      |          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   96 | \u001b[01;35m\u001b[K                                  __glibc_objsize (__dest))\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/utils.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcopy_string\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/utils.c:563:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Klength computed here\n",
      "  563 |     strncpy(copy, s, \u001b[01;36m\u001b[Kstrlen(s)\u001b[m\u001b[K+1);\n",
      "      |                      \u001b[01;36m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_check_error_extended\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:218:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcudaError_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kenum <anonymous>\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wenum-compare\u0007-Wenum-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  218 |         if (status \u001b[01;35m\u001b[K!=\u001b[m\u001b[K CUDNN_STATUS_SUCCESS)\n",
      "      |                    \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcublas_check_error_extended\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:252:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcudaError_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Kenum cudaError\u001b[m\u001b[K’} and ‘\u001b[01m\u001b[Kenum cudaError_enum\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wenum-compare\u0007-Wenum-compare\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  252 |       if (status \u001b[01;35m\u001b[K!=\u001b[m\u001b[K CUDA_SUCCESS)\n",
      "      |                  \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
      "At top level:\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:275:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KswitchBlasHandle\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  275 | static cublasHandle_t \u001b[01;35m\u001b[KswitchBlasHandle\u001b[m\u001b[K[16];\n",
      "      |                       \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/dark_cuda.c:274:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KswitchBlasInit\u001b[m\u001b[K’ defined but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  274 | static int \u001b[01;35m\u001b[KswitchBlasInit\u001b[m\u001b[K[16] = { 0 };\n",
      "      |            \u001b[01;35m\u001b[K^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
      "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_convolutional_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/convolutional_layer.c:1335:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kt_intput_size\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1335 |                         size_t \u001b[01;35m\u001b[Kt_intput_size\u001b[m\u001b[K = binary_transpose_align_input(k, n, state.workspace, &l.t_bit_input, ldb_align, l.bit_align);\n",
      "      |                                \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/list.c -o obj/list.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image.c -o obj/image.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activations.c -o obj/activations.o\n",
      "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kactivate\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KRELU6\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   79 |     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
      "      |     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX_MAXVAL\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgradient\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  310 |     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
      "      |     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/im2col.c -o obj/im2col.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/col2im.c -o obj/col2im.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/blas.c -o obj/blas.o\n",
      "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbackward_shortcut_multilayer_cpu\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/blas.c:207:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_index\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  207 |                 int \u001b[01;35m\u001b[Kout_index\u001b[m\u001b[K = id;\n",
      "      |                     \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crop_layer.c -o obj/crop_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
      "\u001b[01m\u001b[K./src/softmax_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_contrastive_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/softmax_layer.c:242:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kmax_truth\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  242 |                     float \u001b[01;35m\u001b[Kmax_truth\u001b[m\u001b[K = 0;\n",
      "      |                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/softmax_layer.c:421:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’ {aka ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’} [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat=\u0007-Wformat=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  421 |             printf(\" Error: too large number of bboxes: contr_size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K > max_contr_size  = %d \\n\", \u001b[32m\u001b[Kcontr_size\u001b[m\u001b[K, max_contr_size);\n",
      "      |                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K                             \u001b[32m\u001b[K~~~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                                                       \u001b[01;35m\u001b[K|\u001b[m\u001b[K                             \u001b[32m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                                                       \u001b[01;35m\u001b[Kint\u001b[m\u001b[K                           \u001b[32m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K\n",
      "      |                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/data.c -o obj/data.o\n",
      "\u001b[01m\u001b[K./src/data.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kload_data_detection\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/data.c:1289:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kx\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1289 |                 int k, \u001b[01;35m\u001b[Kx\u001b[m\u001b[K, y;\n",
      "      |                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:1076:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kr_scale\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1076 |     float r1 = 0, r2 = 0, r3 = 0, r4 = 0, \u001b[01;35m\u001b[Kr_scale\u001b[m\u001b[K = 0;\n",
      "      |                                           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfill_truth_detection\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/data.c:431:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive writing up to 4095 bytes into a region of size 251 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-overflow=\u0007-Wformat-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  431 |             sprintf(buff, \"echo \u001b[01;35m\u001b[K%s\u001b[m\u001b[K \\\"Wrong annotation: w = %f\\\" >> bad_label.list\", \u001b[32m\u001b[Klabelpath\u001b[m\u001b[K, w);\n",
      "      |                                 \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                                                  \u001b[32m\u001b[K~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:431:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kassuming directive output of 8 bytes\n",
      "  431 |             sprintf(buff, \u001b[01;36m\u001b[K\"echo %s \\\"Wrong annotation: w = %f\\\" >> bad_label.list\"\u001b[m\u001b[K, labelpath, w);\n",
      "      |                           \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:38:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___sprintf_chk\u001b[m\u001b[K’ output between 52 and 4461 bytes into a destination of size 256\n",
      "   38 |   return \u001b[01;36m\u001b[K__builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
      "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   39 | \u001b[01;36m\u001b[K                                  __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   40 | \u001b[01;36m\u001b[K                                  __va_arg_pack ())\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:437:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive writing up to 4095 bytes into a region of size 251 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-overflow=\u0007-Wformat-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  437 |             sprintf(buff, \"echo \u001b[01;35m\u001b[K%s\u001b[m\u001b[K \\\"Wrong annotation: h = %f\\\" >> bad_label.list\", \u001b[32m\u001b[Klabelpath\u001b[m\u001b[K, h);\n",
      "      |                                 \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                                                  \u001b[32m\u001b[K~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:437:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kassuming directive output of 8 bytes\n",
      "  437 |             sprintf(buff, \u001b[01;36m\u001b[K\"echo %s \\\"Wrong annotation: h = %f\\\" >> bad_label.list\"\u001b[m\u001b[K, labelpath, h);\n",
      "      |                           \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:38:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___sprintf_chk\u001b[m\u001b[K’ output between 52 and 4461 bytes into a destination of size 256\n",
      "   38 |   return \u001b[01;36m\u001b[K__builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
      "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   39 | \u001b[01;36m\u001b[K                                  __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   40 | \u001b[01;36m\u001b[K                                  __va_arg_pack ())\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:424:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive writing up to 4095 bytes into a region of size 251 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-overflow=\u0007-Wformat-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  424 |             sprintf(buff, \"echo \u001b[01;35m\u001b[K%s\u001b[m\u001b[K \\\"Wrong annotation: x = %f, y = %f\\\" >> bad_label.list\", \u001b[32m\u001b[Klabelpath\u001b[m\u001b[K, x, y);\n",
      "      |                                 \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                                                          \u001b[32m\u001b[K~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:424:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kassuming directive output of 8 bytes\n",
      "  424 |             sprintf(buff, \u001b[01;36m\u001b[K\"echo %s \\\"Wrong annotation: x = %f, y = %f\\\" >> bad_label.list\"\u001b[m\u001b[K, labelpath, x, y);\n",
      "      |                           \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:424:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kassuming directive output of 8 bytes\n",
      "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:38:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___sprintf_chk\u001b[m\u001b[K’ output between 61 and 4784 bytes into a destination of size 256\n",
      "   38 |   return \u001b[01;36m\u001b[K__builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
      "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   39 | \u001b[01;36m\u001b[K                                  __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   40 | \u001b[01;36m\u001b[K                                  __va_arg_pack ())\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:417:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive writing up to 4095 bytes into a region of size 251 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-overflow=\u0007-Wformat-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  417 |             sprintf(buff, \"echo \u001b[01;35m\u001b[K%s\u001b[m\u001b[K \\\"Wrong annotation: x = 0 or y = 0\\\" >> bad_label.list\", \u001b[32m\u001b[Klabelpath\u001b[m\u001b[K);\n",
      "      |                                 \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                                                          \u001b[32m\u001b[K~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:38:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___sprintf_chk\u001b[m\u001b[K’ output between 59 and 4154 bytes into a destination of size 256\n",
      "   38 |   return \u001b[01;36m\u001b[K__builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
      "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   39 | \u001b[01;36m\u001b[K                                  __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   40 | \u001b[01;36m\u001b[K                                  __va_arg_pack ())\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/data.c:404:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[K%s\u001b[m\u001b[K’ directive writing up to 4095 bytes into a region of size 251 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wformat-overflow=\u0007-Wformat-overflow=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  404 |             sprintf(buff, \"echo \u001b[01;35m\u001b[K%s\u001b[m\u001b[K \\\"Wrong annotation: class_id = %d. But class_id should be [from 0 to %d]\\\" >> bad_label.list\", \u001b[32m\u001b[Klabelpath\u001b[m\u001b[K, id, (classes-1));\n",
      "      |                                 \u001b[01;35m\u001b[K^~\u001b[m\u001b[K                                                                                                \u001b[32m\u001b[K~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/include/stdio.h:894\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:13\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/data.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/x86_64-linux-gnu/bits/stdio2.h:38:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K‘\u001b[01m\u001b[K__builtin___sprintf_chk\u001b[m\u001b[K’ output between 95 and 4210 bytes into a destination of size 256\n",
      "   38 |   return \u001b[01;36m\u001b[K__builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\u001b[m\u001b[K\n",
      "      |          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   39 | \u001b[01;36m\u001b[K                                  __glibc_objsize (__s), __fmt,\u001b[m\u001b[K\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "   40 | \u001b[01;36m\u001b[K                                  __va_arg_pack ())\u001b[m\u001b[K;\n",
      "      |                                   \u001b[01;36m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/matrix.c -o obj/matrix.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/network.c -o obj/network.o\n",
      "\u001b[01m\u001b[K./src/network.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_network_waitkey\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/network.c:435:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kema_period\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  435 |         int \u001b[01;35m\u001b[Kema_period\u001b[m\u001b[K = (net.max_batches - ema_start_point - 1000) * (1.0 - net.ema_alpha);\n",
      "      |             \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/network.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_network\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/network.c:660:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  660 |         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&net->input_pinned_cpu\u001b[m\u001b[K, size * sizeof(float), cudaHostRegisterMapped))\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/network.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/connected_layer.c -o obj/connected_layer.o\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_connected_layer_gpu\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:346:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kone\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  346 |     float \u001b[01;35m\u001b[Kone\u001b[m\u001b[K = 1;    // alpha[0], beta[0]\n",
      "      |           \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:344:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kc\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  344 |     float * \u001b[01;35m\u001b[Kc\u001b[m\u001b[K = l.output_gpu;\n",
      "      |             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:343:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kb\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  343 |     float * \u001b[01;35m\u001b[Kb\u001b[m\u001b[K = l.weights_gpu;\n",
      "      |             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:342:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ka\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  342 |     float * \u001b[01;35m\u001b[Ka\u001b[m\u001b[K = state.input;\n",
      "      |             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:341:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  341 |     int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = l.outputs;\n",
      "      |         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:340:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kk\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  340 |     int \u001b[01;35m\u001b[Kk\u001b[m\u001b[K = l.inputs;\n",
      "      |         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/connected_layer.c:339:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  339 |     int \u001b[01;35m\u001b[Km\u001b[m\u001b[K = l.batch;\n",
      "      |         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cost_layer.c -o obj/cost_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/parser.c -o obj/parser.o\n",
      "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kparse_network_cfg_custom\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/parser.c:1761:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1761 |         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&net.input_pinned_cpu\u001b[m\u001b[K, size * sizeof(float), cudaHostRegisterMapped)) net.input_pinned_cpu_flag = 1;\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activation_layer.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/parser.c:6\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ksave_implicit_weights\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/parser.c:1893:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ki\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1893 |     int \u001b[01;35m\u001b[Ki\u001b[m\u001b[K;\n",
      "      |         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kget_classes_multipliers\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/parser.c:435:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kargument 1 range [18446744071562067968, 18446744073709551615] exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Walloc-size-larger-than=\u0007-Walloc-size-larger-than=\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  435 |         classes_multipliers = (float *)\u001b[01;35m\u001b[Kcalloc(classes_counters, sizeof(float))\u001b[m\u001b[K;\n",
      "      |                                        \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K./src/parser.c:3\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/include/stdlib.h:543:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin a call to allocation function ‘\u001b[01m\u001b[Kcalloc\u001b[m\u001b[K’ declared here\n",
      "  543 | extern void *\u001b[01;36m\u001b[Kcalloc\u001b[m\u001b[K (size_t __nmemb, size_t __size)\n",
      "      |              \u001b[01;36m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/option_list.c -o obj/option_list.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/darknet.c -o obj/darknet.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detection_layer.c -o obj/detection_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/captcha.c -o obj/captcha.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/route_layer.c -o obj/route_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/writing.c -o obj/writing.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/box.c -o obj/box.o\n",
      "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbox_iou_kind\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/box.c:154:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMSE\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wswitch\u0007-Wswitch\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  154 |     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(iou_kind) {\n",
      "      |     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdiounms_sort\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/box.c:898:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbeta_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  898 |                     float \u001b[01;35m\u001b[Kbeta_prob\u001b[m\u001b[K = pow(dets[j].prob[k], 2) / sum_prob;\n",
      "      |                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/box.c:897:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kalpha_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  897 |                     float \u001b[01;35m\u001b[Kalpha_prob\u001b[m\u001b[K = pow(dets[i].prob[k], 2) / sum_prob;\n",
      "      |                           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/nightmare.c -o obj/nightmare.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/coco.c -o obj/coco.o\n",
      "\u001b[01m\u001b[K./src/coco.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_coco_recall\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/coco.c:248:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbase\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  248 |     char *\u001b[01;35m\u001b[Kbase\u001b[m\u001b[K = \"results/comp4_det_test_\";\n",
      "      |           \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dice.c -o obj/dice.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo.c -o obj/yolo.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detector.c -o obj/detector.o\n",
      "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Keliminate_bdd\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/detector.c:585:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kstatement with no effect [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-value\u0007-Wunused-value\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  585 |                     \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (k; buf[k + n] != '\\0'; k++)\n",
      "      |                     \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/detector.c:706:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd2\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  706 |         int \u001b[01;35m\u001b[Kmkd2\u001b[m\u001b[K = make_directory(buff2, 0777);\n",
      "      |             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:704:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  704 |         int \u001b[01;35m\u001b[Kmkd\u001b[m\u001b[K = make_directory(buff, 0777);\n",
      "      |             \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector_map\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/detector.c:1323:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kcur_prob\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1323 |                 double \u001b[01;35m\u001b[Kcur_prob\u001b[m\u001b[K = 0;\n",
      "      |                        \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:1344:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_recall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1344 |         float \u001b[01;35m\u001b[Kclass_recall\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)(truth_classes_count[i] - tp_for_thresh_per_class[i]));\n",
      "      |               \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:1343:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_precision\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1343 |         float \u001b[01;35m\u001b[Kclass_precision\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)fp_for_thresh_per_class[i]);\n",
      "      |               \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdraw_object\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/detector.c:1872:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kinv_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1872 |             float \u001b[01;35m\u001b[Kinv_loss\u001b[m\u001b[K = 1.0 / max_val_cmp(0.01, avg_loss);\n",
      "      |                   \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/layer.c -o obj/layer.o\n",
      "\u001b[01m\u001b[K./src/layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfree_layer_custom\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/layer.c:208:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around ‘\u001b[01m\u001b[K&&\u001b[m\u001b[K’ within ‘\u001b[01m\u001b[K||\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wparentheses\u0007-Wparentheses\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  208 |     if (l.delta_gpu && (l.optimized_memory < 1 || \u001b[01;35m\u001b[Kl.keep_delta_gpu && l.optimized_memory < 3\u001b[m\u001b[K)) cuda_free(l.delta_gpu), l.delta_gpu = NULL;\n",
      "      |                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/compare.c -o obj/compare.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/classifier.c -o obj/classifier.o\n",
      "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_classifier\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/classifier.c:146:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcount\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  146 |     int \u001b[01;35m\u001b[Kcount\u001b[m\u001b[K = 0;\n",
      "      |         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpredict_classifier\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/classifier.c:855:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktime\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  855 |     clock_t \u001b[01;35m\u001b[Ktime\u001b[m\u001b[K;\n",
      "      |             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdemo_classifier\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/classifier.c:1283:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1283 |         struct timeval tval_before, tval_after, \u001b[01;35m\u001b[Ktval_result\u001b[m\u001b[K;\n",
      "      |                                                 \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/classifier.c:1283:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_after\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      " 1283 |         struct timeval tval_before, \u001b[01;35m\u001b[Ktval_after\u001b[m\u001b[K, tval_result;\n",
      "      |                                     \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/local_layer.c -o obj/local_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/swag.c -o obj/swag.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
      "\u001b[01m\u001b[K./src/shortcut_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_shortcut_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/shortcut_layer.c:55:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kscale\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   55 |         float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = sqrt(2. / l.nweights);\n",
      "      |               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/representation_layer.c -o obj/representation_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activation_layer.c -o obj/activation_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gru_layer.c -o obj/gru_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn.c -o obj/rnn.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_vid.c -o obj/rnn_vid.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/demo.c -o obj/demo.o\n",
      "\u001b[01m\u001b[K./src/demo.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdetect_in_thread\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/demo.c:100:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kl\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  100 |         layer \u001b[01;35m\u001b[Kl\u001b[m\u001b[K = net.layers[net.n - 1];\n",
      "      |               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tag.c -o obj/tag.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cifar.c -o obj/cifar.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/go.c -o obj/go.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/art.c -o obj/art.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/region_layer.c -o obj/region_layer.o\n",
      "\u001b[01m\u001b[K./src/region_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_region_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/region_layer.c:63:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   63 |     int \u001b[01;35m\u001b[Kold_h\u001b[m\u001b[K = l->h;\n",
      "      |         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/region_layer.c:62:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   62 |     int \u001b[01;35m\u001b[Kold_w\u001b[m\u001b[K = l->w;\n",
      "      |         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_old_layer.c -o obj/reorg_old_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/super.c -o obj/super.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/voxel.c -o obj/voxel.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tree.c -o obj/tree.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_yolo_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:67:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   67 |     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&l.output\u001b[m\u001b[K, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
      "      |                                      \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:74:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   74 |     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&l.delta\u001b[m\u001b[K, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
      "      |                                      \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_yolo_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:105:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  105 |         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&l->output\u001b[m\u001b[K, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:114:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  114 |         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&l->delta\u001b[m\u001b[K, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kprocess_batch\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:425:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbest_match_t\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-but-set-variable\u0007-Wunused-but-set-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  425 |                     int \u001b[01;35m\u001b[Kbest_match_t\u001b[m\u001b[K = 0;\n",
      "      |                         \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_yolo_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:705:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_anyobj\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  705 |     float \u001b[01;35m\u001b[Kavg_anyobj\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:704:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_obj\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  704 |     float \u001b[01;35m\u001b[Kavg_obj\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:703:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_cat\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  703 |     float \u001b[01;35m\u001b[Kavg_cat\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:702:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Krecall75\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  702 |     float \u001b[01;35m\u001b[Krecall75\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:701:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Krecall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  701 |     float \u001b[01;35m\u001b[Krecall\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:700:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_ciou_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  700 |     float \u001b[01;35m\u001b[Ktot_ciou_loss\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:699:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_diou_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  699 |     float \u001b[01;35m\u001b[Ktot_diou_loss\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:696:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_ciou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  696 |     float \u001b[01;35m\u001b[Ktot_ciou\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:695:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_diou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  695 |     float \u001b[01;35m\u001b[Ktot_diou\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:694:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_giou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  694 |     float \u001b[01;35m\u001b[Ktot_giou\u001b[m\u001b[K = 0;\n",
      "      |           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/yolo_layer.c:666:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-variable\u0007-Wunused-variable\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  666 |     int b, \u001b[01;35m\u001b[Kn\u001b[m\u001b[K;\n",
      "      |            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gaussian_yolo_layer.c -o obj/gaussian_yolo_layer.o\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:70:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   70 |     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&l.output\u001b[m\u001b[K, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
      "      |                                      \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:77:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "   77 |     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&l.delta\u001b[m\u001b[K, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
      "      |                                      \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                      \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:109:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  109 |         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&l->output\u001b[m\u001b[K, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:118:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wincompatible-pointer-types\u0007-Wincompatible-pointer-types\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  118 |         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&l->delta\u001b[m\u001b[K, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
      "      |                                          \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[K|\u001b[m\u001b[K\n",
      "      |                                          \u001b[01;35m\u001b[Kfloat **\u001b[m\u001b[K\n",
      "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:95\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:5331:60:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
      " 5331 | extern __host__ cudaError_t CUDARTAPI cudaHostAlloc(\u001b[01;36m\u001b[Kvoid **pHost\u001b[m\u001b[K, size_t size, unsigned int flags);\n",
      "      |                                                     \u001b[01;36m\u001b[K~~~~~~~^~~~~\u001b[m\u001b[K\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/conv_lstm_layer.c -o obj/conv_lstm_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/scale_channels_layer.c -o obj/scale_channels_layer.o\n",
      "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/sam_layer.c -o obj/sam_layer.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/convolutional_kernels.cu -o obj/convolutional_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/activation_kernels.cu -o obj/activation_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/im2col_kernels.cu -o obj/im2col_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/col2im_kernels.cu -o obj/col2im_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/blas_kernels.cu -o obj/blas_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/crop_layer_kernels.cu -o obj/crop_layer_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/dropout_layer_kernels.cu -o obj/dropout_layer_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/maxpool_layer_kernels.cu -o obj/maxpool_layer_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/network_kernels.cu -o obj/network_kernels.o\n",
      "nvcc -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/avgpool_layer_kernels.cu -o obj/avgpool_layer_kernels.o\n",
      "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -rdynamic -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF obj/image_opencv.o obj/http_stream.o obj/gemm.o obj/utils.o obj/dark_cuda.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/darknet.o obj/detection_layer.o obj/captcha.o obj/route_layer.o obj/writing.o obj/box.o obj/nightmare.o obj/normalization_layer.o obj/avgpool_layer.o obj/coco.o obj/dice.o obj/yolo.o obj/detector.o obj/layer.o obj/compare.o obj/classifier.o obj/local_layer.o obj/swag.o obj/shortcut_layer.o obj/representation_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/rnn.o obj/rnn_vid.o obj/crnn_layer.o obj/demo.o obj/tag.o obj/cifar.o obj/go.o obj/batchnorm_layer.o obj/art.o obj/region_layer.o obj/reorg_layer.o obj/reorg_old_layer.o obj/super.o obj/voxel.o obj/tree.o obj/yolo_layer.o obj/gaussian_yolo_layer.o obj/upsample_layer.o obj/lstm_layer.o obj/conv_lstm_layer.o obj/scale_channels_layer.o obj/sam_layer.o obj/convolutional_kernels.o obj/activation_kernels.o obj/im2col_kernels.o obj/col2im_kernels.o obj/blas_kernels.o obj/crop_layer_kernels.o obj/dropout_layer_kernels.o obj/maxpool_layer_kernels.o obj/network_kernels.o obj/avgpool_layer_kernels.o -o darknet -lm -pthread `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv` -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand -L/usr/local/cudnn/lib64 -lcudnn -lstdc++\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vVtgyY_ELoSf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dd54f717-623a-4de1-f68b-7b365f7790f6"
   },
   "source": [
    "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.weights"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2025-01-02 10:44:33--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-p6.weights\n",
      "Resolving github.com (github.com)... 140.82.114.4\n",
      "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/34899a80-d690-11eb-9d7e-9f2e47e580e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250102T104433Z&X-Amz-Expires=300&X-Amz-Signature=af281a2e79f4982af512ef4e6ad8be551308d1c05b484e17bf2ebde202eaa98a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov4-p6.weights&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-01-02 10:44:33--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/34899a80-d690-11eb-9d7e-9f2e47e580e5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250102T104433Z&X-Amz-Expires=300&X-Amz-Signature=af281a2e79f4982af512ef4e6ad8be551308d1c05b484e17bf2ebde202eaa98a&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov4-p6.weights&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 510868180 (487M) [application/octet-stream]\n",
      "Saving to: ‘yolov4-p6.weights’\n",
      "\n",
      "yolov4-p6.weights   100%[===================>] 487.20M  36.4MB/s    in 13s     \n",
      "\n",
      "2025-01-02 10:44:46 (36.1 MB/s) - ‘yolov4-p6.weights’ saved [510868180/510868180]\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G9Fv0wjCMPYY"
   },
   "source": [
    "def imShow(path):\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    height, width = image.shape[:2]\n",
    "    resized_image = cv2.resize(\n",
    "        image, (3 * width, 3 * height), interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18, 10)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def upload():\n",
    "    from google.colab import files\n",
    "\n",
    "    uploaded = files.upload()\n",
    "    for name, data in uploaded.items():\n",
    "        with open(name, \"wb\") as f:\n",
    "            f.write(data)\n",
    "            print(\"saved file\", name)\n",
    "\n",
    "\n",
    "def download(path):\n",
    "    from google.colab import files\n",
    "\n",
    "    files.download(path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Детекция на искаженных**"
   ],
   "metadata": {
    "id": "SAbAvepjbpcJ"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BjbebMZZ50Zg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2cf79dd1-2ba6-4804-ae98-35aaf8e48338",
    "collapsed": true
   },
   "source": [
    "!./darknet detector test cfg/coco.data cfg/yolov4-p6.cfg yolov4-p6.weights -ext_output -dont_show -out result.json < /content/WoodScape/images_list.txt"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
      "person: 79%\t(left_x:  817   top_y:   28   width:   53   height:   86)\n",
      "person: 38%\t(left_x:  861   top_y:   32   width:   38   height:   49)\n",
      "person: 68%\t(left_x:  882   top_y:   61   width:   46   height:   87)\n",
      "person: 62%\t(left_x:  886   top_y:   59   width:   41   height:   54)\n",
      "person: 59%\t(left_x:  892   top_y:   60   width:   34   height:   35)\n",
      "person: 34%\t(left_x:  923   top_y:   71   width:   32   height:   38)\n",
      "person: 42%\t(left_x:  933   top_y:   76   width:   36   height:   37)\n",
      "person: 54%\t(left_x:  938   top_y:  108   width:   71   height:   77)\n",
      "person: 46%\t(left_x:  940   top_y:   82   width:   54   height:   57)\n",
      "person: 55%\t(left_x:  989   top_y:  120   width:   42   height:   48)\n",
      "person: 65%\t(left_x:  993   top_y:  159   width:   79   height:   69)\n",
      "person: 52%\t(left_x: 1037   top_y:  163   width:   46   height:   54)\n",
      "person: 49%\t(left_x: 1060   top_y:  201   width:   29   height:   26)\n",
      "person: 30%\t(left_x: 1073   top_y:  216   width:   32   height:   28)\n",
      "person: 39%\t(left_x: 1079   top_y:  220   width:   29   height:   31)\n",
      "person: 40%\t(left_x: 1087   top_y:  231   width:   29   height:   31)\n",
      "person: 49%\t(left_x: 1094   top_y:  241   width:   27   height:   40)\n",
      "person: 29%\t(left_x: 1105   top_y:   87   width:   28   height:   38)\n",
      "person: 39%\t(left_x: 1111   top_y:  261   width:   21   height:   25)\n",
      "person: 53%\t(left_x: 1125   top_y:  277   width:   30   height:   38)\n",
      "car: 59%\t(left_x: 1146   top_y:  543   width:  105   height:  152)\n",
      "person: 32%\t(left_x: 1150   top_y:  332   width:   39   height:   39)\n",
      "person: 30%\t(left_x: 1203   top_y:  488   width:   17   height:   45)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07617_RV.png: Predicted in 145.515000 milli-seconds.\n",
      "aeroplane: 32%\t(left_x:    3   top_y:  526   width: 1277   height:  431)\n",
      "person: 74%\t(left_x:  361   top_y:  257   width:   17   height:   31)\n",
      "person: 79%\t(left_x:  534   top_y:  190   width:   21   height:   58)\n",
      "person: 93%\t(left_x:  767   top_y:   91   width:  113   height:  272)\n",
      "person: 62%\t(left_x: 1039   top_y:  316   width:    9   height:   19)\n",
      "car: 54%\t(left_x: 1062   top_y:  319   width:   35   height:   25)\n",
      "skateboard: 46%\t(left_x: 1161   top_y:  510   width:   17   height:   31)\n",
      "person: 89%\t(left_x: 1162   top_y:  412   width:   88   height:  127)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05850_MVL.png: Predicted in 144.546000 milli-seconds.\n",
      "car: 34%\t(left_x:   -2   top_y:   -7   width: 1273   height:  968)\n",
      "car: 62%\t(left_x:  119   top_y:  279   width:   59   height:   54)\n",
      "bicycle: 55%\t(left_x:  222   top_y:  134   width:   42   height:   38)\n",
      "person: 28%\t(left_x:  227   top_y:  132   width:   36   height:   38)\n",
      "person: 26%\t(left_x:  301   top_y:   75   width:   19   height:   32)\n",
      "person: 31%\t(left_x:  665   top_y:   25   width:   14   height:   31)\n",
      "person: 38%\t(left_x:  720   top_y:   30   width:   11   height:   27)\n",
      "person: 55%\t(left_x:  797   top_y:   55   width:   12   height:   24)\n",
      "person: 81%\t(left_x:  840   top_y:   68   width:   21   height:   40)\n",
      "person: 57%\t(left_x:  880   top_y:   89   width:   29   height:   40)\n",
      "person: 44%\t(left_x:  894   top_y:   97   width:   26   height:   42)\n",
      "person: 36%\t(left_x:  938   top_y:   55   width:   15   height:   26)\n",
      "person: 51%\t(left_x:  943   top_y:  136   width:   23   height:   24)\n",
      "person: 61%\t(left_x:  971   top_y:  150   width:   20   height:   26)\n",
      "car: 47%\t(left_x: 1050   top_y:  234   width:   29   height:   25)\n",
      "car: 80%\t(left_x: 1090   top_y:  280   width:   43   height:   43)\n",
      "car: 68%\t(left_x: 1119   top_y:  353   width:   85   height:  102)\n",
      "car: 43%\t(left_x: 1158   top_y:  351   width:   53   height:  100)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05347_MVL.png: Predicted in 145.740000 milli-seconds.\n",
      "car: 73%\t(left_x:  121   top_y:  278   width:   53   height:   52)\n",
      "car: 85%\t(left_x:  180   top_y:  146   width:   68   height:   71)\n",
      "car: 31%\t(left_x:  236   top_y:  120   width:   33   height:   27)\n",
      "car: 90%\t(left_x:  283   top_y:   56   width:  101   height:   82)\n",
      "person: 59%\t(left_x:  402   top_y:   36   width:   10   height:   24)\n",
      "person: 27%\t(left_x:  445   top_y:   18   width:   11   height:   31)\n",
      "person: 71%\t(left_x:  467   top_y:   15   width:   16   height:   42)\n",
      "person: 64%\t(left_x:  489   top_y:    9   width:   21   height:   39)\n",
      "person: 40%\t(left_x:  534   top_y:   17   width:   10   height:   22)\n",
      "person: 41%\t(left_x:  550   top_y:    3   width:   14   height:   44)\n",
      "bicycle: 80%\t(left_x:  576   top_y:   18   width:   62   height:   45)\n",
      "person: 63%\t(left_x:  589   top_y:    3   width:   36   height:   44)\n",
      "bicycle: 83%\t(left_x:  646   top_y:   12   width:   64   height:   46)\n",
      "bicycle: 28%\t(left_x:  717   top_y:   31   width:   29   height:   34)\n",
      "bicycle: 46%\t(left_x:  717   top_y:   29   width:   50   height:   37)\n",
      "person: 62%\t(left_x:  746   top_y:    8   width:   17   height:   21)\n",
      "bicycle: 60%\t(left_x:  795   top_y:   52   width:   56   height:   47)\n",
      "bicycle: 30%\t(left_x:  818   top_y:   64   width:   35   height:   36)\n",
      "person: 37%\t(left_x:  835   top_y:   32   width:   28   height:   26)\n",
      "bicycle: 35%\t(left_x:  862   top_y:   80   width:   49   height:   34)\n",
      "bicycle: 47%\t(left_x:  869   top_y:   90   width:   56   height:   37)\n",
      "bicycle: 35%\t(left_x:  879   top_y:   97   width:   48   height:   38)\n",
      "person: 68%\t(left_x:  895   top_y:   62   width:   22   height:   30)\n",
      "bicycle: 26%\t(left_x:  906   top_y:  113   width:   34   height:   33)\n",
      "bicycle: 55%\t(left_x:  906   top_y:   98   width:   48   height:   47)\n",
      "bicycle: 53%\t(left_x:  949   top_y:  130   width:   41   height:   40)\n",
      "bicycle: 36%\t(left_x:  957   top_y:  128   width:   53   height:   46)\n",
      "person: 33%\t(left_x:  976   top_y:  124   width:   38   height:   46)\n",
      "bicycle: 26%\t(left_x: 1020   top_y:  201   width:   32   height:   27)\n",
      "bicycle: 40%\t(left_x: 1102   top_y:  287   width:   46   height:   31)\n",
      "bicycle: 35%\t(left_x: 1108   top_y:  293   width:   48   height:   38)\n",
      "car: 65%\t(left_x: 1185   top_y:  376   width:   96   height:  143)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02595_MVR.png: Predicted in 144.971000 milli-seconds.\n",
      "person: 52%\t(left_x:   69   top_y:  299   width:  111   height:   77)\n",
      "person: 31%\t(left_x:   77   top_y:  333   width:   61   height:   51)\n",
      "person: 33%\t(left_x:   77   top_y:  334   width:   64   height:   85)\n",
      "person: 28%\t(left_x:  121   top_y:  285   width:   38   height:   39)\n",
      "person: 32%\t(left_x:  160   top_y:  213   width:   44   height:   43)\n",
      "person: 69%\t(left_x:  196   top_y:  143   width:   61   height:   68)\n",
      "bicycle: 41%\t(left_x:  200   top_y:  206   width:   41   height:   37)\n",
      "bicycle: 29%\t(left_x:  217   top_y:  145   width:   61   height:   63)\n",
      "person: 26%\t(left_x:  224   top_y:  129   width:   30   height:   33)\n",
      "traffic light: 46%\t(left_x:  229   top_y:    2   width:   26   height:   35)\n",
      "bicycle: 52%\t(left_x:  240   top_y:  162   width:   41   height:   45)\n",
      "person: 42%\t(left_x:  288   top_y:   70   width:   55   height:   89)\n",
      "person: 26%\t(left_x:  300   top_y:   33   width:   59   height:  124)\n",
      "person: 65%\t(left_x:  318   top_y:   25   width:   55   height:  111)\n",
      "bicycle: 62%\t(left_x:  323   top_y:   83   width:   43   height:   76)\n",
      "person: 31%\t(left_x:  331   top_y:   29   width:   68   height:   96)\n",
      "bicycle: 55%\t(left_x:  358   top_y:   85   width:   33   height:   49)\n",
      "person: 46%\t(left_x:  376   top_y:   29   width:   30   height:   63)\n",
      "person: 76%\t(left_x:  396   top_y:   23   width:   42   height:   72)\n",
      "person: 63%\t(left_x:  433   top_y:   11   width:   36   height:   65)\n",
      "person: 30%\t(left_x:  434   top_y:   40   width:   23   height:   40)\n",
      "person: 57%\t(left_x:  480   top_y:    3   width:   21   height:   56)\n",
      "person: 41%\t(left_x:  494   top_y:   18   width:   18   height:   41)\n",
      "person: 62%\t(left_x:  515   top_y:    3   width:   16   height:   46)\n",
      "bicycle: 26%\t(left_x:  515   top_y:    4   width:   16   height:   45)\n",
      "bicycle: 76%\t(left_x:  583   top_y:    2   width:   93   height:   50)\n",
      "person: 56%\t(left_x:  587   top_y:    2   width:   85   height:   49)\n",
      "person: 45%\t(left_x:  613   top_y:    3   width:   40   height:   37)\n",
      "person: 49%\t(left_x:  780   top_y:    3   width:   14   height:   40)\n",
      "person: 46%\t(left_x:  832   top_y:    5   width:   16   height:   41)\n",
      "bicycle: 47%\t(left_x:  860   top_y:   43   width:   25   height:   30)\n",
      "bicycle: 34%\t(left_x:  862   top_y:   45   width:   47   height:   34)\n",
      "bicycle: 40%\t(left_x:  879   top_y:   26   width:   27   height:   49)\n",
      "person: 69%\t(left_x:  879   top_y:   26   width:   27   height:   47)\n",
      "bicycle: 41%\t(left_x:  886   top_y:   51   width:   28   height:   30)\n",
      "bicycle: 36%\t(left_x:  924   top_y:   72   width:   27   height:   28)\n",
      "person: 29%\t(left_x:  925   top_y:   58   width:   28   height:   39)\n",
      "bicycle: 33%\t(left_x:  925   top_y:   58   width:   28   height:   39)\n",
      "bicycle: 30%\t(left_x:  937   top_y:   56   width:   24   height:   48)\n",
      "bicycle: 36%\t(left_x:  937   top_y:   76   width:   22   height:   28)\n",
      "person: 69%\t(left_x:  937   top_y:   54   width:   24   height:   45)\n",
      "person: 52%\t(left_x: 1123   top_y:  278   width:   31   height:   49)\n",
      "person: 27%\t(left_x: 1139   top_y:  263   width:   20   height:   36)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01203_RV.png: Predicted in 144.315000 milli-seconds.\n",
      "car: 46%\t(left_x:    1   top_y:  502   width: 1274   height:  451)\n",
      "bicycle: 80%\t(left_x:   42   top_y:  402   width:   74   height:   92)\n",
      "bicycle: 55%\t(left_x:   86   top_y:  354   width:   84   height:  103)\n",
      "bicycle: 60%\t(left_x:  104   top_y:  346   width:   87   height:   92)\n",
      "bicycle: 43%\t(left_x:  105   top_y:  383   width:   60   height:   78)\n",
      "bicycle: 58%\t(left_x:  161   top_y:  342   width:   49   height:   65)\n",
      "bicycle: 70%\t(left_x:  201   top_y:  327   width:   59   height:   72)\n",
      "person: 50%\t(left_x:  202   top_y:  295   width:   26   height:   41)\n",
      "bicycle: 62%\t(left_x:  218   top_y:  315   width:   55   height:   71)\n",
      "person: 79%\t(left_x:  229   top_y:  276   width:   47   height:   73)\n",
      "bicycle: 73%\t(left_x:  274   top_y:  293   width:   73   height:   64)\n",
      "person: 40%\t(left_x:  366   top_y:  285   width:   20   height:   46)\n",
      "car: 92%\t(left_x:  597   top_y:  228   width:  123   height:   97)\n",
      "car: 58%\t(left_x:  732   top_y:  270   width:   18   height:   13)\n",
      "car: 54%\t(left_x:  751   top_y:  273   width:   30   height:   17)\n",
      "car: 70%\t(left_x:  777   top_y:  277   width:   36   height:   20)\n",
      "car: 63%\t(left_x:  805   top_y:  283   width:   37   height:   24)\n",
      "car: 32%\t(left_x:  816   top_y:  285   width:   37   height:   23)\n",
      "car: 79%\t(left_x:  835   top_y:  292   width:   65   height:   39)\n",
      "car: 87%\t(left_x:  894   top_y:  313   width:   95   height:   57)\n",
      "person: 29%\t(left_x:  996   top_y:  342   width:    9   height:   15)\n",
      "car: 77%\t(left_x: 1016   top_y:  358   width:   28   height:   22)\n",
      "car: 55%\t(left_x: 1104   top_y:  403   width:   25   height:   26)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04398_MVR.png: Predicted in 146.478000 milli-seconds.\n",
      "bicycle: 49%\t(left_x:   40   top_y:  385   width:   99   height:   89)\n",
      "bicycle: 57%\t(left_x:   53   top_y:  345   width:  110   height:   93)\n",
      "bicycle: 34%\t(left_x:   59   top_y:  324   width:  112   height:   66)\n",
      "bicycle: 61%\t(left_x:   64   top_y:  299   width:  118   height:   81)\n",
      "bicycle: 29%\t(left_x:   65   top_y:  235   width:   73   height:   95)\n",
      "bicycle: 54%\t(left_x:   81   top_y:  242   width:  130   height:  110)\n",
      "car: 35%\t(left_x:  160   top_y:  257   width: 1114   height:  691)\n",
      "person: 33%\t(left_x:  210   top_y:  133   width:    9   height:    9)\n",
      "person: 32%\t(left_x:  237   top_y:  127   width:   35   height:   43)\n",
      "person: 52%\t(left_x:  248   top_y:  122   width:   27   height:   40)\n",
      "person: 41%\t(left_x:  258   top_y:  110   width:   37   height:   45)\n",
      "bicycle: 35%\t(left_x:  934   top_y:   72   width:   45   height:   65)\n",
      "person: 48%\t(left_x: 1126   top_y:  284   width:   28   height:   45)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00815_FV.png: Predicted in 145.325000 milli-seconds.\n",
      "car: 37%\t(left_x:    1   top_y:  487   width: 1280   height:  455)\n",
      "car: 81%\t(left_x:   18   top_y:  477   width:   50   height:   48)\n",
      "traffic light: 77%\t(left_x:  159   top_y:  313   width:   16   height:   39)\n",
      "traffic light: 29%\t(left_x:  170   top_y:  396   width:    8   height:   17)\n",
      "traffic light: 51%\t(left_x:  203   top_y:  355   width:   12   height:   24)\n",
      "traffic light: 27%\t(left_x:  249   top_y:  362   width:   17   height:   23)\n",
      "traffic light: 79%\t(left_x:  302   top_y:  263   width:   18   height:   40)\n",
      "car: 80%\t(left_x:  369   top_y:  362   width:   48   height:   26)\n",
      "car: 91%\t(left_x:  453   top_y:  319   width:  118   height:   77)\n",
      "traffic light: 26%\t(left_x:  504   top_y:  306   width:   11   height:   11)\n",
      "car: 32%\t(left_x:  563   top_y:  343   width:   12   height:   11)\n",
      "car: 80%\t(left_x:  579   top_y:  337   width:   37   height:   25)\n",
      "car: 83%\t(left_x:  628   top_y:  336   width:   33   height:   25)\n",
      "car: 81%\t(left_x:  670   top_y:  340   width:   26   height:   18)\n",
      "bicycle: 73%\t(left_x:  843   top_y:  351   width:   33   height:   31)\n",
      "person: 31%\t(left_x:  843   top_y:  348   width:   31   height:   33)\n",
      "person: 56%\t(left_x:  850   top_y:  327   width:   20   height:   40)\n",
      "person: 80%\t(left_x:  881   top_y:  328   width:   21   height:   51)\n",
      "traffic light: 77%\t(left_x:  916   top_y:  131   width:   32   height:   71)\n",
      "bicycle: 31%\t(left_x:  919   top_y:  352   width:   29   height:   47)\n",
      "bicycle: 77%\t(left_x:  920   top_y:  352   width:   63   height:   58)\n",
      "stop sign: 48%\t(left_x:  926   top_y:   93   width:   64   height:   67)\n",
      "person: 88%\t(left_x: 1046   top_y:  333   width:   34   height:   93)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01935_MVR.png: Predicted in 144.593000 milli-seconds.\n",
      "person: 58%\t(left_x:   33   top_y:  297   width:   90   height:   97)\n",
      "person: 57%\t(left_x:   44   top_y:  713   width:  109   height:   61)\n",
      "bicycle: 26%\t(left_x:   53   top_y:  300   width:  118   height:   81)\n",
      "bicycle: 51%\t(left_x:   82   top_y:  367   width:   61   height:   50)\n",
      "bicycle: 54%\t(left_x:  100   top_y:  303   width:   78   height:   65)\n",
      "bicycle: 75%\t(left_x:  120   top_y:  217   width:   58   height:   58)\n",
      "person: 57%\t(left_x:  159   top_y:  195   width:   32   height:   43)\n",
      "bicycle: 29%\t(left_x:  162   top_y:  197   width:   32   height:   43)\n",
      "bicycle: 91%\t(left_x:  373   top_y:    5   width:  115   height:   81)\n",
      "bicycle: 42%\t(left_x:  825   top_y:   15   width:   55   height:   36)\n",
      "person: 51%\t(left_x:  912   top_y:   38   width:   38   height:   39)\n",
      "bicycle: 25%\t(left_x:  913   top_y:   39   width:   39   height:   39)\n",
      "bicycle: 37%\t(left_x:  927   top_y:   54   width:   29   height:   33)\n",
      "person: 35%\t(left_x:  930   top_y:   47   width:   36   height:   40)\n",
      "person: 58%\t(left_x:  945   top_y:   41   width:   41   height:   60)\n",
      "person: 27%\t(left_x:  954   top_y:   58   width:   34   height:   42)\n",
      "bicycle: 45%\t(left_x: 1015   top_y:  135   width:   43   height:   32)\n",
      "bicycle: 44%\t(left_x: 1034   top_y:  143   width:   37   height:   32)\n",
      "person: 29%\t(left_x: 1035   top_y:  142   width:   36   height:   34)\n",
      "car: 35%\t(left_x: 1110   top_y:  285   width:   51   height:   51)\n",
      "person: 30%\t(left_x: 1131   top_y:  286   width:   23   height:   42)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01584_MVL.png: Predicted in 143.879000 milli-seconds.\n",
      "car: 47%\t(left_x:   -5   top_y:   22   width: 1272   height:  934)\n",
      "car: 40%\t(left_x:  120   top_y:  278   width:   58   height:   55)\n",
      "car: 27%\t(left_x:  129   top_y:  244   width:   24   height:   18)\n",
      "car: 57%\t(left_x:  237   top_y:  102   width:   36   height:   39)\n",
      "car: 33%\t(left_x:  271   top_y:   89   width:   36   height:   28)\n",
      "car: 71%\t(left_x:  320   top_y:   59   width:   58   height:   34)\n",
      "car: 87%\t(left_x:  374   top_y:   30   width:   77   height:   47)\n",
      "person: 41%\t(left_x:  438   top_y:   16   width:   14   height:   18)\n",
      "person: 59%\t(left_x:  460   top_y:   11   width:   16   height:   39)\n",
      "person: 40%\t(left_x:  513   top_y:    5   width:   15   height:   35)\n",
      "person: 47%\t(left_x:  522   top_y:    2   width:   18   height:   38)\n",
      "truck: 75%\t(left_x:  549   top_y:    2   width:  161   height:   43)\n",
      "person: 88%\t(left_x:  784   top_y:   20   width:   27   height:   48)\n",
      "person: 77%\t(left_x:  808   top_y:   29   width:   33   height:   48)\n",
      "person: 63%\t(left_x:  823   top_y:   36   width:   41   height:   51)\n",
      "bicycle: 37%\t(left_x:  830   top_y:   52   width:   39   height:   48)\n",
      "bicycle: 58%\t(left_x:  934   top_y:  114   width:   39   height:   40)\n",
      "bicycle: 28%\t(left_x:  960   top_y:  133   width:   33   height:   34)\n",
      "bicycle: 50%\t(left_x:  966   top_y:  135   width:   43   height:   43)\n",
      "bicycle: 56%\t(left_x:  972   top_y:  142   width:   58   height:   50)\n",
      "bicycle: 26%\t(left_x:  979   top_y:  143   width:   73   height:   59)\n",
      "bicycle: 32%\t(left_x:  988   top_y:  155   width:   46   height:   37)\n",
      "bicycle: 36%\t(left_x:  999   top_y:  157   width:   57   height:   51)\n",
      "person: 40%\t(left_x: 1002   top_y:  157   width:   55   height:   52)\n",
      "person: 25%\t(left_x: 1008   top_y:  179   width:   47   height:   44)\n",
      "person: 36%\t(left_x: 1024   top_y:  190   width:   45   height:   37)\n",
      "bicycle: 43%\t(left_x: 1044   top_y:  211   width:   42   height:   37)\n",
      "bicycle: 35%\t(left_x: 1055   top_y:  222   width:   38   height:   36)\n",
      "bicycle: 32%\t(left_x: 1062   top_y:  229   width:   37   height:   33)\n",
      "bicycle: 40%\t(left_x: 1073   top_y:  244   width:   45   height:   36)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02164_MVL.png: Predicted in 144.314000 milli-seconds.\n",
      "car: 44%\t(left_x:   -3   top_y:   40   width: 1273   height:  916)\n",
      "car: 68%\t(left_x:  117   top_y:  278   width:   58   height:   53)\n",
      "car: 90%\t(left_x:  300   top_y:   40   width:   74   height:   74)\n",
      "car: 33%\t(left_x:  370   top_y:    2   width:  128   height:   87)\n",
      "truck: 77%\t(left_x:  370   top_y:    3   width:  129   height:   88)\n",
      "car: 91%\t(left_x:  523   top_y:    2   width:  265   height:   75)\n",
      "bicycle: 65%\t(left_x:  913   top_y:   99   width:   69   height:   62)\n",
      "bicycle: 47%\t(left_x:  945   top_y:  109   width:   51   height:   57)\n",
      "bicycle: 65%\t(left_x:  958   top_y:  137   width:   63   height:   57)\n",
      "bicycle: 32%\t(left_x:  988   top_y:  154   width:   36   height:   58)\n",
      "bicycle: 67%\t(left_x:  998   top_y:  160   width:   57   height:   64)\n",
      "bicycle: 30%\t(left_x: 1022   top_y:  176   width:   44   height:   57)\n",
      "bicycle: 45%\t(left_x: 1041   top_y:  212   width:   58   height:   42)\n",
      "person: 27%\t(left_x: 1044   top_y:  210   width:   64   height:   45)\n",
      "person: 36%\t(left_x: 1073   top_y:  206   width:   35   height:   52)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08081_MVR.png: Predicted in 145.644000 milli-seconds.\n",
      "car: 36%\t(left_x:    1   top_y:  318   width:  106   height:  195)\n",
      "car: 80%\t(left_x:    3   top_y:  313   width:  201   height:  231)\n",
      "car: 74%\t(left_x:   20   top_y:  587   width:  158   height:  263)\n",
      "car: 41%\t(left_x:   29   top_y:  556   width:   72   height:   55)\n",
      "car: 34%\t(left_x:   91   top_y:  289   width:   33   height:   34)\n",
      "car: 92%\t(left_x:  119   top_y:  119   width:  228   height:  208)\n",
      "car: 36%\t(left_x:  296   top_y:   16   width:  202   height:  116)\n",
      "car: 75%\t(left_x:  296   top_y:   56   width:   99   height:   79)\n",
      "car: 63%\t(left_x:  341   top_y:   15   width:  161   height:   82)\n",
      "car: 87%\t(left_x:  462   top_y:    2   width:   87   height:   34)\n",
      "person: 91%\t(left_x:  541   top_y:    2   width:  111   height:  152)\n",
      "car: 62%\t(left_x:  703   top_y:    2   width:   61   height:   16)\n",
      "car: 60%\t(left_x:  748   top_y:    5   width:   47   height:   22)\n",
      "car: 92%\t(left_x:  762   top_y:    3   width:  118   height:   60)\n",
      "car: 89%\t(left_x:  957   top_y:  115   width:  167   height:  143)\n",
      "car: 43%\t(left_x: 1026   top_y:   22   width:   61   height:   63)\n",
      "car: 79%\t(left_x: 1108   top_y:  265   width:   55   height:   54)\n",
      "person: 27%\t(left_x: 1127   top_y:  231   width:   11   height:   13)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02369_FV.png: Predicted in 144.792000 milli-seconds.\n",
      "car: 39%\t(left_x:   19   top_y:  623   width: 1266   height:  227)\n",
      "person: 66%\t(left_x:   74   top_y:  380   width:   42   height:   88)\n",
      "car: 94%\t(left_x:  289   top_y:  315   width:  212   height:  111)\n",
      "car: 87%\t(left_x:  479   top_y:  328   width:   75   height:   47)\n",
      "car: 82%\t(left_x:  582   top_y:  333   width:   35   height:   29)\n",
      "car: 31%\t(left_x:  607   top_y:  333   width:   15   height:   23)\n",
      "car: 39%\t(left_x:  610   top_y:  333   width:   21   height:   23)\n",
      "car: 25%\t(left_x:  619   top_y:  337   width:   14   height:   18)\n",
      "car: 80%\t(left_x:  626   top_y:  330   width:   48   height:   39)\n",
      "car: 60%\t(left_x:  673   top_y:  334   width:   16   height:   22)\n",
      "car: 80%\t(left_x:  685   top_y:  336   width:   39   height:   29)\n",
      "bicycle: 49%\t(left_x:  719   top_y:  335   width:   21   height:   42)\n",
      "bicycle: 43%\t(left_x:  731   top_y:  335   width:   21   height:   45)\n",
      "bicycle: 60%\t(left_x:  748   top_y:  332   width:   35   height:   56)\n",
      "bicycle: 36%\t(left_x:  763   top_y:  337   width:   34   height:   58)\n",
      "bicycle: 50%\t(left_x:  773   top_y:  333   width:   41   height:   67)\n",
      "bicycle: 55%\t(left_x:  780   top_y:  335   width:   51   height:   74)\n",
      "bicycle: 38%\t(left_x:  803   top_y:  342   width:   39   height:   69)\n",
      "bicycle: 32%\t(left_x:  813   top_y:  338   width:   49   height:   73)\n",
      "bicycle: 46%\t(left_x:  832   top_y:  332   width:   71   height:   83)\n",
      "bicycle: 53%\t(left_x:  863   top_y:  344   width:   62   height:   76)\n",
      "bicycle: 41%\t(left_x:  876   top_y:  352   width:   75   height:   68)\n",
      "bicycle: 43%\t(left_x:  905   top_y:  358   width:   53   height:   59)\n",
      "car: 74%\t(left_x:  944   top_y:  329   width:  176   height:  150)\n",
      "truck: 26%\t(left_x:  944   top_y:  329   width:  175   height:  151)\n",
      "truck: 68%\t(left_x: 1159   top_y:  437   width:   63   height:   69)\n",
      "car: 28%\t(left_x: 1159   top_y:  437   width:   62   height:   69)\n",
      "car: 42%\t(left_x: 1234   top_y:  492   width:   18   height:   12)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07633_MVR.png: Predicted in 145.004000 milli-seconds.\n",
      "person: 73%\t(left_x:   50   top_y:  743   width:  160   height:  106)\n",
      "person: 91%\t(left_x:   58   top_y:  297   width:  132   height:   89)\n",
      "person: 27%\t(left_x:   66   top_y:  729   width:   54   height:   30)\n",
      "car: 91%\t(left_x:  244   top_y:   83   width:  137   height:   92)\n",
      "car: 45%\t(left_x: 1106   top_y:  265   width:   51   height:   57)\n",
      "person: 26%\t(left_x: 1126   top_y:  232   width:   13   height:   16)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00442_RV.png: Predicted in 145.846000 milli-seconds.\n",
      "motorbike: 87%\t(left_x:   69   top_y:  329   width:  107   height:  188)\n",
      "motorbike: 87%\t(left_x:  140   top_y:  316   width:  104   height:  155)\n",
      "bicycle: 64%\t(left_x:  275   top_y:  322   width:   76   height:   78)\n",
      "bicycle: 75%\t(left_x:  321   top_y:  313   width:   69   height:   65)\n",
      "bicycle: 69%\t(left_x:  367   top_y:  301   width:   54   height:   60)\n",
      "bicycle: 57%\t(left_x:  399   top_y:  290   width:   40   height:   57)\n",
      "bicycle: 49%\t(left_x:  422   top_y:  285   width:   39   height:   51)\n",
      "bicycle: 31%\t(left_x:  424   top_y:  277   width:   54   height:   56)\n",
      "bicycle: 55%\t(left_x:  452   top_y:  278   width:   38   height:   46)\n",
      "bicycle: 39%\t(left_x:  468   top_y:  277   width:   39   height:   38)\n",
      "bicycle: 27%\t(left_x:  483   top_y:  277   width:   28   height:   34)\n",
      "bicycle: 44%\t(left_x:  488   top_y:  271   width:   32   height:   33)\n",
      "bicycle: 41%\t(left_x:  516   top_y:  263   width:   26   height:   35)\n",
      "bicycle: 62%\t(left_x:  540   top_y:  261   width:   31   height:   29)\n",
      "car: 89%\t(left_x:  584   top_y:  258   width:   57   height:   26)\n",
      "car: 54%\t(left_x:  672   top_y:  267   width:   20   height:   12)\n",
      "car: 46%\t(left_x:  690   top_y:  267   width:   17   height:   11)\n",
      "car: 29%\t(left_x:  720   top_y:  269   width:   11   height:   10)\n",
      "car: 62%\t(left_x:  774   top_y:  273   width:   19   height:   16)\n",
      "bicycle: 73%\t(left_x:  829   top_y:  284   width:   66   height:   96)\n",
      "person: 84%\t(left_x:  838   top_y:  236   width:   76   height:  140)\n",
      "person: 35%\t(left_x:  941   top_y:  311   width:    9   height:   19)\n",
      "person: 28%\t(left_x: 1010   top_y:  325   width:   22   height:   42)\n",
      "person: 58%\t(left_x: 1022   top_y:  322   width:   24   height:   47)\n",
      "person: 33%\t(left_x: 1156   top_y:  419   width:   20   height:   36)\n",
      "person: 52%\t(left_x: 1164   top_y:  420   width:   27   height:   45)\n",
      "person: 32%\t(left_x: 1187   top_y:  430   width:   33   height:   37)\n",
      "person: 30%\t(left_x: 1187   top_y:  439   width:   26   height:   36)\n",
      "person: 43%\t(left_x: 1197   top_y:  442   width:   38   height:   43)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06585_FV.png: Predicted in 143.415000 milli-seconds.\n",
      "car: 39%\t(left_x:    0   top_y:  517   width:   26   height:   69)\n",
      "car: 42%\t(left_x:    0   top_y:  458   width:   47   height:   55)\n",
      "truck: 88%\t(left_x:  255   top_y:  309   width:  101   height:   58)\n",
      "car: 92%\t(left_x:  494   top_y:  242   width:  154   height:  104)\n",
      "car: 80%\t(left_x:  632   top_y:  264   width:   28   height:   52)\n",
      "car: 93%\t(left_x:  719   top_y:  257   width:  157   height:  109)\n",
      "car: 86%\t(left_x:  884   top_y:  312   width:  157   height:   88)\n",
      "skateboard: 45%\t(left_x: 1038   top_y:  417   width:   22   height:   11)\n",
      "person: 90%\t(left_x: 1039   top_y:  334   width:   41   height:   91)\n",
      "traffic light: 26%\t(left_x: 1084   top_y:  228   width:   14   height:   16)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07944_FV.png: Predicted in 145.719000 milli-seconds.\n",
      "car: 63%\t(left_x:   31   top_y:  555   width:   52   height:   76)\n",
      "car: 92%\t(left_x:   62   top_y:  321   width:  175   height:  190)\n",
      "car: 91%\t(left_x:  209   top_y:  307   width:  161   height:   99)\n",
      "car: 59%\t(left_x:  349   top_y:  307   width:   44   height:   18)\n",
      "car: 73%\t(left_x:  363   top_y:  313   width:   79   height:   48)\n",
      "car: 80%\t(left_x:  386   top_y:  292   width:   99   height:   51)\n",
      "person: 34%\t(left_x:  570   top_y:  293   width:   12   height:   19)\n",
      "car: 55%\t(left_x:  650   top_y:  293   width:   22   height:    6)\n",
      "car: 56%\t(left_x:  683   top_y:  292   width:   19   height:   10)\n",
      "car: 94%\t(left_x:  724   top_y:  281   width:  198   height:   95)\n",
      "car: 92%\t(left_x:  907   top_y:  274   width:  244   height:  214)\n",
      "car: 50%\t(left_x: 1125   top_y:  378   width:   36   height:  115)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07874_RV.png: Predicted in 145.019000 milli-seconds.\n",
      "car: 58%\t(left_x:    2   top_y:  558   width: 1279   height:  398)\n",
      "car: 86%\t(left_x:  105   top_y:  248   width:  252   height:  215)\n",
      "person: 82%\t(left_x:  269   top_y:  197   width:   45   height:   64)\n",
      "car: 86%\t(left_x:  306   top_y:  201   width:  178   height:  111)\n",
      "car: 91%\t(left_x:  426   top_y:  176   width:  153   height:   56)\n",
      "car: 62%\t(left_x:  561   top_y:  180   width:   41   height:   25)\n",
      "car: 38%\t(left_x:  569   top_y:  177   width:   43   height:   23)\n",
      "car: 76%\t(left_x:  613   top_y:  179   width:   55   height:   21)\n",
      "car: 43%\t(left_x:  694   top_y:  185   width:   21   height:   15)\n",
      "car: 72%\t(left_x:  702   top_y:  186   width:   50   height:   19)\n",
      "car: 75%\t(left_x:  733   top_y:  186   width:   58   height:   24)\n",
      "car: 88%\t(left_x:  750   top_y:  194   width:  101   height:   41)\n",
      "car: 28%\t(left_x:  829   top_y:  201   width:   33   height:   13)\n",
      "car: 66%\t(left_x:  846   top_y:  211   width:   43   height:   25)\n",
      "car: 76%\t(left_x:  852   top_y:  219   width:   62   height:   55)\n",
      "car: 26%\t(left_x:  890   top_y:  161   width:   92   height:  184)\n",
      "person: 89%\t(left_x:  891   top_y:  160   width:   92   height:  185)\n",
      "car: 67%\t(left_x:  948   top_y:  234   width:   68   height:   77)\n",
      "skateboard: 39%\t(left_x:  966   top_y:  333   width:   26   height:   29)\n",
      "skateboard: 32%\t(left_x:  967   top_y:  335   width:   38   height:   35)\n",
      "person: 91%\t(left_x:  978   top_y:  223   width:  102   height:  154)\n",
      "car: 61%\t(left_x: 1046   top_y:  308   width:   32   height:   27)\n",
      "car: 83%\t(left_x: 1095   top_y:  342   width:   36   height:   33)\n",
      "car: 88%\t(left_x: 1120   top_y:  409   width:  131   height:  139)\n",
      "car: 36%\t(left_x: 1183   top_y:  388   width:   38   height:   38)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00245_FV.png: Predicted in 145.491000 milli-seconds.\n",
      "car: 60%\t(left_x:    6   top_y:  637   width: 1273   height:  318)\n",
      "car: 91%\t(left_x:  114   top_y:  409   width:  102   height:   62)\n",
      "car: 82%\t(left_x:  257   top_y:  380   width:   63   height:   39)\n",
      "car: 88%\t(left_x:  362   top_y:  355   width:   55   height:   33)\n",
      "car: 33%\t(left_x:  432   top_y:  349   width:   34   height:   18)\n",
      "car: 77%\t(left_x:  458   top_y:  349   width:   41   height:   19)\n",
      "car: 33%\t(left_x:  539   top_y:  344   width:   17   height:   11)\n",
      "traffic light: 51%\t(left_x:  547   top_y:  307   width:    9   height:   18)\n",
      "car: 46%\t(left_x:  624   top_y:  341   width:   14   height:   11)\n",
      "traffic light: 70%\t(left_x:  634   top_y:  265   width:   11   height:   18)\n",
      "traffic light: 71%\t(left_x:  682   top_y:  266   width:   10   height:   18)\n",
      "car: 69%\t(left_x:  684   top_y:  337   width:   33   height:   25)\n",
      "traffic light: 43%\t(left_x:  735   top_y:  303   width:   11   height:   19)\n",
      "car: 92%\t(left_x:  777   top_y:  331   width:  105   height:   57)\n",
      "bicycle: 51%\t(left_x:  907   top_y:  361   width:   22   height:   29)\n",
      "person: 52%\t(left_x:  919   top_y:  341   width:   12   height:   31)\n",
      "bicycle: 66%\t(left_x: 1025   top_y:  376   width:   42   height:   47)\n",
      "person: 42%\t(left_x: 1025   top_y:  355   width:   18   height:   50)\n",
      "bicycle: 29%\t(left_x: 1074   top_y:  395   width:   23   height:   45)\n",
      "bicycle: 44%\t(left_x: 1074   top_y:  394   width:   41   height:   49)\n",
      "bicycle: 33%\t(left_x: 1078   top_y:  394   width:   60   height:   53)\n",
      "bicycle: 40%\t(left_x: 1107   top_y:  397   width:   35   height:   59)\n",
      "bicycle: 81%\t(left_x: 1127   top_y:  402   width:   59   height:   65)\n",
      "car: 83%\t(left_x: 1181   top_y:  437   width:   98   height:  146)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04879_FV.png: Predicted in 143.556000 milli-seconds.\n",
      "car: 26%\t(left_x:   27   top_y:  630   width: 1252   height:  204)\n",
      "person: 51%\t(left_x:   94   top_y:  415   width:   28   height:   49)\n",
      "traffic light: 40%\t(left_x:  106   top_y:  357   width:   10   height:   22)\n",
      "person: 47%\t(left_x:  116   top_y:  410   width:   21   height:   39)\n",
      "traffic light: 38%\t(left_x:  127   top_y:  363   width:   10   height:   13)\n",
      "traffic light: 72%\t(left_x:  136   top_y:  342   width:   13   height:   34)\n",
      "person: 28%\t(left_x:  155   top_y:  394   width:   22   height:   39)\n",
      "backpack: 32%\t(left_x:  186   top_y:  348   width:   17   height:   28)\n",
      "person: 28%\t(left_x:  196   top_y:  397   width:   10   height:   27)\n",
      "person: 27%\t(left_x:  284   top_y:  371   width:   12   height:   24)\n",
      "person: 25%\t(left_x:  320   top_y:  371   width:    8   height:   15)\n",
      "traffic light: 80%\t(left_x:  334   top_y:  239   width:   25   height:   56)\n",
      "kite: 45%\t(left_x:  342   top_y:   51   width:   23   height:   18)\n",
      "traffic light: 45%\t(left_x:  352   top_y:  339   width:   11   height:   25)\n",
      "traffic light: 69%\t(left_x:  359   top_y:  259   width:   19   height:   31)\n",
      "car: 44%\t(left_x:  373   top_y:  287   width:  177   height:  115)\n",
      "truck: 59%\t(left_x:  373   top_y:  287   width:  174   height:  116)\n",
      "car: 51%\t(left_x:  547   top_y:  347   width:   17   height:   10)\n",
      "person: 30%\t(left_x:  596   top_y:  338   width:   12   height:   25)\n",
      "car: 86%\t(left_x:  624   top_y:  330   width:   42   height:   34)\n",
      "person: 54%\t(left_x:  665   top_y:  336   width:    9   height:   19)\n",
      "person: 31%\t(left_x:  709   top_y:  331   width:    8   height:   23)\n",
      "person: 34%\t(left_x:  720   top_y:  323   width:   11   height:   37)\n",
      "traffic light: 83%\t(left_x:  726   top_y:  242   width:   28   height:   49)\n",
      "person: 74%\t(left_x:  755   top_y:  323   width:   17   height:   45)\n",
      "bicycle: 32%\t(left_x:  798   top_y:  344   width:   23   height:   23)\n",
      "motorbike: 79%\t(left_x:  844   top_y:  339   width:   84   height:   51)\n",
      "bicycle: 90%\t(left_x:  938   top_y:  330   width:  127   height:  131)\n",
      "person: 31%\t(left_x:  940   top_y:  329   width:  125   height:  132)\n",
      "person: 88%\t(left_x:  973   top_y:  266   width:   70   height:  148)\n",
      "motorbike: 86%\t(left_x: 1099   top_y:  330   width:  134   height:  175)\n",
      "bicycle: 66%\t(left_x: 1227   top_y:  441   width:   53   height:  138)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01997_FV.png: Predicted in 146.525000 milli-seconds.\n",
      "car: 56%\t(left_x:    2   top_y:  511   width: 1281   height:  439)\n",
      "bicycle: 29%\t(left_x:   23   top_y:  477   width:   37   height:   38)\n",
      "bicycle: 35%\t(left_x:   59   top_y:  459   width:   26   height:   41)\n",
      "bicycle: 35%\t(left_x:   85   top_y:  447   width:   36   height:   35)\n",
      "bicycle: 26%\t(left_x:  153   top_y:  421   width:   32   height:   34)\n",
      "bicycle: 32%\t(left_x:  180   top_y:  410   width:   27   height:   31)\n",
      "car: 81%\t(left_x:  208   top_y:  375   width:   86   height:   56)\n",
      "car: 90%\t(left_x:  291   top_y:  366   width:   67   height:   39)\n",
      "car: 88%\t(left_x:  507   top_y:  324   width:   64   height:   47)\n",
      "car: 81%\t(left_x:  564   top_y:  332   width:   25   height:   26)\n",
      "car: 54%\t(left_x:  585   top_y:  334   width:   16   height:   18)\n",
      "traffic light: 29%\t(left_x:  593   top_y:  150   width:   15   height:   10)\n",
      "car: 35%\t(left_x:  601   top_y:  337   width:   12   height:   10)\n",
      "car: 58%\t(left_x:  611   top_y:  332   width:   31   height:   25)\n",
      "truck: 34%\t(left_x:  611   top_y:  332   width:   30   height:   24)\n",
      "person: 38%\t(left_x:  690   top_y:  325   width:    9   height:   24)\n",
      "person: 37%\t(left_x:  699   top_y:  326   width:   10   height:   25)\n",
      "bicycle: 39%\t(left_x:  854   top_y:  336   width:   33   height:   34)\n",
      "motorbike: 33%\t(left_x:  884   top_y:  344   width:   47   height:   33)\n",
      "bicycle: 26%\t(left_x:  888   top_y:  345   width:   43   height:   32)\n",
      "motorbike: 39%\t(left_x: 1000   top_y:  353   width:   63   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00369_RV.png: Predicted in 144.534000 milli-seconds.\n",
      "car: 25%\t(left_x:    1   top_y:  488   width: 1281   height:  463)\n",
      "bicycle: 83%\t(left_x:  220   top_y:  318   width:  131   height:  141)\n",
      "person: 88%\t(left_x:  237   top_y:  252   width:   75   height:  152)\n",
      "backpack: 61%\t(left_x:  313   top_y:  313   width:   43   height:   53)\n",
      "bicycle: 75%\t(left_x:  362   top_y:  284   width:   30   height:   52)\n",
      "bicycle: 64%\t(left_x:  516   top_y:  263   width:   25   height:   40)\n",
      "person: 49%\t(left_x:  520   top_y:  245   width:   18   height:   50)\n",
      "car: 61%\t(left_x:  617   top_y:  256   width:   28   height:   21)\n",
      "truck: 26%\t(left_x:  617   top_y:  257   width:   28   height:   21)\n",
      "car: 30%\t(left_x:  680   top_y:  256   width:   14   height:   15)\n",
      "car: 50%\t(left_x:  693   top_y:  255   width:   24   height:   20)\n",
      "car: 33%\t(left_x:  707   top_y:  256   width:   23   height:   19)\n",
      "car: 50%\t(left_x:  717   top_y:  259   width:   36   height:   22)\n",
      "car: 51%\t(left_x:  743   top_y:  252   width:   55   height:   34)\n",
      "car: 65%\t(left_x:  768   top_y:  262   width:   74   height:   35)\n",
      "car: 72%\t(left_x:  795   top_y:  270   width:   92   height:   39)\n",
      "car: 92%\t(left_x:  836   top_y:  276   width:  139   height:   77)\n",
      "bicycle: 80%\t(left_x: 1047   top_y:  350   width:   63   height:   66)\n",
      "car: 87%\t(left_x: 1130   top_y:  390   width:  139   height:  165)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08122_MVL.png: Predicted in 145.020000 milli-seconds.\n",
      "car: 28%\t(left_x:  113   top_y:  269   width:   43   height:   48)\n",
      "person: 88%\t(left_x: 1044   top_y:  384   width:  234   height:  215)\n",
      "person: 88%\t(left_x: 1062   top_y:  630   width:  134   height:  118)\n",
      "car: 77%\t(left_x: 1102   top_y:  275   width:  110   height:  172)\n",
      "umbrella: 28%\t(left_x: 1221   top_y:  298   width:   58   height:  133)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06384_RV.png: Predicted in 145.606000 milli-seconds.\n",
      "kite: 46%\t(left_x:  234   top_y:  377   width:   95   height:  143)\n",
      "car: 92%\t(left_x:  266   top_y:  239   width:  107   height:   63)\n",
      "person: 32%\t(left_x:  541   top_y:  193   width:   12   height:   29)\n",
      "bus: 78%\t(left_x:  561   top_y:  135   width:   92   height:   95)\n",
      "car: 53%\t(left_x:  760   top_y:  194   width:   29   height:   14)\n",
      "car: 26%\t(left_x:  780   top_y:  193   width:   13   height:   13)\n",
      "car: 88%\t(left_x: 1117   top_y:  382   width:  120   height:  139)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08179_FV.png: Predicted in 145.072000 milli-seconds.\n",
      "car: 82%\t(left_x:    4   top_y:  457   width:   50   height:   69)\n",
      "person: 91%\t(left_x:    9   top_y:  337   width:  145   height:  266)\n",
      "car: 94%\t(left_x:  124   top_y:  320   width:  224   height:  134)\n",
      "car: 90%\t(left_x:  280   top_y:  304   width:  109   height:   61)\n",
      "person: 94%\t(left_x:  312   top_y:   55   width:  324   height:  515)\n",
      "umbrella: 40%\t(left_x:  334   top_y:   57   width:  380   height:  164)\n",
      "umbrella: 30%\t(left_x:  525   top_y:   57   width:  189   height:  165)\n",
      "car: 89%\t(left_x:  589   top_y:  274   width:   85   height:   69)\n",
      "car: 89%\t(left_x:  704   top_y:  285   width:  123   height:   76)\n",
      "car: 92%\t(left_x:  802   top_y:  301   width:  118   height:   75)\n",
      "fire hydrant: 45%\t(left_x:  944   top_y:  352   width:   18   height:   27)\n",
      "car: 81%\t(left_x:  973   top_y:  355   width:   93   height:   62)\n",
      "car: 31%\t(left_x: 1049   top_y:  388   width:   31   height:   33)\n",
      "car: 62%\t(left_x: 1055   top_y:  389   width:   40   height:   39)\n",
      "traffic light: 34%\t(left_x: 1078   top_y:  342   width:   10   height:   13)\n",
      "car: 50%\t(left_x: 1090   top_y:  411   width:   21   height:   24)\n",
      "car: 51%\t(left_x: 1108   top_y:  413   width:   40   height:   36)\n",
      "truck: 37%\t(left_x: 1119   top_y:  418   width:   47   height:   56)\n",
      "car: 58%\t(left_x: 1120   top_y:  418   width:   47   height:   56)\n",
      "car: 28%\t(left_x: 1150   top_y:  414   width:   27   height:   28)\n",
      "car: 39%\t(left_x: 1171   top_y:  462   width:   16   height:   26)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06439_MVR.png: Predicted in 144.131000 milli-seconds.\n",
      "person: 77%\t(left_x:   -0   top_y:  487   width:  230   height:  124)\n",
      "car: 33%\t(left_x:  145   top_y:   57   width: 1028   height:  859)\n",
      "car: 51%\t(left_x:  279   top_y:  114   width:   21   height:   21)\n",
      "car: 92%\t(left_x:  335   top_y:   23   width:  190   height:   90)\n",
      "person: 86%\t(left_x:  508   top_y:    3   width:  139   height:  243)\n",
      "car: 86%\t(left_x:  628   top_y:    3   width:  328   height:  236)\n",
      "person: 29%\t(left_x: 1127   top_y:  234   width:   13   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00837_MVR.png: Predicted in 145.354000 milli-seconds.\n",
      "car: 86%\t(left_x:   15   top_y:  380   width:  163   height:  273)\n",
      "car: 29%\t(left_x:  164   top_y:   17   width: 1106   height:  934)\n",
      "bicycle: 84%\t(left_x:  275   top_y:   58   width:  138   height:  124)\n",
      "car: 95%\t(left_x:  440   top_y:    4   width:  555   height:  242)\n",
      "bicycle: 83%\t(left_x:  467   top_y:    2   width:  165   height:   67)\n",
      "car: 31%\t(left_x:  999   top_y:  111   width:   54   height:   34)\n",
      "car: 35%\t(left_x: 1055   top_y:   47   width:   95   height:  102)\n",
      "car: 66%\t(left_x: 1101   top_y:  285   width:   65   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07440_FV.png: Predicted in 145.577000 milli-seconds.\n",
      "truck: 57%\t(left_x:    3   top_y:  378   width:   88   height:  185)\n",
      "car: 27%\t(left_x:    5   top_y:  376   width:   88   height:  184)\n",
      "truck: 27%\t(left_x:  304   top_y:  312   width:   46   height:   58)\n",
      "truck: 36%\t(left_x:  358   top_y:  332   width:   64   height:   34)\n",
      "car: 62%\t(left_x:  358   top_y:  332   width:   63   height:   35)\n",
      "car: 44%\t(left_x:  514   top_y:  300   width:   68   height:   48)\n",
      "truck: 65%\t(left_x:  514   top_y:  295   width:   68   height:   54)\n",
      "car: 73%\t(left_x:  569   top_y:  306   width:   62   height:   40)\n",
      "truck: 27%\t(left_x:  569   top_y:  306   width:   62   height:   40)\n",
      "stop sign: 38%\t(left_x:  752   top_y:  249   width:   24   height:   39)\n",
      "person: 89%\t(left_x:  932   top_y:  192   width:  230   height:  424)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02272_RV.png: Predicted in 144.257000 milli-seconds.\n",
      "car: 94%\t(left_x:   89   top_y:  214   width:  363   height:  337)\n",
      "car: 82%\t(left_x:  449   top_y:  235   width:  119   height:   87)\n",
      "person: 76%\t(left_x:  615   top_y:  251   width:   13   height:   22)\n",
      "truck: 44%\t(left_x:  706   top_y:  250   width:   50   height:   29)\n",
      "motorbike: 46%\t(left_x:  773   top_y:  268   width:   33   height:   21)\n",
      "car: 45%\t(left_x: 1042   top_y:  337   width:   59   height:   58)\n",
      "truck: 55%\t(left_x: 1042   top_y:  337   width:   59   height:   58)\n",
      "bicycle: 48%\t(left_x: 1074   top_y:  384   width:   36   height:   52)\n",
      "bicycle: 78%\t(left_x: 1111   top_y:  385   width:   53   height:   75)\n",
      "car: 76%\t(left_x: 1170   top_y:  437   width:   53   height:   59)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03939_FV.png: Predicted in 144.239000 milli-seconds.\n",
      "car: 29%\t(left_x:    7   top_y:  522   width: 1264   height:  372)\n",
      "bicycle: 26%\t(left_x:   25   top_y:  424   width:   56   height:   77)\n",
      "bicycle: 25%\t(left_x:   36   top_y:  449   width:   37   height:   53)\n",
      "toothbrush: 25%\t(left_x:   53   top_y:  665   width: 1202   height:  174)\n",
      "bicycle: 32%\t(left_x:   55   top_y:  418   width:   47   height:   75)\n",
      "bicycle: 40%\t(left_x:   74   top_y:  414   width:   34   height:   64)\n",
      "bicycle: 44%\t(left_x:   82   top_y:  408   width:   44   height:   63)\n",
      "bicycle: 49%\t(left_x:   97   top_y:  405   width:   46   height:   62)\n",
      "bicycle: 41%\t(left_x:  111   top_y:  405   width:   46   height:   57)\n",
      "bicycle: 38%\t(left_x:  134   top_y:  405   width:   41   height:   53)\n",
      "bicycle: 41%\t(left_x:  147   top_y:  407   width:   38   height:   47)\n",
      "bicycle: 40%\t(left_x:  163   top_y:  409   width:   43   height:   41)\n",
      "bicycle: 66%\t(left_x:  182   top_y:  390   width:   34   height:   50)\n",
      "bicycle: 59%\t(left_x:  202   top_y:  387   width:   36   height:   49)\n",
      "bicycle: 56%\t(left_x:  208   top_y:  386   width:   46   height:   45)\n",
      "motorbike: 61%\t(left_x:  261   top_y:  377   width:   49   height:   41)\n",
      "car: 89%\t(left_x:  390   top_y:  343   width:   78   height:   40)\n",
      "person: 57%\t(left_x:  394   top_y:  345   width:   10   height:   19)\n",
      "car: 37%\t(left_x:  597   top_y:  339   width:   13   height:    8)\n",
      "car: 80%\t(left_x:  663   top_y:  335   width:   21   height:   17)\n",
      "car: 56%\t(left_x:  695   top_y:  333   width:   21   height:   23)\n",
      "car: 86%\t(left_x:  709   top_y:  324   width:   54   height:   46)\n",
      "car: 92%\t(left_x:  736   top_y:  302   width:  158   height:  107)\n",
      "car: 56%\t(left_x:  868   top_y:  160   width:  412   height:  452)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06955_FV.png: Predicted in 146.713000 milli-seconds.\n",
      "car: 94%\t(left_x:  328   top_y:  295   width:  172   height:   94)\n",
      "car: 82%\t(left_x:  477   top_y:  295   width:  124   height:   49)\n",
      "person: 28%\t(left_x:  482   top_y:  287   width:  108   height:   61)\n",
      "person: 86%\t(left_x:  503   top_y:  265   width:   29   height:   93)\n",
      "car: 88%\t(left_x:  563   top_y:  297   width:   75   height:   34)\n",
      "car: 56%\t(left_x: 1072   top_y:  586   width:  126   height:  111)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07933_MVL.png: Predicted in 145.466000 milli-seconds.\n",
      "motorbike: 34%\t(left_x:    2   top_y:   33   width: 1279   height:  922)\n",
      "car: 29%\t(left_x:    2   top_y:   33   width: 1279   height:  922)\n",
      "car: 79%\t(left_x:  161   top_y:  153   width:   58   height:   59)\n",
      "car: 33%\t(left_x:  241   top_y:   96   width:   35   height:   36)\n",
      "car: 29%\t(left_x:  372   top_y:   12   width:   38   height:   31)\n",
      "car: 73%\t(left_x:  386   top_y:    3   width:   61   height:   39)\n",
      "car: 89%\t(left_x:  401   top_y:    3   width:  174   height:   52)\n",
      "car: 41%\t(left_x:  570   top_y:    2   width:   56   height:    9)\n",
      "car: 83%\t(left_x:  638   top_y:    2   width:  123   height:   31)\n",
      "car: 93%\t(left_x:  767   top_y:   12   width:  323   height:  264)\n",
      "car: 51%\t(left_x:  774   top_y:    8   width:   24   height:   21)\n",
      "car: 89%\t(left_x: 1062   top_y:  276   width:  212   height:  399)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04698_FV.png: Predicted in 146.171000 milli-seconds.\n",
      "car: 49%\t(left_x:   -1   top_y:  563   width: 1278   height:  329)\n",
      "car: 84%\t(left_x:  245   top_y:  335   width:  166   height:   94)\n",
      "car: 82%\t(left_x:  489   top_y:  338   width:   58   height:   32)\n",
      "car: 57%\t(left_x:  548   top_y:  311   width:   58   height:   52)\n",
      "truck: 26%\t(left_x:  548   top_y:  312   width:   58   height:   52)\n",
      "car: 57%\t(left_x:  605   top_y:  340   width:   12   height:   10)\n",
      "car: 73%\t(left_x:  626   top_y:  337   width:   19   height:   16)\n",
      "car: 64%\t(left_x:  647   top_y:  340   width:   14   height:   10)\n",
      "car: 39%\t(left_x:  664   top_y:  341   width:   11   height:    8)\n",
      "car: 72%\t(left_x:  696   top_y:  340   width:   21   height:   16)\n",
      "car: 27%\t(left_x:  714   top_y:  339   width:   22   height:   22)\n",
      "car: 28%\t(left_x:  731   top_y:  328   width:   32   height:   38)\n",
      "car: 29%\t(left_x:  732   top_y:  343   width:   17   height:   25)\n",
      "car: 78%\t(left_x:  741   top_y:  328   width:   64   height:   51)\n",
      "bicycle: 58%\t(left_x:  989   top_y:  340   width:   60   height:  101)\n",
      "bicycle: 49%\t(left_x: 1004   top_y:  335   width:   79   height:  113)\n",
      "bicycle: 58%\t(left_x: 1038   top_y:  336   width:   55   height:  119)\n",
      "bicycle: 63%\t(left_x: 1068   top_y:  337   width:   67   height:  126)\n",
      "bicycle: 65%\t(left_x: 1096   top_y:  348   width:   60   height:  130)\n",
      "bicycle: 51%\t(left_x: 1121   top_y:  348   width:   70   height:  135)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07660_MVR.png: Predicted in 145.798000 milli-seconds.\n",
      "person: 31%\t(left_x:   89   top_y:  366   width:   23   height:   39)\n",
      "car: 70%\t(left_x:  128   top_y:  127   width:  157   height:  202)\n",
      "car: 64%\t(left_x:  136   top_y:   41   width:  348   height:  281)\n",
      "car: 63%\t(left_x:  252   top_y:   40   width:  229   height:  193)\n",
      "person: 32%\t(left_x:  795   top_y:    3   width:   16   height:   22)\n",
      "person: 78%\t(left_x:  887   top_y:    9   width:   91   height:  162)\n",
      "car: 29%\t(left_x:  888   top_y:   10   width:   91   height:  161)\n",
      "skateboard: 39%\t(left_x:  905   top_y:  150   width:   51   height:   32)\n",
      "car: 73%\t(left_x:  939   top_y:   75   width:   91   height:   85)\n",
      "skateboard: 36%\t(left_x:  975   top_y:  168   width:   29   height:   28)\n",
      "person: 75%\t(left_x:  977   top_y:  110   width:   73   height:   84)\n",
      "person: 35%\t(left_x: 1052   top_y:  319   width:   92   height:   86)\n",
      "person: 39%\t(left_x: 1053   top_y:  157   width:   38   height:   31)\n",
      "person: 47%\t(left_x: 1061   top_y:  390   width:   67   height:   47)\n",
      "person: 52%\t(left_x: 1065   top_y:   40   width:   47   height:   58)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03573_MVL.png: Predicted in 145.034000 milli-seconds.\n",
      "car: 55%\t(left_x:    8   top_y:  243   width: 1113   height:  706)\n",
      "car: 72%\t(left_x:  118   top_y:  279   width:   61   height:   53)\n",
      "car: 80%\t(left_x:  305   top_y:   53   width:   68   height:   58)\n",
      "truck: 87%\t(left_x:  405   top_y:    3   width:  124   height:   71)\n",
      "person: 28%\t(left_x:  555   top_y:   16   width:   40   height:   28)\n",
      "bicycle: 74%\t(left_x:  555   top_y:   18   width:   42   height:   27)\n",
      "bicycle: 56%\t(left_x:  609   top_y:   15   width:   23   height:   25)\n",
      "person: 27%\t(left_x:  610   top_y:   14   width:   21   height:   26)\n",
      "person: 38%\t(left_x:  745   top_y:   27   width:   22   height:   44)\n",
      "bicycle: 42%\t(left_x:  773   top_y:   32   width:   35   height:   46)\n",
      "bicycle: 63%\t(left_x:  814   top_y:   50   width:   41   height:   44)\n",
      "person: 34%\t(left_x:  903   top_y:   91   width:   26   height:   41)\n",
      "bicycle: 34%\t(left_x:  937   top_y:  121   width:   34   height:   37)\n",
      "bicycle: 49%\t(left_x:  953   top_y:  129   width:   41   height:   38)\n",
      "person: 47%\t(left_x: 1042   top_y:  205   width:   35   height:   34)\n",
      "person: 34%\t(left_x: 1063   top_y:  228   width:   34   height:   35)\n",
      "person: 42%\t(left_x: 1079   top_y:  240   width:   36   height:   40)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06142_MVL.png: Predicted in 145.185000 milli-seconds.\n",
      "car: 89%\t(left_x:  170   top_y:    5   width:  751   height:  364)\n",
      "person: 89%\t(left_x:  908   top_y:  145   width:  332   height:  348)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00087_RV.png: Predicted in 144.609000 milli-seconds.\n",
      "car: 36%\t(left_x:   -1   top_y:   32   width: 1280   height:  913)\n",
      "car: 89%\t(left_x:   26   top_y:  397   width:  159   height:  133)\n",
      "car: 86%\t(left_x:  194   top_y:  320   width:  121   height:   83)\n",
      "car: 91%\t(left_x:  305   top_y:  294   width:   84   height:   56)\n",
      "car: 70%\t(left_x:  455   top_y:  276   width:   41   height:   16)\n",
      "car: 29%\t(left_x:  549   top_y:  262   width:   13   height:   18)\n",
      "car: 94%\t(left_x:  555   top_y:  233   width:  124   height:   92)\n",
      "car: 86%\t(left_x:  668   top_y:  244   width:   80   height:   47)\n",
      "car: 91%\t(left_x:  743   top_y:  244   width:  102   height:   74)\n",
      "car: 93%\t(left_x:  839   top_y:  246   width:  242   height:  171)\n",
      "person: 35%\t(left_x:  959   top_y:  279   width:   23   height:   29)\n",
      "person: 28%\t(left_x:  959   top_y:  281   width:   36   height:   35)\n",
      "car: 87%\t(left_x: 1117   top_y:  337   width:  161   height:  239)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01343_MVL.png: Predicted in 144.664000 milli-seconds.\n",
      "car: 33%\t(left_x:    0   top_y:   60   width: 1245   height:  875)\n",
      "car: 36%\t(left_x:  118   top_y:  280   width:   60   height:   50)\n",
      "person: 29%\t(left_x:  326   top_y:   67   width:   15   height:   22)\n",
      "car: 91%\t(left_x:  361   top_y:   28   width:  108   height:   58)\n",
      "car: 93%\t(left_x:  527   top_y:    2   width:  197   height:   63)\n",
      "car: 93%\t(left_x:  805   top_y:   61   width:  187   height:  122)\n",
      "bicycle: 48%\t(left_x: 1045   top_y:  214   width:   41   height:   39)\n",
      "bicycle: 29%\t(left_x: 1051   top_y:  216   width:   54   height:   42)\n",
      "bicycle: 54%\t(left_x: 1059   top_y:  221   width:   49   height:   56)\n",
      "bicycle: 30%\t(left_x: 1063   top_y:  241   width:   43   height:   38)\n",
      "bicycle: 43%\t(left_x: 1071   top_y:  246   width:   47   height:   36)\n",
      "bicycle: 57%\t(left_x: 1086   top_y:  262   width:   52   height:   41)\n",
      "bicycle: 29%\t(left_x: 1098   top_y:  273   width:   50   height:   53)\n",
      "bicycle: 48%\t(left_x: 1102   top_y:  298   width:   55   height:   39)\n",
      "bicycle: 27%\t(left_x: 1116   top_y:  323   width:   35   height:   35)\n",
      "bicycle: 57%\t(left_x: 1117   top_y:  316   width:   57   height:   42)\n",
      "bicycle: 27%\t(left_x: 1126   top_y:  323   width:   53   height:   43)\n",
      "bicycle: 54%\t(left_x: 1141   top_y:  344   width:   48   height:   42)\n",
      "person: 40%\t(left_x: 1142   top_y:  751   width:   74   height:   60)\n",
      "person: 45%\t(left_x: 1204   top_y:  580   width:   38   height:   21)\n",
      "traffic light: 41%\t(left_x: 1238   top_y:  485   width:   10   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00023_FV.png: Predicted in 143.651000 milli-seconds.\n",
      "person: 40%\t(left_x:  118   top_y:  201   width:   16   height:   53)\n",
      "person: 85%\t(left_x:  410   top_y:  307   width:   31   height:   83)\n",
      "handbag: 31%\t(left_x:  411   top_y:  317   width:   17   height:   34)\n",
      "car: 92%\t(left_x:  483   top_y:  315   width:  100   height:   62)\n",
      "car: 78%\t(left_x:  568   top_y:  325   width:   42   height:   31)\n",
      "car: 56%\t(left_x:  603   top_y:  330   width:   17   height:   22)\n",
      "car: 38%\t(left_x:  610   top_y:  331   width:   17   height:   20)\n",
      "truck: 29%\t(left_x:  634   top_y:  325   width:   23   height:   22)\n",
      "car: 39%\t(left_x:  635   top_y:  327   width:   25   height:   22)\n",
      "car: 64%\t(left_x:  642   top_y:  333   width:   21   height:   17)\n",
      "car: 76%\t(left_x:  680   top_y:  331   width:   34   height:   25)\n",
      "person: 44%\t(left_x:  750   top_y:  342   width:   11   height:   14)\n",
      "person: 88%\t(left_x:  890   top_y:  339   width:   22   height:   55)\n",
      "person: 84%\t(left_x:  954   top_y:  339   width:   34   height:   91)\n",
      "person: 85%\t(left_x: 1113   top_y:  342   width:   58   height:  171)\n",
      "person: 43%\t(left_x: 1140   top_y:  349   width:   36   height:  160)\n",
      "person: 88%\t(left_x: 1173   top_y:  394   width:   67   height:  139)\n",
      "person: 54%\t(left_x: 1214   top_y:  417   width:   65   height:  142)\n",
      "skateboard: 34%\t(left_x: 1215   top_y:  536   width:   31   height:   26)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04269_MVL.png: Predicted in 144.386000 milli-seconds.\n",
      "car: 31%\t(left_x:    1   top_y:   12   width: 1277   height:  939)\n",
      "car: 74%\t(left_x:  173   top_y:  151   width:   74   height:   67)\n",
      "car: 91%\t(left_x:  235   top_y:   43   width:  192   height:  146)\n",
      "car: 94%\t(left_x:  418   top_y:    3   width:  648   height:  353)\n",
      "parking meter: 35%\t(left_x: 1090   top_y:  321   width:  170   height:  287)\n",
      "car: 30%\t(left_x: 1091   top_y:  321   width:  170   height:  286)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01304_FV.png: Predicted in 145.236000 milli-seconds.\n",
      "car: 64%\t(left_x:    4   top_y:  454   width: 1277   height:  510)\n",
      "car: 92%\t(left_x:   68   top_y:  384   width:  150   height:   90)\n",
      "traffic light: 33%\t(left_x:  323   top_y:  307   width:   10   height:   25)\n",
      "bicycle: 64%\t(left_x:  331   top_y:  362   width:   46   height:   27)\n",
      "person: 26%\t(left_x:  332   top_y:  361   width:   43   height:   28)\n",
      "person: 35%\t(left_x:  335   top_y:  350   width:   14   height:   33)\n",
      "person: 32%\t(left_x:  355   top_y:  350   width:   10   height:   20)\n",
      "bicycle: 41%\t(left_x:  380   top_y:  356   width:   16   height:   14)\n",
      "car: 26%\t(left_x:  503   top_y:  344   width:   19   height:   12)\n",
      "car: 57%\t(left_x:  506   top_y:  343   width:   30   height:   12)\n",
      "car: 43%\t(left_x:  541   top_y:  342   width:   17   height:   12)\n",
      "car: 31%\t(left_x:  631   top_y:  338   width:   11   height:   10)\n",
      "bicycle: 39%\t(left_x:  779   top_y:  348   width:   14   height:   21)\n",
      "person: 76%\t(left_x:  780   top_y:  328   width:   15   height:   41)\n",
      "bicycle: 85%\t(left_x:  871   top_y:  329   width:   93   height:  104)\n",
      "person: 35%\t(left_x:  874   top_y:  316   width:   89   height:  116)\n",
      "person: 85%\t(left_x:  895   top_y:  282   width:   65   height:  123)\n",
      "bicycle: 80%\t(left_x:  956   top_y:  350   width:  100   height:  108)\n",
      "person: 86%\t(left_x:  974   top_y:  293   width:   72   height:  140)\n",
      "handbag: 44%\t(left_x: 1029   top_y:  318   width:   23   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01731_FV.png: Predicted in 145.254000 milli-seconds.\n",
      "car: 44%\t(left_x:   10   top_y:  541   width: 1274   height:  380)\n",
      "truck: 25%\t(left_x:   34   top_y:  453   width:   33   height:   39)\n",
      "car: 63%\t(left_x:  132   top_y:  414   width:   36   height:   35)\n",
      "traffic light: 29%\t(left_x:  142   top_y:  187   width:   14   height:   14)\n",
      "traffic light: 61%\t(left_x:  231   top_y:  350   width:   12   height:   23)\n",
      "car: 71%\t(left_x:  329   top_y:  372   width:   31   height:   17)\n",
      "car: 74%\t(left_x:  418   top_y:  358   width:   29   height:   15)\n",
      "car: 46%\t(left_x:  431   top_y:  357   width:   26   height:   14)\n",
      "traffic light: 39%\t(left_x:  433   top_y:  307   width:   10   height:   13)\n",
      "traffic light: 43%\t(left_x:  456   top_y:  334   width:    6   height:   13)\n",
      "car: 55%\t(left_x:  458   top_y:  356   width:   19   height:   12)\n",
      "bus: 71%\t(left_x:  557   top_y:  330   width:   45   height:   30)\n",
      "truck: 43%\t(left_x:  609   top_y:  319   width:   50   height:   51)\n",
      "car: 36%\t(left_x:  609   top_y:  319   width:   50   height:   50)\n",
      "car: 40%\t(left_x:  668   top_y:  338   width:   22   height:   22)\n",
      "truck: 25%\t(left_x:  669   top_y:  338   width:   21   height:   22)\n",
      "bicycle: 36%\t(left_x:  786   top_y:  347   width:   31   height:   32)\n",
      "person: 71%\t(left_x:  819   top_y:  320   width:   21   height:   60)\n",
      "bicycle: 32%\t(left_x:  836   top_y:  357   width:   34   height:   31)\n",
      "bicycle: 75%\t(left_x:  849   top_y:  345   width:   77   height:   62)\n",
      "person: 30%\t(left_x:  856   top_y:  338   width:   64   height:   68)\n",
      "bicycle: 34%\t(left_x:  866   top_y:  309   width:   44   height:   92)\n",
      "person: 80%\t(left_x:  869   top_y:  307   width:   35   height:   89)\n",
      "bicycle: 75%\t(left_x:  921   top_y:  354   width:   55   height:   60)\n",
      "person: 32%\t(left_x:  923   top_y:  350   width:   51   height:   64)\n",
      "person: 67%\t(left_x:  934   top_y:  324   width:   37   height:   80)\n",
      "person: 60%\t(left_x:  970   top_y:  354   width:   22   height:   55)\n",
      "person: 58%\t(left_x:  985   top_y:  352   width:   13   height:   34)\n",
      "car: 89%\t(left_x: 1012   top_y:  385   width:   71   height:   35)\n",
      "bicycle: 90%\t(left_x: 1083   top_y:  398   width:  115   height:  107)\n",
      "person: 90%\t(left_x: 1121   top_y:  351   width:   68   height:  122)\n",
      "car: 50%\t(left_x: 1218   top_y:  453   width:   22   height:   15)\n",
      "bicycle: 53%\t(left_x: 1236   top_y:  473   width:   43   height:   96)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02556_FV.png: Predicted in 145.136000 milli-seconds.\n",
      "car: 31%\t(left_x:    1   top_y:  423   width: 1274   height:  543)\n",
      "car: 91%\t(left_x:   10   top_y:  361   width:  235   height:  204)\n",
      "car: 31%\t(left_x:  361   top_y:  363   width:   30   height:   15)\n",
      "car: 94%\t(left_x:  413   top_y:  311   width:  146   height:   93)\n",
      "car: 85%\t(left_x:  557   top_y:  333   width:   44   height:   32)\n",
      "bus: 93%\t(left_x:  604   top_y:  264   width:   82   height:  103)\n",
      "bicycle: 44%\t(left_x:  722   top_y:  339   width:   25   height:   30)\n",
      "bicycle: 39%\t(left_x:  727   top_y:  340   width:   33   height:   30)\n",
      "bicycle: 49%\t(left_x:  747   top_y:  342   width:   21   height:   29)\n",
      "bicycle: 34%\t(left_x:  748   top_y:  337   width:   31   height:   35)\n",
      "bicycle: 59%\t(left_x:  763   top_y:  336   width:   31   height:   39)\n",
      "bicycle: 38%\t(left_x:  777   top_y:  335   width:   26   height:   43)\n",
      "bicycle: 66%\t(left_x:  781   top_y:  334   width:   36   height:   47)\n",
      "bicycle: 36%\t(left_x:  803   top_y:  336   width:   29   height:   49)\n",
      "bicycle: 71%\t(left_x:  804   top_y:  341   width:   56   height:   47)\n",
      "car: 80%\t(left_x: 1155   top_y:  420   width:   47   height:   46)\n",
      "car: 40%\t(left_x: 1220   top_y:  453   width:   24   height:   23)\n",
      "car: 69%\t(left_x: 1236   top_y:  455   width:   44   height:   38)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07328_MVR.png: Predicted in 144.262000 milli-seconds.\n",
      "person: 41%\t(left_x:   -0   top_y:  376   width:  175   height:  564)\n",
      "aeroplane: 30%\t(left_x:  171   top_y:   35   width: 1098   height:  908)\n",
      "person: 40%\t(left_x:  302   top_y:  831   width:   73   height:   98)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02608_RV.png: Predicted in 144.180000 milli-seconds.\n",
      "person: 53%\t(left_x:  296   top_y:  285   width:   11   height:   29)\n",
      "person: 34%\t(left_x:  310   top_y:  294   width:   24   height:   39)\n",
      "person: 40%\t(left_x:  312   top_y:  283   width:   17   height:   45)\n",
      "person: 39%\t(left_x:  314   top_y:  283   width:   14   height:   22)\n",
      "bicycle: 29%\t(left_x:  355   top_y:  284   width:   37   height:   38)\n",
      "bicycle: 27%\t(left_x:  377   top_y:  278   width:   31   height:   33)\n",
      "bicycle: 27%\t(left_x:  392   top_y:  276   width:   28   height:   32)\n",
      "bicycle: 25%\t(left_x:  411   top_y:  274   width:   19   height:   28)\n",
      "bicycle: 32%\t(left_x:  419   top_y:  274   width:   17   height:   28)\n",
      "bicycle: 41%\t(left_x:  427   top_y:  274   width:   21   height:   28)\n",
      "car: 41%\t(left_x:  564   top_y:  259   width:   14   height:   13)\n",
      "car: 50%\t(left_x:  573   top_y:  261   width:   15   height:   12)\n",
      "car: 27%\t(left_x:  577   top_y:  259   width:   16   height:   12)\n",
      "truck: 79%\t(left_x:  594   top_y:  221   width:   63   height:   70)\n",
      "car: 43%\t(left_x:  654   top_y:  256   width:   11   height:   13)\n",
      "car: 44%\t(left_x:  676   top_y:  257   width:   26   height:   17)\n",
      "truck: 37%\t(left_x:  677   top_y:  257   width:   25   height:   17)\n",
      "car: 84%\t(left_x:  734   top_y:  263   width:   51   height:   32)\n",
      "car: 84%\t(left_x:  795   top_y:  273   width:   53   height:   31)\n",
      "car: 84%\t(left_x:  826   top_y:  255   width:  176   height:  123)\n",
      "truck: 70%\t(left_x:  986   top_y:  303   width:  218   height:  172)\n",
      "car: 34%\t(left_x:  986   top_y:  303   width:  216   height:  172)\n",
      "car: 67%\t(left_x: 1151   top_y:  444   width:  109   height:  108)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01888_MVL.png: Predicted in 145.618000 milli-seconds.\n",
      "car: 65%\t(left_x:  116   top_y:  279   width:   62   height:   55)\n",
      "car: 47%\t(left_x:  216   top_y:  138   width:   27   height:   25)\n",
      "car: 87%\t(left_x:  279   top_y:   81   width:   57   height:   48)\n",
      "car: 87%\t(left_x:  339   top_y:   51   width:   65   height:   47)\n",
      "car: 91%\t(left_x:  410   top_y:   25   width:   88   height:   49)\n",
      "person: 31%\t(left_x:  430   top_y:   22   width:   11   height:   17)\n",
      "person: 30%\t(left_x:  442   top_y:   19   width:   10   height:   13)\n",
      "bicycle: 70%\t(left_x:  501   top_y:   19   width:   22   height:   35)\n",
      "bicycle: 53%\t(left_x:  531   top_y:   18   width:   28   height:   35)\n",
      "bicycle: 29%\t(left_x:  535   top_y:   15   width:   36   height:   37)\n",
      "bicycle: 56%\t(left_x:  552   top_y:   14   width:   36   height:   37)\n",
      "bicycle: 37%\t(left_x:  581   top_y:    9   width:   38   height:   40)\n",
      "bicycle: 49%\t(left_x:  589   top_y:   13   width:   55   height:   37)\n",
      "bicycle: 31%\t(left_x:  609   top_y:   21   width:   47   height:   30)\n",
      "car: 44%\t(left_x:  618   top_y:    3   width:   62   height:   26)\n",
      "bicycle: 44%\t(left_x:  653   top_y:   27   width:   46   height:   27)\n",
      "bicycle: 53%\t(left_x:  835   top_y:   59   width:   43   height:   36)\n",
      "motorbike: 74%\t(left_x:  870   top_y:   72   width:   77   height:   62)\n",
      "car: 92%\t(left_x:  938   top_y:  138   width:  148   height:  128)\n",
      "car: 85%\t(left_x: 1071   top_y:  262   width:   90   height:  102)\n",
      "pottedplant: 40%\t(left_x: 1098   top_y:  195   width:   42   height:   37)\n",
      "car: 64%\t(left_x: 1141   top_y:  357   width:   78   height:   88)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06625_FV.png: Predicted in 145.090000 milli-seconds.\n",
      "truck: 43%\t(left_x:    0   top_y:  415   width:   57   height:  113)\n",
      "car: 33%\t(left_x:    0   top_y:  520   width:   74   height:  109)\n",
      "car: 29%\t(left_x:    4   top_y:  451   width:   56   height:   65)\n",
      "car: 49%\t(left_x:   15   top_y:  472   width:   44   height:   35)\n",
      "car: 87%\t(left_x:  263   top_y:  306   width:  112   height:   73)\n",
      "car: 94%\t(left_x:  516   top_y:  237   width:  173   height:  110)\n",
      "car: 93%\t(left_x:  757   top_y:  255   width:  184   height:  124)\n",
      "car: 92%\t(left_x:  935   top_y:  320   width:  155   height:   98)\n",
      "car: 88%\t(left_x: 1085   top_y:  380   width:  108   height:   85)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00960_MVL.png: Predicted in 147.658000 milli-seconds.\n",
      "car: 43%\t(left_x:   -4   top_y:   54   width: 1267   height:  900)\n",
      "person: 60%\t(left_x:  320   top_y:   23   width:   38   height:   66)\n",
      "bicycle: 49%\t(left_x:  417   top_y:   33   width:   48   height:   33)\n",
      "bicycle: 35%\t(left_x:  420   top_y:   25   width:   29   height:   40)\n",
      "person: 65%\t(left_x:  421   top_y:   18   width:   26   height:   44)\n",
      "bicycle: 31%\t(left_x:  431   top_y:   28   width:   37   height:   31)\n",
      "bicycle: 46%\t(left_x:  506   top_y:   17   width:   22   height:   36)\n",
      "bicycle: 45%\t(left_x:  527   top_y:   15   width:   22   height:   37)\n",
      "bicycle: 25%\t(left_x:  530   top_y:    9   width:   32   height:   42)\n",
      "bicycle: 41%\t(left_x:  548   top_y:   11   width:   21   height:   41)\n",
      "bicycle: 48%\t(left_x:  565   top_y:   15   width:   24   height:   36)\n",
      "bicycle: 32%\t(left_x:  577   top_y:   11   width:   42   height:   40)\n",
      "bicycle: 62%\t(left_x:  601   top_y:   12   width:   42   height:   40)\n",
      "car: 56%\t(left_x:  620   top_y:    6   width:   32   height:   21)\n",
      "person: 30%\t(left_x:  651   top_y:    3   width:   17   height:   36)\n",
      "person: 89%\t(left_x:  664   top_y:    4   width:   88   height:  143)\n",
      "handbag: 29%\t(left_x:  665   top_y:   18   width:   26   height:   48)\n",
      "handbag: 30%\t(left_x:  665   top_y:   32   width:   17   height:   31)\n",
      "handbag: 47%\t(left_x:  676   top_y:    3   width:   42   height:   64)\n",
      "car: 44%\t(left_x:  717   top_y:    6   width:  148   height:  169)\n",
      "person: 92%\t(left_x:  720   top_y:    3   width:  146   height:  172)\n",
      "handbag: 42%\t(left_x:  727   top_y:   63   width:   32   height:   66)\n",
      "car: 72%\t(left_x:  811   top_y:   62   width:   55   height:   47)\n",
      "bicycle: 78%\t(left_x:  901   top_y:  107   width:   44   height:   39)\n",
      "car: 91%\t(left_x:  993   top_y:  182   width:  133   height:  143)\n",
      "person: 36%\t(left_x: 1123   top_y:  298   width:   32   height:   30)\n",
      "car: 86%\t(left_x: 1125   top_y:  349   width:   74   height:  107)\n",
      "person: 32%\t(left_x: 1137   top_y:  298   width:   18   height:   24)\n",
      "car: 26%\t(left_x: 1185   top_y:  467   width:   47   height:  114)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05217_MVR.png: Predicted in 143.323000 milli-seconds.\n",
      "bicycle: 40%\t(left_x:   53   top_y:  442   width:   47   height:   78)\n",
      "person: 70%\t(left_x:  148   top_y:  206   width:   46   height:   38)\n",
      "parking meter: 40%\t(left_x:  559   top_y:    6   width:   24   height:   89)\n",
      "car: 85%\t(left_x: 1037   top_y:  160   width:   81   height:   75)\n",
      "car: 42%\t(left_x: 1103   top_y:  284   width:   58   height:   53)\n",
      "person: 38%\t(left_x: 1107   top_y:  284   width:   51   height:   52)\n",
      "person: 30%\t(left_x: 1132   top_y:  253   width:   13   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00354_RV.png: Predicted in 144.726000 milli-seconds.\n",
      "car: 41%\t(left_x:    8   top_y:  522   width: 1262   height:  435)\n",
      "car: 95%\t(left_x:   68   top_y:  265   width:  349   height:  317)\n",
      "bicycle: 76%\t(left_x:  420   top_y:  276   width:   41   height:   47)\n",
      "car: 91%\t(left_x:  460   top_y:  251   width:   91   height:   65)\n",
      "car: 80%\t(left_x:  550   top_y:  254   width:   38   height:   29)\n",
      "car: 58%\t(left_x:  582   top_y:  256   width:   18   height:   21)\n",
      "car: 87%\t(left_x:  599   top_y:  250   width:   52   height:   39)\n",
      "car: 65%\t(left_x:  655   top_y:  257   width:   16   height:   14)\n",
      "car: 25%\t(left_x:  672   top_y:  260   width:    9   height:    9)\n",
      "person: 90%\t(left_x:  979   top_y:  283   width:   60   height:  107)\n",
      "backpack: 36%\t(left_x:  990   top_y:  294   width:   22   height:   44)\n",
      "handbag: 41%\t(left_x:  990   top_y:  295   width:   23   height:   46)\n",
      "person: 88%\t(left_x: 1019   top_y:  295   width:   68   height:  118)\n",
      "pottedplant: 58%\t(left_x: 1125   top_y:  436   width:   38   height:   50)\n",
      "pottedplant: 35%\t(left_x: 1154   top_y:  459   width:   45   height:   38)\n",
      "pottedplant: 38%\t(left_x: 1175   top_y:  407   width:   33   height:   42)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04713_FV.png: Predicted in 145.273000 milli-seconds.\n",
      "car: 30%\t(left_x:   -3   top_y:  521   width: 1233   height:  388)\n",
      "car: 92%\t(left_x:   10   top_y:  362   width:  236   height:  200)\n",
      "car: 94%\t(left_x:  266   top_y:  335   width:  153   height:   92)\n",
      "car: 90%\t(left_x:  408   top_y:  328   width:   98   height:   58)\n",
      "car: 67%\t(left_x:  493   top_y:  329   width:   38   height:   37)\n",
      "car: 89%\t(left_x:  508   top_y:  325   width:   79   height:   50)\n",
      "car: 43%\t(left_x:  581   top_y:  335   width:   17   height:   19)\n",
      "car: 66%\t(left_x:  595   top_y:  335   width:   28   height:   20)\n",
      "car: 33%\t(left_x:  727   top_y:  344   width:   15   height:    8)\n",
      "traffic light: 30%\t(left_x:  744   top_y:  290   width:   19   height:   25)\n",
      "person: 43%\t(left_x:  756   top_y:  335   width:   10   height:   24)\n",
      "person: 29%\t(left_x:  806   top_y:  342   width:   12   height:   31)\n",
      "motorbike: 52%\t(left_x:  810   top_y:  310   width:   44   height:   87)\n",
      "car: 63%\t(left_x:  879   top_y:  358   width:   58   height:   27)\n",
      "bench: 56%\t(left_x: 1007   top_y:  375   width:   70   height:   60)\n",
      "bicycle: 89%\t(left_x: 1107   top_y:  396   width:  105   height:   94)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00110_FV.png: Predicted in 143.963000 milli-seconds.\n",
      "car: 91%\t(left_x:    8   top_y:  293   width:  386   height:  308)\n",
      "car: 33%\t(left_x:  133   top_y:  657   width: 1050   height:  183)\n",
      "car: 78%\t(left_x:  633   top_y:  347   width:   28   height:   10)\n",
      "car: 75%\t(left_x:  672   top_y:  346   width:   30   height:   11)\n",
      "car: 83%\t(left_x:  707   top_y:  342   width:   36   height:   22)\n",
      "car: 76%\t(left_x:  734   top_y:  338   width:   68   height:   34)\n",
      "person: 77%\t(left_x:  873   top_y:  342   width:   22   height:   39)\n",
      "stop sign: 70%\t(left_x:  932   top_y:  218   width:   39   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02651_MVL.png: Predicted in 145.011000 milli-seconds.\n",
      "car: 37%\t(left_x:    2   top_y:   37   width: 1276   height:  918)\n",
      "car: 41%\t(left_x:  118   top_y:  277   width:   60   height:   54)\n",
      "car: 92%\t(left_x:  266   top_y:   74   width:   97   height:   74)\n",
      "person: 80%\t(left_x:  363   top_y:   42   width:   20   height:   42)\n",
      "bicycle: 40%\t(left_x:  377   top_y:   53   width:   27   height:   25)\n",
      "motorbike: 27%\t(left_x:  426   top_y:   38   width:   32   height:   25)\n",
      "person: 41%\t(left_x:  435   top_y:   37   width:   23   height:   24)\n",
      "bicycle: 56%\t(left_x: 1100   top_y:  301   width:   56   height:   45)\n",
      "bicycle: 52%\t(left_x: 1117   top_y:  347   width:   42   height:   45)\n",
      "person: 36%\t(left_x: 1154   top_y:  254   width:   15   height:   21)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00361_FV.png: Predicted in 146.108000 milli-seconds.\n",
      "car: 49%\t(left_x:    4   top_y:  540   width: 1278   height:  357)\n",
      "car: 91%\t(left_x:  154   top_y:  356   width:  174   height:  121)\n",
      "car: 86%\t(left_x:  326   top_y:  359   width:   95   height:   57)\n",
      "car: 79%\t(left_x:  419   top_y:  354   width:   56   height:   31)\n",
      "car: 79%\t(left_x:  490   top_y:  348   width:   38   height:   21)\n",
      "car: 48%\t(left_x:  577   top_y:  344   width:   14   height:   10)\n",
      "car: 40%\t(left_x:  658   top_y:  341   width:   15   height:   11)\n",
      "car: 29%\t(left_x:  672   top_y:  338   width:   13   height:   16)\n",
      "car: 57%\t(left_x:  679   top_y:  336   width:   20   height:   20)\n",
      "car: 82%\t(left_x:  690   top_y:  336   width:   43   height:   27)\n",
      "bicycle: 88%\t(left_x: 1109   top_y:  397   width:  118   height:  105)\n",
      "person: 78%\t(left_x: 1144   top_y:  348   width:   56   height:  100)\n",
      "backpack: 28%\t(left_x: 1149   top_y:  349   width:   56   height:   95)\n",
      "backpack: 67%\t(left_x: 1175   top_y:  350   width:   36   height:   55)\n",
      "person: 79%\t(left_x: 1207   top_y:  370   width:   40   height:  106)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07341_FV.png: Predicted in 144.651000 milli-seconds.\n",
      "car: 27%\t(left_x:  497   top_y:  371   width:   20   height:   13)\n",
      "person: 93%\t(left_x:  617   top_y:  276   width:   56   height:  173)\n",
      "car: 79%\t(left_x:  661   top_y:  353   width:   96   height:   60)\n",
      "car: 29%\t(left_x:  715   top_y:  327   width:  261   height:  145)\n",
      "person: 94%\t(left_x:  940   top_y:  276   width:   96   height:  250)\n",
      "car: 76%\t(left_x: 1178   top_y:  437   width:   82   height:  112)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07884_MVR.png: Predicted in 145.672000 milli-seconds.\n",
      "car: 86%\t(left_x:   84   top_y:    4   width:  801   height:  438)\n",
      "car: 70%\t(left_x:  910   top_y:   51   width:   39   height:   32)\n",
      "car: 74%\t(left_x: 1044   top_y:  152   width:   62   height:   58)\n",
      "car: 54%\t(left_x: 1106   top_y:  266   width:   45   height:   56)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03833_MVL.png: Predicted in 146.169000 milli-seconds.\n",
      "car: 37%\t(left_x:    8   top_y:   12   width: 1136   height:  933)\n",
      "car: 49%\t(left_x:  118   top_y:  278   width:   57   height:   54)\n",
      "person: 36%\t(left_x:  322   top_y:   58   width:   21   height:   35)\n",
      "bicycle: 50%\t(left_x:  322   top_y:   62   width:   20   height:   31)\n",
      "bicycle: 30%\t(left_x:  323   top_y:   46   width:   26   height:   47)\n",
      "person: 69%\t(left_x:  325   top_y:   44   width:   27   height:   43)\n",
      "person: 43%\t(left_x:  362   top_y:   28   width:   23   height:   36)\n",
      "person: 37%\t(left_x:  362   top_y:   38   width:   22   height:   33)\n",
      "bicycle: 50%\t(left_x:  365   top_y:   47   width:   19   height:   25)\n",
      "truck: 45%\t(left_x:  399   top_y:   14   width:   54   height:   52)\n",
      "car: 60%\t(left_x:  400   top_y:   14   width:   53   height:   51)\n",
      "car: 57%\t(left_x:  437   top_y:    9   width:   24   height:   28)\n",
      "car: 44%\t(left_x:  443   top_y:    7   width:   24   height:   26)\n",
      "car: 47%\t(left_x:  451   top_y:    5   width:   19   height:   22)\n",
      "car: 31%\t(left_x:  455   top_y:    6   width:   24   height:   20)\n",
      "car: 43%\t(left_x:  468   top_y:    8   width:   12   height:   15)\n",
      "car: 28%\t(left_x:  469   top_y:    5   width:   15   height:   13)\n",
      "car: 30%\t(left_x:  475   top_y:    6   width:   13   height:   11)\n",
      "car: 92%\t(left_x:  777   top_y:   18   width:  136   height:   73)\n",
      "bicycle: 27%\t(left_x:  937   top_y:  105   width:   34   height:   21)\n",
      "bicycle: 46%\t(left_x:  938   top_y:   99   width:   53   height:   34)\n",
      "bicycle: 58%\t(left_x:  964   top_y:  121   width:   39   height:   33)\n",
      "bicycle: 34%\t(left_x: 1057   top_y:  220   width:   48   height:   37)\n",
      "bicycle: 37%\t(left_x: 1071   top_y:  222   width:   49   height:   38)\n",
      "bicycle: 52%\t(left_x: 1082   top_y:  231   width:   41   height:   45)\n",
      "bicycle: 49%\t(left_x: 1093   top_y:  256   width:   37   height:   35)\n",
      "bicycle: 28%\t(left_x: 1097   top_y:  263   width:   65   height:   43)\n",
      "bicycle: 47%\t(left_x: 1152   top_y:  384   width:   48   height:   23)\n",
      "bicycle: 31%\t(left_x: 1156   top_y:  391   width:   53   height:   28)\n",
      "bicycle: 35%\t(left_x: 1162   top_y:  400   width:   56   height:   27)\n",
      "bicycle: 49%\t(left_x: 1184   top_y:  493   width:   56   height:   35)\n",
      "bicycle: 56%\t(left_x: 1189   top_y:  540   width:   52   height:   33)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07052_MVR.png: Predicted in 145.336000 milli-seconds.\n",
      "car: 51%\t(left_x:   51   top_y:  528   width:   52   height:  101)\n",
      "person: 27%\t(left_x:  984   top_y:  102   width:   22   height:   31)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01618_MVR.png: Predicted in 144.159000 milli-seconds.\n",
      "car: 78%\t(left_x:   82   top_y:  800   width:   88   height:   95)\n",
      "person: 83%\t(left_x:  163   top_y:  171   width:   70   height:   94)\n",
      "bus: 73%\t(left_x:  384   top_y:    3   width:   87   height:   86)\n",
      "truck: 32%\t(left_x:  385   top_y:    3   width:   86   height:   83)\n",
      "keyboard: 57%\t(left_x:  455   top_y:  437   width:  303   height:  229)\n",
      "person: 88%\t(left_x:  532   top_y:    2   width:   59   height:  104)\n",
      "person: 26%\t(left_x:  582   top_y:    3   width:   17   height:   32)\n",
      "bicycle: 27%\t(left_x:  622   top_y:    6   width:   17   height:   29)\n",
      "person: 86%\t(left_x:  809   top_y:    3   width:   41   height:   66)\n",
      "person: 37%\t(left_x:  992   top_y:   94   width:   25   height:   41)\n",
      "person: 28%\t(left_x: 1016   top_y:  108   width:   22   height:   34)\n",
      "car: 82%\t(left_x: 1110   top_y:  286   width:   51   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05874_MVR.png: Predicted in 144.856000 milli-seconds.\n",
      "person: 85%\t(left_x:  125   top_y:  103   width:  201   height:  204)\n",
      "person: 90%\t(left_x:  170   top_y:   83   width:  176   height:  137)\n",
      "motorbike: 64%\t(left_x:  498   top_y:    1   width:  129   height:   37)\n",
      "bicycle: 30%\t(left_x:  742   top_y:    2   width:   35   height:   16)\n",
      "bicycle: 39%\t(left_x:  785   top_y:    2   width:   33   height:   27)\n",
      "car: 28%\t(left_x: 1111   top_y:  285   width:   50   height:   48)\n",
      "person: 34%\t(left_x: 1133   top_y:  286   width:   23   height:   40)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01419_FV.png: Predicted in 145.049000 milli-seconds.\n",
      "car: 60%\t(left_x:    6   top_y:  525   width: 1278   height:  377)\n",
      "bicycle: 57%\t(left_x:   34   top_y:  415   width:   76   height:   80)\n",
      "bicycle: 40%\t(left_x:   77   top_y:  402   width:   72   height:   58)\n",
      "motorbike: 35%\t(left_x:   85   top_y:  402   width:   66   height:   58)\n",
      "person: 79%\t(left_x:  178   top_y:  376   width:   32   height:   54)\n",
      "car: 63%\t(left_x:  325   top_y:  362   width:   31   height:   23)\n",
      "car: 40%\t(left_x:  349   top_y:  364   width:   16   height:   16)\n",
      "car: 35%\t(left_x:  354   top_y:  363   width:   15   height:   14)\n",
      "car: 40%\t(left_x:  357   top_y:  363   width:   15   height:   11)\n",
      "car: 28%\t(left_x:  373   top_y:  362   width:   12   height:    7)\n",
      "car: 25%\t(left_x:  401   top_y:  357   width:   14   height:    8)\n",
      "car: 28%\t(left_x:  407   top_y:  355   width:   10   height:   10)\n",
      "car: 59%\t(left_x:  415   top_y:  353   width:   21   height:   13)\n",
      "car: 93%\t(left_x:  506   top_y:  324   width:   92   height:   56)\n",
      "bicycle: 74%\t(left_x:  817   top_y:  348   width:   20   height:   32)\n",
      "person: 62%\t(left_x:  857   top_y:  343   width:   15   height:   44)\n",
      "person: 71%\t(left_x:  869   top_y:  342   width:   17   height:   47)\n",
      "bicycle: 53%\t(left_x:  886   top_y:  365   width:   29   height:   28)\n",
      "car: 29%\t(left_x:  987   top_y:  396   width:   10   height:    9)\n",
      "car: 33%\t(left_x:  988   top_y:  396   width:   13   height:    9)\n",
      "car: 57%\t(left_x:  995   top_y:  397   width:   15   height:   12)\n",
      "car: 56%\t(left_x: 1008   top_y:  401   width:   20   height:   16)\n",
      "car: 71%\t(left_x: 1025   top_y:  405   width:   31   height:   18)\n",
      "car: 28%\t(left_x: 1036   top_y:  407   width:   21   height:   15)\n",
      "car: 31%\t(left_x: 1064   top_y:  420   width:   32   height:   25)\n",
      "bicycle: 61%\t(left_x: 1134   top_y:  445   width:   34   height:   43)\n",
      "person: 26%\t(left_x: 1136   top_y:  443   width:   34   height:   44)\n",
      "person: 33%\t(left_x: 1145   top_y:  421   width:   27   height:   56)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05979_MVR.png: Predicted in 145.923000 milli-seconds.\n",
      "person: 44%\t(left_x:  109   top_y:  840   width:   19   height:   27)\n",
      "bicycle: 49%\t(left_x:  872   top_y:   47   width:   60   height:   69)\n",
      "bicycle: 52%\t(left_x:  960   top_y:  111   width:   77   height:   89)\n",
      "car: 72%\t(left_x: 1023   top_y:  143   width:   77   height:   84)\n",
      "car: 37%\t(left_x: 1104   top_y:  284   width:   58   height:   53)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04073_MVR.png: Predicted in 145.372000 milli-seconds.\n",
      "bicycle: 31%\t(left_x:    5   top_y:  453   width:   94   height:   91)\n",
      "bicycle: 27%\t(left_x:   25   top_y:  484   width:   67   height:   66)\n",
      "bicycle: 55%\t(left_x:   27   top_y:  436   width:   76   height:   82)\n",
      "bicycle: 35%\t(left_x:   43   top_y:  385   width:   75   height:   62)\n",
      "person: 49%\t(left_x:  231   top_y:   80   width:   36   height:   58)\n",
      "person: 25%\t(left_x:  232   top_y:   80   width:   26   height:   33)\n",
      "bicycle: 82%\t(left_x:  248   top_y:  140   width:   63   height:   79)\n",
      "person: 25%\t(left_x:  280   top_y:   47   width:   43   height:   63)\n",
      "bicycle: 37%\t(left_x:  280   top_y:   44   width:   58   height:   56)\n",
      "person: 77%\t(left_x:  280   top_y:   65   width:   32   height:   53)\n",
      "bicycle: 76%\t(left_x:  329   top_y:   58   width:   58   height:   68)\n",
      "bicycle: 87%\t(left_x:  373   top_y:   11   width:  111   height:  141)\n",
      "bicycle: 75%\t(left_x:  421   top_y:   15   width:   69   height:   89)\n",
      "bicycle: 41%\t(left_x:  519   top_y:    3   width:   35   height:   76)\n",
      "bicycle: 79%\t(left_x:  533   top_y:    3   width:   98   height:   93)\n",
      "bicycle: 78%\t(left_x:  595   top_y:    3   width:   81   height:   71)\n",
      "bicycle: 55%\t(left_x:  815   top_y:    4   width:   51   height:   70)\n",
      "bicycle: 39%\t(left_x:  852   top_y:    8   width:   43   height:   97)\n",
      "bicycle: 44%\t(left_x:  864   top_y:   14   width:   50   height:   99)\n",
      "bicycle: 45%\t(left_x:  880   top_y:   26   width:   40   height:   89)\n",
      "bicycle: 37%\t(left_x:  896   top_y:   22   width:   51   height:   92)\n",
      "bicycle: 35%\t(left_x:  910   top_y:   25   width:   58   height:   92)\n",
      "bicycle: 51%\t(left_x:  937   top_y:   34   width:   40   height:   90)\n",
      "bicycle: 41%\t(left_x:  963   top_y:   69   width:   40   height:   57)\n",
      "bicycle: 44%\t(left_x:  981   top_y:   88   width:   38   height:   49)\n",
      "bicycle: 29%\t(left_x:  985   top_y:   92   width:   50   height:   56)\n",
      "bicycle: 49%\t(left_x:  999   top_y:  103   width:   37   height:   49)\n",
      "bicycle: 26%\t(left_x: 1053   top_y:   59   width:   33   height:   33)\n",
      "person: 54%\t(left_x: 1126   top_y:  285   width:   27   height:   44)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01910_MVR.png: Predicted in 144.562000 milli-seconds.\n",
      "bicycle: 52%\t(left_x:   51   top_y:  260   width:  230   height:  269)\n",
      "bicycle: 83%\t(left_x:  316   top_y:    3   width:  193   height:  274)\n",
      "bicycle: 72%\t(left_x:  430   top_y:    4   width:  136   height:  159)\n",
      "pottedplant: 34%\t(left_x:  510   top_y:    3   width:   34   height:   41)\n",
      "bicycle: 76%\t(left_x:  618   top_y:    3   width:  106   height:  192)\n",
      "bicycle: 80%\t(left_x:  789   top_y:   11   width:   84   height:  182)\n",
      "bicycle: 75%\t(left_x:  881   top_y:   52   width:  110   height:   82)\n",
      "bicycle: 72%\t(left_x:  948   top_y:   84   width:   97   height:  106)\n",
      "bicycle: 27%\t(left_x: 1055   top_y:  174   width:   49   height:   34)\n",
      "bicycle: 28%\t(left_x: 1077   top_y:  174   width:   33   height:   34)\n",
      "car: 53%\t(left_x: 1110   top_y:  285   width:   50   height:   52)\n",
      "person: 27%\t(left_x: 1118   top_y:  285   width:   38   height:   50)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05943_RV.png: Predicted in 145.544000 milli-seconds.\n",
      "car: 33%\t(left_x:    3   top_y:  615   width: 1277   height:  341)\n",
      "car: 90%\t(left_x:   10   top_y:  339   width:  270   height:  254)\n",
      "car: 95%\t(left_x:  265   top_y:  251   width:  272   height:  184)\n",
      "car: 92%\t(left_x:  506   top_y:  249   width:   76   height:   65)\n",
      "car: 35%\t(left_x:  577   top_y:  258   width:   15   height:   26)\n",
      "car: 93%\t(left_x:  578   top_y:  200   width:  210   height:  170)\n",
      "car: 89%\t(left_x:  774   top_y:  258   width:   67   height:   75)\n",
      "bicycle: 86%\t(left_x:  916   top_y:  337   width:  186   height:  164)\n",
      "bicycle: 88%\t(left_x: 1042   top_y:  438   width:  211   height:  185)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02819_MVR.png: Predicted in 144.382000 milli-seconds.\n",
      "car: 33%\t(left_x:   61   top_y:  371   width:   57   height:   43)\n",
      "car: 33%\t(left_x:   77   top_y:  356   width:   54   height:   33)\n",
      "bicycle: 37%\t(left_x:  116   top_y:  279   width:   36   height:   52)\n",
      "bicycle: 26%\t(left_x:  147   top_y:  244   width:   52   height:   48)\n",
      "bicycle: 30%\t(left_x:  148   top_y:  229   width:   60   height:   50)\n",
      "bicycle: 30%\t(left_x:  150   top_y:  261   width:   43   height:   35)\n",
      "car: 40%\t(left_x:  157   top_y:   25   width: 1119   height:  926)\n",
      "bicycle: 65%\t(left_x:  172   top_y:  199   width:   58   height:   51)\n",
      "bicycle: 58%\t(left_x:  213   top_y:  174   width:   44   height:   37)\n",
      "car: 27%\t(left_x:  233   top_y:  115   width:   64   height:   60)\n",
      "bicycle: 47%\t(left_x:  409   top_y:   37   width:   61   height:   47)\n",
      "person: 25%\t(left_x:  475   top_y:    8   width:   48   height:   55)\n",
      "person: 88%\t(left_x:  553   top_y:    2   width:   48   height:   63)\n",
      "bicycle: 67%\t(left_x:  839   top_y:   29   width:   75   height:   59)\n",
      "person: 74%\t(left_x:  878   top_y:    4   width:   37   height:   71)\n",
      "person: 27%\t(left_x:  926   top_y:    6   width:   30   height:   61)\n",
      "car: 66%\t(left_x:  997   top_y:  102   width:  112   height:  116)\n",
      "person: 32%\t(left_x: 1125   top_y:  285   width:   29   height:   46)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00297_MVR.png: Predicted in 144.472000 milli-seconds.\n",
      "bicycle: 31%\t(left_x:    2   top_y:  523   width:   93   height:   77)\n",
      "bicycle: 71%\t(left_x:   38   top_y:  407   width:   96   height:  124)\n",
      "car: 43%\t(left_x:  129   top_y:  233   width:   82   height:   92)\n",
      "bicycle: 46%\t(left_x:  350   top_y:   57   width:   33   height:   55)\n",
      "person: 33%\t(left_x:  373   top_y:   43   width:   45   height:   59)\n",
      "bicycle: 26%\t(left_x:  373   top_y:   60   width:   39   height:   45)\n",
      "truck: 55%\t(left_x:  396   top_y:    3   width:  572   height:  113)\n",
      "car: 49%\t(left_x:  400   top_y:    4   width:  558   height:  111)\n",
      "person: 31%\t(left_x:  997   top_y:   92   width:   32   height:   40)\n",
      "car: 57%\t(left_x: 1109   top_y:  286   width:   54   height:   50)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00149_MVR.png: Predicted in 145.240000 milli-seconds.\n",
      "person: 28%\t(left_x:  903   top_y:   31   width:   14   height:   19)\n",
      "person: 36%\t(left_x:  914   top_y:   28   width:   19   height:   26)\n",
      "person: 31%\t(left_x:  924   top_y:   28   width:   14   height:   29)\n",
      "person: 50%\t(left_x: 1064   top_y:  258   width:   24   height:   29)\n",
      "person: 28%\t(left_x: 1106   top_y:  285   width:   23   height:   50)\n",
      "person: 35%\t(left_x: 1124   top_y:  284   width:   13   height:   45)\n",
      "person: 26%\t(left_x: 1135   top_y:  286   width:   21   height:   41)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01128_MVR.png: Predicted in 144.767000 milli-seconds.\n",
      "bicycle: 38%\t(left_x:   10   top_y:  566   width:   94   height:   66)\n",
      "person: 45%\t(left_x:   18   top_y:  440   width:   70   height:   38)\n",
      "person: 35%\t(left_x:   31   top_y:  409   width:   61   height:   45)\n",
      "bicycle: 34%\t(left_x:   32   top_y:  517   width:   53   height:   46)\n",
      "person: 37%\t(left_x:   75   top_y:  706   width:   74   height:   25)\n",
      "person: 39%\t(left_x:   76   top_y:  729   width:   46   height:   26)\n",
      "person: 33%\t(left_x:   85   top_y:  300   width:   40   height:   69)\n",
      "bicycle: 83%\t(left_x:  105   top_y:  280   width:  107   height:  171)\n",
      "bicycle: 84%\t(left_x:  154   top_y:   55   width:  311   height:  302)\n",
      "person: 81%\t(left_x:  155   top_y:  132   width:  114   height:   97)\n",
      "backpack: 48%\t(left_x:  171   top_y:  148   width:   43   height:   36)\n",
      "person: 32%\t(left_x:  198   top_y:  107   width:   34   height:   50)\n",
      "person: 30%\t(left_x:  230   top_y:  113   width:   39   height:   45)\n",
      "person: 28%\t(left_x:  726   top_y:    2   width:   29   height:   40)\n",
      "person: 51%\t(left_x:  762   top_y:    3   width:   26   height:   49)\n",
      "person: 87%\t(left_x:  772   top_y:    3   width:   46   height:   65)\n",
      "person: 91%\t(left_x:  810   top_y:    3   width:   69   height:   80)\n",
      "bicycle: 79%\t(left_x:  862   top_y:   22   width:   61   height:   85)\n",
      "person: 76%\t(left_x:  916   top_y:   18   width:   54   height:  100)\n",
      "person: 32%\t(left_x:  945   top_y:   49   width:   49   height:   81)\n",
      "person: 39%\t(left_x:  949   top_y:   57   width:   32   height:   42)\n",
      "person: 61%\t(left_x:  955   top_y:   65   width:   33   height:   41)\n",
      "person: 41%\t(left_x: 1057   top_y:  156   width:   31   height:   39)\n",
      "person: 50%\t(left_x: 1133   top_y:  289   width:   25   height:   39)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01354_RV.png: Predicted in 145.479000 milli-seconds.\n",
      "bicycle: 90%\t(left_x:  151   top_y:  337   width:  117   height:  118)\n",
      "car: 86%\t(left_x:  640   top_y:  246   width:   43   height:   37)\n",
      "car: 34%\t(left_x:  687   top_y:  255   width:   11   height:    9)\n",
      "car: 32%\t(left_x:  777   top_y:  268   width:   29   height:   19)\n",
      "bicycle: 43%\t(left_x:  815   top_y:  283   width:   25   height:   23)\n",
      "bicycle: 64%\t(left_x:  848   top_y:  283   width:   51   height:   46)\n",
      "person: 35%\t(left_x: 1001   top_y:  315   width:   14   height:   24)\n",
      "motorbike: 91%\t(left_x: 1021   top_y:  337   width:  183   height:  180)\n",
      "motorbike: 80%\t(left_x: 1129   top_y:  453   width:  146   height:  153)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04534_RV.png: Predicted in 144.980000 milli-seconds.\n",
      "bicycle: 32%\t(left_x:   22   top_y:  503   width:   47   height:   49)\n",
      "bicycle: 68%\t(left_x:  441   top_y:  269   width:   39   height:   45)\n",
      "bicycle: 59%\t(left_x:  477   top_y:  269   width:   35   height:   28)\n",
      "bicycle: 27%\t(left_x:  485   top_y:  267   width:   46   height:   27)\n",
      "bicycle: 50%\t(left_x:  513   top_y:  265   width:   23   height:   27)\n",
      "person: 62%\t(left_x:  549   top_y:  249   width:   23   height:   45)\n",
      "bicycle: 46%\t(left_x:  550   top_y:  265   width:   22   height:   30)\n",
      "person: 29%\t(left_x:  590   top_y:  252   width:    7   height:   21)\n",
      "car: 26%\t(left_x:  611   top_y:  264   width:   17   height:   10)\n",
      "car: 43%\t(left_x:  705   top_y:  264   width:   15   height:    9)\n",
      "motorbike: 67%\t(left_x:  781   top_y:  278   width:   26   height:   33)\n",
      "person: 34%\t(left_x:  783   top_y:  259   width:   25   height:   47)\n",
      "person: 59%\t(left_x:  784   top_y:  260   width:   23   height:   28)\n",
      "car: 88%\t(left_x:  805   top_y:  274   width:   81   height:   44)\n",
      "car: 89%\t(left_x:  854   top_y:  287   width:  128   height:   80)\n",
      "bench: 35%\t(left_x: 1077   top_y:  383   width:   76   height:   64)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02664_MVR.png: Predicted in 151.718000 milli-seconds.\n",
      "person: 35%\t(left_x:   20   top_y:  548   width:   45   height:   27)\n",
      "person: 32%\t(left_x:   39   top_y:  644   width:   24   height:   13)\n",
      "bicycle: 36%\t(left_x:  124   top_y:  265   width:   41   height:   33)\n",
      "bicycle: 67%\t(left_x:  269   top_y:  106   width:   51   height:   59)\n",
      "bicycle: 92%\t(left_x:  286   top_y:    9   width:  359   height:  245)\n",
      "person: 32%\t(left_x:  290   top_y:    7   width:  353   height:  244)\n",
      "bicycle: 25%\t(left_x:  312   top_y:   81   width:   41   height:   42)\n",
      "person: 71%\t(left_x:  411   top_y:    5   width:  119   height:  176)\n",
      "bicycle: 78%\t(left_x:  643   top_y:    3   width:  176   height:   86)\n",
      "person: 39%\t(left_x:  649   top_y:    3   width:  167   height:   84)\n",
      "person: 66%\t(left_x:  711   top_y:    1   width:   83   height:   65)\n",
      "person: 52%\t(left_x:  831   top_y:    3   width:   49   height:   59)\n",
      "bicycle: 62%\t(left_x:  837   top_y:    4   width:   49   height:   68)\n",
      "person: 37%\t(left_x: 1015   top_y:  106   width:   23   height:   27)\n",
      "person: 27%\t(left_x: 1017   top_y:  111   width:   28   height:   28)\n",
      "person: 28%\t(left_x: 1128   top_y:  288   width:   26   height:   40)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04706_MVR.png: Predicted in 145.350000 milli-seconds.\n",
      "person: 32%\t(left_x:   59   top_y:  343   width:   60   height:   33)\n",
      "person: 80%\t(left_x:   63   top_y:  287   width:  118   height:   76)\n",
      "person: 59%\t(left_x:   88   top_y:  225   width:   92   height:   58)\n",
      "skateboard: 26%\t(left_x:  110   top_y:  327   width:   56   height:   38)\n",
      "skateboard: 36%\t(left_x:  127   top_y:  334   width:   52   height:   35)\n",
      "person: 28%\t(left_x:  130   top_y:  226   width:   50   height:   52)\n",
      "person: 25%\t(left_x:  146   top_y:  215   width:   38   height:   40)\n",
      "person: 38%\t(left_x:  174   top_y:  188   width:   53   height:   44)\n",
      "person: 38%\t(left_x:  199   top_y:  189   width:   46   height:   38)\n",
      "bicycle: 49%\t(left_x:  970   top_y:  179   width:   75   height:   52)\n",
      "car: 64%\t(left_x:  989   top_y:    5   width:   59   height:   49)\n",
      "car: 32%\t(left_x: 1109   top_y:  236   width:   44   height:   31)\n",
      "skateboard: 35%\t(left_x: 1112   top_y:  314   width:   49   height:   19)\n",
      "person: 38%\t(left_x: 1124   top_y:  286   width:   19   height:   44)\n",
      "person: 69%\t(left_x: 1128   top_y:  286   width:   26   height:   42)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03241_MVR.png: Predicted in 145.350000 milli-seconds.\n",
      "bicycle: 37%\t(left_x:   10   top_y:  388   width:  144   height:  208)\n",
      "person: 32%\t(left_x:  161   top_y:  166   width:   54   height:   55)\n",
      "bicycle: 41%\t(left_x:  268   top_y:   93   width:   48   height:   55)\n",
      "bicycle: 30%\t(left_x:  531   top_y:    2   width:   74   height:  107)\n",
      "bicycle: 82%\t(left_x:  541   top_y:    3   width:  212   height:  166)\n",
      "bicycle: 77%\t(left_x:  682   top_y:    3   width:  153   height:  169)\n",
      "person: 35%\t(left_x:  950   top_y:   60   width:   31   height:   37)\n",
      "person: 39%\t(left_x:  953   top_y:  105   width:   32   height:   45)\n",
      "person: 47%\t(left_x:  953   top_y:   76   width:   61   height:   79)\n",
      "car: 57%\t(left_x: 1110   top_y:  287   width:   46   height:   48)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00489_RV.png: Predicted in 145.239000 milli-seconds.\n",
      "car: 33%\t(left_x:   -3   top_y:  567   width: 1282   height:  384)\n",
      "bicycle: 27%\t(left_x:   26   top_y:  446   width:  134   height:  180)\n",
      "bicycle: 26%\t(left_x:   34   top_y:  419   width:   92   height:  138)\n",
      "bicycle: 82%\t(left_x:   44   top_y:  393   width:  185   height:  217)\n",
      "bicycle: 56%\t(left_x:   48   top_y:  519   width:  115   height:  112)\n",
      "bicycle: 85%\t(left_x:  228   top_y:  338   width:  130   height:  126)\n",
      "bicycle: 69%\t(left_x:  280   top_y:  310   width:  124   height:  105)\n",
      "bicycle: 38%\t(left_x:  310   top_y:  294   width:  110   height:  101)\n",
      "bicycle: 25%\t(left_x:  340   top_y:  328   width:   72   height:   68)\n",
      "motorbike: 50%\t(left_x:  351   top_y:  295   width:   88   height:   61)\n",
      "motorbike: 26%\t(left_x:  357   top_y:  282   width:  118   height:   72)\n",
      "motorbike: 64%\t(left_x:  404   top_y:  279   width:   74   height:   74)\n",
      "person: 26%\t(left_x:  469   top_y:  293   width:   14   height:   20)\n",
      "person: 83%\t(left_x:  486   top_y:  267   width:   18   height:   51)\n",
      "bicycle: 28%\t(left_x:  555   top_y:  281   width:   25   height:   21)\n",
      "bicycle: 26%\t(left_x:  568   top_y:  282   width:   25   height:   17)\n",
      "car: 51%\t(left_x:  585   top_y:  276   width:   20   height:   20)\n",
      "car: 59%\t(left_x:  601   top_y:  276   width:   16   height:   16)\n",
      "car: 80%\t(left_x:  619   top_y:  277   width:   22   height:   17)\n",
      "person: 73%\t(left_x:  685   top_y:  271   width:   10   height:   27)\n",
      "chair: 27%\t(left_x:  799   top_y:  305   width:   25   height:   33)\n",
      "person: 25%\t(left_x:  805   top_y:  301   width:   28   height:   37)\n",
      "person: 55%\t(left_x:  820   top_y:  302   width:   14   height:   37)\n",
      "person: 27%\t(left_x:  858   top_y:  293   width:   17   height:   38)\n",
      "car: 40%\t(left_x: 1011   top_y:  352   width:   61   height:   50)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00257_MVR.png: Predicted in 145.107000 milli-seconds.\n",
      "car: 48%\t(left_x:    5   top_y:  -10   width: 1276   height:  974)\n",
      "car: 38%\t(left_x:  338   top_y:   66   width:   46   height:   27)\n",
      "bicycle: 48%\t(left_x:  395   top_y:   21   width:   56   height:   57)\n",
      "bicycle: 57%\t(left_x:  436   top_y:    7   width:   68   height:   49)\n",
      "car: 67%\t(left_x: 1103   top_y:  286   width:   61   height:   50)\n",
      "person: 32%\t(left_x: 1132   top_y:  246   width:   17   height:   22)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04146_FV.png: Predicted in 147.942000 milli-seconds.\n",
      "person: 68%\t(left_x:   42   top_y:  440   width:   30   height:   67)\n",
      "car: 91%\t(left_x:   86   top_y:  383   width:  188   height:  112)\n",
      "car: 91%\t(left_x:  295   top_y:  353   width:  114   height:   60)\n",
      "car: 88%\t(left_x:  403   top_y:  340   width:   75   height:   42)\n",
      "car: 78%\t(left_x:  476   top_y:  342   width:   38   height:   24)\n",
      "car: 75%\t(left_x:  510   top_y:  341   width:   37   height:   20)\n",
      "truck: 47%\t(left_x:  542   top_y:  309   width:   49   height:   45)\n",
      "bus: 35%\t(left_x:  542   top_y:  309   width:   49   height:   45)\n",
      "car: 40%\t(left_x:  596   top_y:  339   width:   15   height:   10)\n",
      "truck: 44%\t(left_x:  635   top_y:  332   width:   28   height:   25)\n",
      "car: 49%\t(left_x:  635   top_y:  332   width:   28   height:   24)\n",
      "car: 37%\t(left_x:  702   top_y:  336   width:   12   height:   12)\n",
      "bench: 70%\t(left_x: 1155   top_y:  435   width:  121   height:   92)\n",
      "person: 75%\t(left_x: 1183   top_y:  420   width:   29   height:   35)\n",
      "person: 69%\t(left_x: 1215   top_y:  434   width:   27   height:   36)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03457_MVR.png: Predicted in 144.748000 milli-seconds.\n",
      "bicycle: 68%\t(left_x:   69   top_y:  289   width:   86   height:   86)\n",
      "bicycle: 58%\t(left_x:   75   top_y:  234   width:  127   height:  124)\n",
      "bicycle: 92%\t(left_x:  331   top_y:    4   width:  191   height:  148)\n",
      "bicycle: 59%\t(left_x:  541   top_y:    3   width:  229   height:   73)\n",
      "bicycle: 38%\t(left_x:  645   top_y:    4   width:  124   height:   61)\n",
      "bicycle: 69%\t(left_x:  913   top_y:   66   width:   59   height:   63)\n",
      "person: 33%\t(left_x:  963   top_y:   56   width:   24   height:   32)\n",
      "bicycle: 56%\t(left_x:  975   top_y:  100   width:   47   height:   50)\n",
      "bicycle: 34%\t(left_x: 1024   top_y:   18   width:   50   height:   49)\n",
      "bicycle: 37%\t(left_x: 1026   top_y:  127   width:   23   height:   27)\n",
      "bicycle: 28%\t(left_x: 1029   top_y:  125   width:   30   height:   31)\n",
      "person: 34%\t(left_x: 1039   top_y:  128   width:   21   height:   37)\n",
      "bicycle: 32%\t(left_x: 1040   top_y:  127   width:   21   height:   38)\n",
      "person: 56%\t(left_x: 1079   top_y:  193   width:   33   height:   34)\n",
      "person: 26%\t(left_x: 1123   top_y:  284   width:   16   height:   45)\n",
      "person: 47%\t(left_x: 1133   top_y:  287   width:   27   height:   42)\n",
      "person: 28%\t(left_x: 1136   top_y:  246   width:   17   height:   20)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05500_RV.png: Predicted in 144.620000 milli-seconds.\n",
      "person: 80%\t(left_x:   37   top_y:  396   width:  113   height:  186)\n",
      "bicycle: 32%\t(left_x:   39   top_y:  399   width:  112   height:  180)\n",
      "backpack: 75%\t(left_x:   59   top_y:  376   width:   56   height:   64)\n",
      "bicycle: 69%\t(left_x:  103   top_y:  461   width:   88   height:   93)\n",
      "person: 81%\t(left_x:  312   top_y:  289   width:   40   height:   68)\n",
      "person: 41%\t(left_x:  494   top_y:  263   width:    7   height:   21)\n",
      "person: 50%\t(left_x:  509   top_y:  258   width:   10   height:   27)\n",
      "car: 51%\t(left_x:  595   top_y:  256   width:   12   height:   11)\n",
      "car: 78%\t(left_x:  604   top_y:  252   width:   26   height:   20)\n",
      "car: 88%\t(left_x:  632   top_y:  253   width:   40   height:   26)\n",
      "car: 90%\t(left_x:  684   top_y:  250   width:   68   height:   57)\n",
      "car: 94%\t(left_x:  735   top_y:  250   width:  173   height:  115)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08025_FV.png: Predicted in 144.268000 milli-seconds.\n",
      "car: 54%\t(left_x:    6   top_y:  521   width:   77   height:  141)\n",
      "car: 94%\t(left_x:  193   top_y:  276   width:  222   height:  149)\n",
      "car: 86%\t(left_x:  401   top_y:  301   width:   74   height:   57)\n",
      "car: 88%\t(left_x:  414   top_y:  288   width:   90   height:   51)\n",
      "car: 63%\t(left_x:  498   top_y:  295   width:   28   height:   19)\n",
      "person: 78%\t(left_x:  682   top_y:  291   width:   15   height:   32)\n",
      "car: 90%\t(left_x:  767   top_y:  305   width:  132   height:   57)\n",
      "car: 94%\t(left_x:  833   top_y:  316   width:  179   height:   97)\n",
      "car: 86%\t(left_x:  995   top_y:  361   width:   73   height:   69)\n",
      "car: 78%\t(left_x: 1062   top_y:  393   width:   97   height:   87)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03732_RV.png: Predicted in 147.309000 milli-seconds.\n",
      "car: 41%\t(left_x:   -4   top_y:  491   width: 1281   height:  464)\n",
      "bicycle: 85%\t(left_x:   56   top_y:  374   width:  131   height:  164)\n",
      "bicycle: 48%\t(left_x:   91   top_y:  358   width:  121   height:  135)\n",
      "bicycle: 66%\t(left_x:  136   top_y:  341   width:   86   height:  146)\n",
      "bicycle: 52%\t(left_x:  152   top_y:  339   width:  103   height:  117)\n",
      "motorbike: 75%\t(left_x:  223   top_y:  325   width:   81   height:   59)\n",
      "person: 32%\t(left_x:  228   top_y:  317   width:   71   height:   65)\n",
      "person: 64%\t(left_x:  238   top_y:  303   width:   39   height:   70)\n",
      "person: 45%\t(left_x:  271   top_y:  297   width:   21   height:   39)\n",
      "person: 41%\t(left_x:  318   top_y:  291   width:   16   height:   38)\n",
      "person: 75%\t(left_x:  360   top_y:  276   width:   19   height:   44)\n",
      "motorbike: 73%\t(left_x:  394   top_y:  277   width:   50   height:   36)\n",
      "person: 40%\t(left_x:  459   top_y:  267   width:   13   height:   29)\n",
      "car: 91%\t(left_x:  536   top_y:  246   width:   92   height:   56)\n",
      "car: 45%\t(left_x:  949   top_y:  307   width:   44   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03412_MVL.png: Predicted in 143.931000 milli-seconds.\n",
      "car: 52%\t(left_x:  118   top_y:  280   width:   61   height:   53)\n",
      "person: 28%\t(left_x:  134   top_y:  244   width:   18   height:   18)\n",
      "traffic light: 27%\t(left_x:  147   top_y:  209   width:   21   height:   24)\n",
      "car: 86%\t(left_x:  282   top_y:   49   width:  107   height:   89)\n",
      "person: 64%\t(left_x:  380   top_y:   31   width:   22   height:   44)\n",
      "bicycle: 57%\t(left_x:  388   top_y:   57   width:   29   height:   27)\n",
      "car: 93%\t(left_x:  416   top_y:    3   width:  142   height:   70)\n",
      "person: 86%\t(left_x:  576   top_y:    3   width:   23   height:   32)\n",
      "bicycle: 73%\t(left_x:  619   top_y:   13   width:   63   height:   31)\n",
      "car: 89%\t(left_x:  881   top_y:   88   width:  162   height:  121)\n",
      "person: 38%\t(left_x: 1067   top_y:  218   width:   43   height:   31)\n",
      "person: 47%\t(left_x: 1073   top_y:  226   width:   39   height:   38)\n",
      "person: 33%\t(left_x: 1082   top_y:  239   width:   33   height:   33)\n",
      "traffic light: 26%\t(left_x: 1166   top_y:  227   width:   28   height:   27)\n",
      "car: 53%\t(left_x: 1180   top_y:  397   width:   33   height:   53)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01229_FV.png: Predicted in 144.321000 milli-seconds.\n",
      "car: 67%\t(left_x:   10   top_y:  544   width: 1276   height:  343)\n",
      "car: 27%\t(left_x:   33   top_y:  457   width:   59   height:   28)\n",
      "car: 40%\t(left_x:   95   top_y:  438   width:   53   height:   30)\n",
      "person: 85%\t(left_x:  311   top_y:  358   width:   27   height:   44)\n",
      "person: 32%\t(left_x:  357   top_y:  358   width:   10   height:   26)\n",
      "car: 27%\t(left_x:  522   top_y:  346   width:   13   height:   12)\n",
      "traffic light: 35%\t(left_x:  575   top_y:  292   width:    9   height:   13)\n",
      "car: 38%\t(left_x:  633   top_y:  341   width:   13   height:   11)\n",
      "car: 59%\t(left_x:  633   top_y:  339   width:   23   height:   12)\n",
      "car: 51%\t(left_x:  655   top_y:  341   width:   11   height:   11)\n",
      "car: 70%\t(left_x:  666   top_y:  337   width:   21   height:   17)\n",
      "motorbike: 80%\t(left_x:  766   top_y:  331   width:   58   height:   68)\n",
      "motorbike: 36%\t(left_x:  769   top_y:  300   width:   49   height:   90)\n",
      "person: 86%\t(left_x:  771   top_y:  299   width:   44   height:   79)\n",
      "person: 60%\t(left_x: 1022   top_y:  361   width:   21   height:   47)\n",
      "bicycle: 73%\t(left_x: 1111   top_y:  386   width:   69   height:   70)\n",
      "bicycle: 40%\t(left_x: 1158   top_y:  418   width:   37   height:   50)\n",
      "bicycle: 48%\t(left_x: 1170   top_y:  421   width:   42   height:   55)\n",
      "bicycle: 33%\t(left_x: 1182   top_y:  378   width:   62   height:  107)\n",
      "person: 72%\t(left_x: 1183   top_y:  378   width:   60   height:  108)\n",
      "bicycle: 26%\t(left_x: 1189   top_y:  415   width:   89   height:   98)\n",
      "bicycle: 44%\t(left_x: 1233   top_y:  418   width:   47   height:  100)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07634_RV.png: Predicted in 147.838000 milli-seconds.\n",
      "skateboard: 55%\t(left_x:  827   top_y:  258   width:   20   height:   11)\n",
      "person: 91%\t(left_x:  828   top_y:  161   width:   47   height:  108)\n",
      "person: 94%\t(left_x:  975   top_y:  231   width:  100   height:  160)\n",
      "skateboard: 56%\t(left_x:  977   top_y:  354   width:   63   height:   47)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05909_RV.png: Predicted in 147.522000 milli-seconds.\n",
      "car: 88%\t(left_x:   22   top_y:  453   width:   70   height:   78)\n",
      "person: 28%\t(left_x:   67   top_y:  398   width:   76   height:  114)\n",
      "person: 81%\t(left_x:   98   top_y:  392   width:   48   height:   79)\n",
      "car: 40%\t(left_x:  100   top_y:  392   width:   48   height:   77)\n",
      "car: 72%\t(left_x:  120   top_y:  392   width:   55   height:   48)\n",
      "bicycle: 84%\t(left_x:  329   top_y:  299   width:   59   height:   67)\n",
      "bicycle: 27%\t(left_x:  359   top_y:  297   width:   40   height:   62)\n",
      "bicycle: 67%\t(left_x:  370   top_y:  291   width:   53   height:   71)\n",
      "car: 26%\t(left_x:  389   top_y:  280   width:   46   height:   28)\n",
      "person: 27%\t(left_x:  410   top_y:  274   width:   15   height:   31)\n",
      "car: 91%\t(left_x:  480   top_y:  255   width:   74   height:   43)\n",
      "car: 77%\t(left_x:  614   top_y:  253   width:   26   height:   22)\n",
      "car: 83%\t(left_x:  630   top_y:  255   width:   45   height:   21)\n",
      "car: 68%\t(left_x:  685   top_y:  256   width:   28   height:   17)\n",
      "car: 69%\t(left_x:  696   top_y:  257   width:   21   height:   18)\n",
      "person: 32%\t(left_x:  716   top_y:  254   width:   11   height:   23)\n",
      "person: 26%\t(left_x: 1124   top_y:  372   width:   36   height:   60)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02662_MVR.png: Predicted in 145.708000 milli-seconds.\n",
      "person: 27%\t(left_x:    9   top_y:  637   width:   67   height:   32)\n",
      "person: 31%\t(left_x:   24   top_y:  633   width:   60   height:   30)\n",
      "person: 69%\t(left_x:   56   top_y:  265   width:   96   height:   66)\n",
      "bicycle: 60%\t(left_x:   93   top_y:  322   width:   44   height:   62)\n",
      "bicycle: 42%\t(left_x:  131   top_y:  253   width:   41   height:   60)\n",
      "bicycle: 90%\t(left_x:  397   top_y:    3   width:  259   height:  148)\n",
      "person: 44%\t(left_x:  400   top_y:    3   width:  255   height:  144)\n",
      "person: 78%\t(left_x:  483   top_y:    3   width:  115   height:   88)\n",
      "bicycle: 84%\t(left_x:  681   top_y:    3   width:  137   height:   62)\n",
      "person: 34%\t(left_x:  711   top_y:    3   width:   88   height:   51)\n",
      "person: 49%\t(left_x:  747   top_y:    3   width:   43   height:   44)\n",
      "bicycle: 25%\t(left_x:  838   top_y:   15   width:   33   height:   33)\n",
      "bicycle: 38%\t(left_x:  846   top_y:   13   width:   40   height:   38)\n",
      "bicycle: 56%\t(left_x:  878   top_y:   27   width:   37   height:   41)\n",
      "person: 27%\t(left_x:  961   top_y:   70   width:   19   height:   24)\n",
      "person: 28%\t(left_x:  998   top_y:  104   width:   19   height:   33)\n",
      "person: 37%\t(left_x:  999   top_y:   92   width:   32   height:   45)\n",
      "person: 47%\t(left_x: 1010   top_y:  106   width:   30   height:   36)\n",
      "person: 32%\t(left_x: 1036   top_y:  125   width:   20   height:   21)\n",
      "person: 41%\t(left_x: 1121   top_y:  288   width:   23   height:   43)\n",
      "person: 43%\t(left_x: 1130   top_y:  287   width:   27   height:   41)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02443_FV.png: Predicted in 144.385000 milli-seconds.\n",
      "car: 64%\t(left_x:   25   top_y:  469   width:   41   height:   43)\n",
      "car: 89%\t(left_x:  124   top_y:  402   width:  109   height:   66)\n",
      "person: 31%\t(left_x:  274   top_y:  389   width:   12   height:   17)\n",
      "car: 65%\t(left_x:  308   top_y:  369   width:   53   height:   25)\n",
      "car: 78%\t(left_x:  409   top_y:  355   width:   35   height:   18)\n",
      "car: 52%\t(left_x:  523   top_y:  345   width:   21   height:    8)\n",
      "bus: 70%\t(left_x:  629   top_y:  304   width:   43   height:   55)\n",
      "truck: 52%\t(left_x:  630   top_y:  304   width:   42   height:   54)\n",
      "bus: 90%\t(left_x:  670   top_y:  279   width:   89   height:   81)\n",
      "bicycle: 27%\t(left_x:  757   top_y:  340   width:   18   height:   16)\n",
      "bicycle: 26%\t(left_x:  761   top_y:  339   width:   36   height:   20)\n",
      "bicycle: 34%\t(left_x:  775   top_y:  340   width:   24   height:   19)\n",
      "person: 50%\t(left_x:  796   top_y:  806   width:   18   height:   40)\n",
      "bicycle: 42%\t(left_x:  825   top_y:  344   width:   23   height:   24)\n",
      "bicycle: 37%\t(left_x:  839   top_y:  344   width:   36   height:   29)\n",
      "bicycle: 35%\t(left_x:  852   top_y:  346   width:   36   height:   31)\n",
      "bicycle: 42%\t(left_x:  925   top_y:  360   width:   22   height:   34)\n",
      "bicycle: 56%\t(left_x:  947   top_y:  363   width:   26   height:   35)\n",
      "bicycle: 85%\t(left_x:  982   top_y:  364   width:   47   height:   51)\n",
      "car: 88%\t(left_x: 1028   top_y:  350   width:  252   height:  192)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01472_FV.png: Predicted in 145.495000 milli-seconds.\n",
      "car: 49%\t(left_x:   13   top_y:  554   width: 1274   height:  369)\n",
      "person: 90%\t(left_x:   64   top_y:  416   width:   32   height:   81)\n",
      "bicycle: 89%\t(left_x:  188   top_y:  389   width:   82   height:   70)\n",
      "person: 30%\t(left_x:  188   top_y:  383   width:   81   height:   75)\n",
      "person: 85%\t(left_x:  211   top_y:  354   width:   40   height:   77)\n",
      "backpack: 29%\t(left_x:  235   top_y:  370   width:   17   height:   18)\n",
      "motorbike: 37%\t(left_x:  307   top_y:  360   width:   37   height:   45)\n",
      "bicycle: 42%\t(left_x:  308   top_y:  360   width:   36   height:   44)\n",
      "car: 52%\t(left_x:  332   top_y:  322   width:  118   height:   70)\n",
      "truck: 50%\t(left_x:  333   top_y:  322   width:  118   height:   69)\n",
      "bicycle: 71%\t(left_x:  336   top_y:  361   width:   54   height:   47)\n",
      "bicycle: 31%\t(left_x:  343   top_y:  346   width:   41   height:   57)\n",
      "person: 67%\t(left_x:  352   top_y:  336   width:   28   height:   58)\n",
      "bicycle: 65%\t(left_x:  462   top_y:  347   width:   32   height:   22)\n",
      "car: 29%\t(left_x:  589   top_y:  340   width:   18   height:   10)\n",
      "car: 53%\t(left_x:  590   top_y:  338   width:   27   height:   12)\n",
      "car: 56%\t(left_x:  618   top_y:  338   width:   21   height:   11)\n",
      "car: 32%\t(left_x:  658   top_y:  337   width:   19   height:   10)\n",
      "car: 44%\t(left_x:  697   top_y:  336   width:   29   height:   16)\n",
      "person: 36%\t(left_x:  738   top_y:  334   width:   10   height:   24)\n",
      "person: 32%\t(left_x:  740   top_y:  332   width:   18   height:   27)\n",
      "person: 48%\t(left_x:  747   top_y:  329   width:   12   height:   31)\n",
      "car: 49%\t(left_x:  759   top_y:  327   width:   44   height:   42)\n",
      "truck: 41%\t(left_x:  760   top_y:  326   width:   44   height:   42)\n",
      "motorbike: 29%\t(left_x:  826   top_y:  350   width:   24   height:   33)\n",
      "bicycle: 32%\t(left_x:  826   top_y:  350   width:   23   height:   33)\n",
      "person: 30%\t(left_x: 1038   top_y:  352   width:  186   height:  185)\n",
      "bicycle: 90%\t(left_x: 1038   top_y:  354   width:  188   height:  186)\n",
      "person: 90%\t(left_x: 1124   top_y:  288   width:   85   height:  193)\n",
      "person: 31%\t(left_x: 1223   top_y:  412   width:   33   height:   57)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01876_RV.png: Predicted in 145.017000 milli-seconds.\n",
      "car: 76%\t(left_x:   11   top_y:  267   width:  268   height:  268)\n",
      "car: 94%\t(left_x:  289   top_y:  224   width:  241   height:  150)\n",
      "car: 82%\t(left_x:  557   top_y:  248   width:   39   height:   35)\n",
      "car: 73%\t(left_x:  591   top_y:  252   width:   18   height:   24)\n",
      "car: 92%\t(left_x:  610   top_y:  243   width:   64   height:   53)\n",
      "car: 33%\t(left_x:  700   top_y:  263   width:   19   height:    9)\n",
      "person: 38%\t(left_x:  734   top_y:  260   width:   10   height:   22)\n",
      "bicycle: 43%\t(left_x:  918   top_y:  321   width:   30   height:   27)\n",
      "bicycle: 34%\t(left_x:  938   top_y:  328   width:   21   height:   25)\n",
      "person: 58%\t(left_x:  972   top_y:  316   width:   29   height:   53)\n",
      "bicycle: 39%\t(left_x: 1008   top_y:  362   width:   30   height:   28)\n",
      "bicycle: 29%\t(left_x: 1012   top_y:  364   width:   44   height:   33)\n",
      "bicycle: 33%\t(left_x: 1024   top_y:  369   width:   28   height:   31)\n",
      "bicycle: 47%\t(left_x: 1026   top_y:  368   width:   40   height:   34)\n",
      "bicycle: 47%\t(left_x: 1045   top_y:  376   width:   39   height:   37)\n",
      "bicycle: 61%\t(left_x: 1062   top_y:  390   width:   43   height:   35)\n",
      "bicycle: 53%\t(left_x: 1089   top_y:  408   width:   25   height:   33)\n",
      "car: 91%\t(left_x: 1110   top_y:  435   width:  148   height:  134)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05781_MVL.png: Predicted in 144.509000 milli-seconds.\n",
      "car: 27%\t(left_x:   -4   top_y:   22   width: 1271   height:  939)\n",
      "car: 77%\t(left_x:  286   top_y:   66   width:   60   height:   51)\n",
      "car: 75%\t(left_x:  336   top_y:   22   width:   95   height:   71)\n",
      "truck: 84%\t(left_x:  431   top_y:    3   width:  135   height:   60)\n",
      "person: 30%\t(left_x:  578   top_y:    3   width:   22   height:   35)\n",
      "bicycle: 30%\t(left_x:  597   top_y:    6   width:   33   height:   31)\n",
      "car: 92%\t(left_x:  643   top_y:    2   width:  226   height:   89)\n",
      "motorbike: 28%\t(left_x:  853   top_y:   44   width:   51   height:   53)\n",
      "car: 87%\t(left_x:  922   top_y:  103   width:  205   height:  160)\n",
      "motorbike: 54%\t(left_x: 1102   top_y:  281   width:   50   height:   32)\n",
      "car: 37%\t(left_x: 1161   top_y:  386   width:   30   height:   29)\n",
      "car: 83%\t(left_x: 1166   top_y:  532   width:   90   height:  150)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08091_MVR.png: Predicted in 144.890000 milli-seconds.\n",
      "car: 52%\t(left_x:   75   top_y:  777   width:  118   height:  180)\n",
      "car: 67%\t(left_x:   78   top_y:  240   width:  138   height:  191)\n",
      "car: 72%\t(left_x:  118   top_y:  189   width:  130   height:   95)\n",
      "car: 42%\t(left_x:  137   top_y:  238   width:   78   height:  102)\n",
      "car: 36%\t(left_x:  159   top_y:  190   width:   89   height:   74)\n",
      "car: 79%\t(left_x:  193   top_y:  139   width:   97   height:   63)\n",
      "umbrella: 49%\t(left_x:  290   top_y:    3   width:  118   height:   49)\n",
      "car: 29%\t(left_x:  334   top_y:  109   width:   22   height:   15)\n",
      "person: 86%\t(left_x:  392   top_y:    3   width:  153   height:  206)\n",
      "car: 26%\t(left_x:  501   top_y:    2   width:   52   height:   27)\n",
      "car: 76%\t(left_x:  503   top_y:    2   width:   83   height:   53)\n",
      "car: 76%\t(left_x:  537   top_y:    4   width:   74   height:   54)\n",
      "car: 51%\t(left_x:  590   top_y:    3   width:   42   height:   62)\n",
      "car: 67%\t(left_x:  594   top_y:    2   width:  241   height:   74)\n",
      "person: 83%\t(left_x:  631   top_y:    3   width:   86   height:  164)\n",
      "car: 95%\t(left_x:  707   top_y:    4   width:  345   height:  201)\n",
      "car: 78%\t(left_x: 1022   top_y:  147   width:   66   height:   61)\n",
      "car: 25%\t(left_x: 1065   top_y:  177   width:   50   height:   48)\n",
      "car: 79%\t(left_x: 1074   top_y:  204   width:   74   height:   61)\n",
      "car: 56%\t(left_x: 1096   top_y:  266   width:   68   height:   48)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05509_FV.png: Predicted in 143.988000 milli-seconds.\n",
      "motorbike: 75%\t(left_x:   23   top_y:  451   width:   92   height:  122)\n",
      "bicycle: 73%\t(left_x:  131   top_y:  422   width:   61   height:   74)\n",
      "motorbike: 68%\t(left_x:  241   top_y:  380   width:   85   height:   69)\n",
      "motorbike: 61%\t(left_x:  302   top_y:  362   width:   91   height:   63)\n",
      "motorbike: 46%\t(left_x:  349   top_y:  357   width:   53   height:   47)\n",
      "motorbike: 43%\t(left_x:  370   top_y:  356   width:   40   height:   44)\n",
      "motorbike: 29%\t(left_x:  388   top_y:  359   width:   41   height:   37)\n",
      "person: 85%\t(left_x:  576   top_y:  316   width:   21   height:   50)\n",
      "car: 75%\t(left_x:  609   top_y:  335   width:   20   height:   17)\n",
      "car: 63%\t(left_x:  638   top_y:  330   width:   25   height:   22)\n",
      "truck: 26%\t(left_x:  638   top_y:  330   width:   25   height:   22)\n",
      "bicycle: 60%\t(left_x:  705   top_y:  332   width:   25   height:   35)\n",
      "car: 88%\t(left_x:  804   top_y:  309   width:  161   height:   94)\n",
      "truck: 39%\t(left_x:  814   top_y:  288   width:   94   height:   52)\n",
      "traffic light: 27%\t(left_x:  929   top_y:  302   width:   11   height:   13)\n",
      "car: 82%\t(left_x:  963   top_y:  351   width:  133   height:   66)\n",
      "parking meter: 72%\t(left_x:  990   top_y:  162   width:   82   height:  333)\n",
      "car: 44%\t(left_x: 1057   top_y:  357   width:   38   height:   61)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03537_MVL.png: Predicted in 144.255000 milli-seconds.\n",
      "truck: 49%\t(left_x:  140   top_y:  107   width:  159   height:  147)\n",
      "car: 37%\t(left_x:  141   top_y:  107   width:  158   height:  145)\n",
      "car: 72%\t(left_x:  253   top_y:   68   width:  122   height:   75)\n",
      "person: 88%\t(left_x:  371   top_y:   14   width:   46   height:   94)\n",
      "person: 95%\t(left_x:  669   top_y:    3   width:   97   height:  121)\n",
      "bicycle: 93%\t(left_x:  758   top_y:   12   width:  205   height:  193)\n",
      "person: 91%\t(left_x:  970   top_y:  110   width:   85   height:  102)\n",
      "backpack: 26%\t(left_x:  970   top_y:  110   width:   84   height:  101)\n",
      "backpack: 50%\t(left_x: 1006   top_y:  121   width:   37   height:   45)\n",
      "person: 37%\t(left_x: 1088   top_y:  239   width:   53   height:   41)\n",
      "bicycle: 41%\t(left_x: 1089   top_y:  239   width:   53   height:   41)\n",
      "person: 33%\t(left_x: 1129   top_y:  318   width:   36   height:   37)\n",
      "person: 27%\t(left_x: 1137   top_y:  320   width:   35   height:   44)\n",
      "person: 26%\t(left_x: 1177   top_y:  388   width:   28   height:   18)\n",
      "person: 56%\t(left_x: 1178   top_y:  435   width:   53   height:   43)\n",
      "person: 37%\t(left_x: 1178   top_y:  394   width:   23   height:   29)\n",
      "car: 26%\t(left_x: 1219   top_y:  593   width:   23   height:   23)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01872_RV.png: Predicted in 144.484000 milli-seconds.\n",
      "car: 28%\t(left_x:    2   top_y:  461   width: 1279   height:  492)\n",
      "bicycle: 85%\t(left_x:  171   top_y:  291   width:   84   height:  155)\n",
      "bicycle: 34%\t(left_x:  237   top_y:  312   width:   45   height:  124)\n",
      "bicycle: 57%\t(left_x:  239   top_y:  305   width:   71   height:  110)\n",
      "bicycle: 77%\t(left_x:  245   top_y:  261   width:   96   height:  137)\n",
      "pottedplant: 26%\t(left_x:  261   top_y:   85   width:  143   height:   97)\n",
      "bicycle: 82%\t(left_x:  346   top_y:  249   width:   60   height:   97)\n",
      "bicycle: 74%\t(left_x:  389   top_y:  249   width:   52   height:   91)\n",
      "bicycle: 52%\t(left_x:  423   top_y:  251   width:   36   height:   70)\n",
      "bicycle: 48%\t(left_x:  436   top_y:  251   width:   33   height:   61)\n",
      "bicycle: 80%\t(left_x:  451   top_y:  242   width:   53   height:   66)\n",
      "bicycle: 75%\t(left_x:  532   top_y:  247   width:   38   height:   40)\n",
      "bicycle: 31%\t(left_x:  541   top_y:  249   width:   40   height:   30)\n",
      "bicycle: 54%\t(left_x:  559   top_y:  251   width:   26   height:   26)\n",
      "bicycle: 30%\t(left_x:  581   top_y:  252   width:   16   height:   20)\n",
      "car: 92%\t(left_x:  598   top_y:  234   width:   85   height:   69)\n",
      "car: 48%\t(left_x:  785   top_y:  268   width:   22   height:   19)\n",
      "person: 31%\t(left_x:  789   top_y:  255   width:    6   height:   14)\n",
      "person: 44%\t(left_x:  842   top_y:  275   width:   12   height:   28)\n",
      "person: 58%\t(left_x:  853   top_y:  277   width:   17   height:   33)\n",
      "bicycle: 26%\t(left_x:  990   top_y:  342   width:   16   height:   25)\n",
      "person: 65%\t(left_x: 1135   top_y:  415   width:   36   height:   48)\n",
      "person: 25%\t(left_x: 1142   top_y:  428   width:   28   height:   38)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07097_FV.png: Predicted in 144.493000 milli-seconds.\n",
      "person: 52%\t(left_x:    0   top_y:  432   width:   80   height:  130)\n",
      "person: 85%\t(left_x:   45   top_y:  383   width:   52   height:  102)\n",
      "person: 84%\t(left_x:   72   top_y:  378   width:   51   height:   89)\n",
      "person: 50%\t(left_x:  187   top_y:  342   width:   18   height:   31)\n",
      "car: 90%\t(left_x:  245   top_y:  316   width:  104   height:   62)\n",
      "car: 26%\t(left_x:  340   top_y:  314   width:   26   height:   19)\n",
      "car: 56%\t(left_x:  362   top_y:  308   width:   49   height:   22)\n",
      "car: 47%\t(left_x:  397   top_y:  307   width:   30   height:   15)\n",
      "car: 30%\t(left_x:  418   top_y:  304   width:   21   height:   14)\n",
      "car: 31%\t(left_x:  678   top_y:  285   width:   30   height:    8)\n",
      "car: 45%\t(left_x:  714   top_y:  289   width:   31   height:    9)\n",
      "car: 42%\t(left_x:  749   top_y:  293   width:   38   height:    9)\n",
      "truck: 36%\t(left_x:  785   top_y:  292   width:   40   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03612_MVR.png: Predicted in 145.387000 milli-seconds.\n",
      "car: 42%\t(left_x:   23   top_y:  678   width:   32   height:   26)\n",
      "car: 35%\t(left_x:   63   top_y:  337   width:   60   height:   91)\n",
      "car: 89%\t(left_x:  106   top_y:  178   width:  119   height:  165)\n",
      "car: 25%\t(left_x:  207   top_y:  160   width:   28   height:   32)\n",
      "person: 79%\t(left_x:  213   top_y:  126   width:   50   height:   54)\n",
      "person: 78%\t(left_x:  257   top_y:   96   width:   48   height:   53)\n",
      "car: 94%\t(left_x:  352   top_y:    4   width:  175   height:  105)\n",
      "bench: 26%\t(left_x:  437   top_y:  128   width:   57   height:   46)\n",
      "bicycle: 50%\t(left_x:  573   top_y:    3   width:   23   height:   25)\n",
      "person: 31%\t(left_x:  573   top_y:    2   width:   22   height:   26)\n",
      "bicycle: 53%\t(left_x:  621   top_y:    3   width:   28   height:   23)\n",
      "bicycle: 27%\t(left_x:  648   top_y:    3   width:   36   height:   21)\n",
      "bicycle: 47%\t(left_x:  710   top_y:    3   width:   30   height:   27)\n",
      "bicycle: 26%\t(left_x:  716   top_y:    3   width:   53   height:   28)\n",
      "bicycle: 37%\t(left_x:  744   top_y:    3   width:   32   height:   29)\n",
      "bicycle: 30%\t(left_x:  751   top_y:    3   width:   44   height:   28)\n",
      "person: 88%\t(left_x:  800   top_y:    3   width:   41   height:   74)\n",
      "handbag: 28%\t(left_x:  864   top_y:   60   width:   26   height:   26)\n",
      "person: 75%\t(left_x:  883   top_y:   11   width:   37   height:   83)\n",
      "person: 63%\t(left_x:  901   top_y:   16   width:   27   height:   79)\n",
      "person: 27%\t(left_x:  906   top_y:   37   width:   39   height:   65)\n",
      "person: 34%\t(left_x:  918   top_y:   50   width:   37   height:   49)\n",
      "person: 79%\t(left_x:  934   top_y:   54   width:   53   height:   62)\n",
      "person: 66%\t(left_x:  989   top_y:   93   width:   31   height:   35)\n",
      "person: 51%\t(left_x: 1003   top_y:   13   width:   24   height:   32)\n",
      "person: 34%\t(left_x: 1008   top_y:  104   width:   29   height:   36)\n",
      "car: 46%\t(left_x: 1110   top_y:  286   width:   52   height:   50)\n",
      "person: 26%\t(left_x: 1112   top_y:  286   width:   51   height:   48)\n",
      "person: 35%\t(left_x: 1129   top_y:  285   width:   28   height:   41)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07682_RV.png: Predicted in 144.223000 milli-seconds.\n",
      "car: 40%\t(left_x:  279   top_y:  286   width:   24   height:   17)\n",
      "car: 44%\t(left_x:  292   top_y:  258   width:   30   height:   31)\n",
      "car: 90%\t(left_x:  334   top_y:  205   width:   94   height:   76)\n",
      "car: 90%\t(left_x:  451   top_y:  188   width:   66   height:   52)\n",
      "car: 42%\t(left_x:  542   top_y:  176   width:   58   height:   29)\n",
      "car: 89%\t(left_x:  546   top_y:  178   width:  109   height:   39)\n",
      "car: 94%\t(left_x:  645   top_y:  163   width:  256   height:  121)\n",
      "person: 91%\t(left_x:  953   top_y:  264   width:  198   height:  242)\n",
      "car: 46%\t(left_x:  955   top_y:  262   width:  198   height:  244)\n",
      "skateboard: 42%\t(left_x:  965   top_y:  444   width:  113   height:   64)\n",
      "car: 48%\t(left_x:  984   top_y:  265   width:  119   height:  164)\n",
      "car: 62%\t(left_x:  988   top_y:  307   width:  257   height:  250)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01073_MVR.png: Predicted in 144.032000 milli-seconds.\n",
      "person: 51%\t(left_x:   17   top_y:  583   width:   60   height:   37)\n",
      "bicycle: 60%\t(left_x:   22   top_y:  488   width:   91   height:   60)\n",
      "person: 36%\t(left_x:   28   top_y:  561   width:   29   height:   26)\n",
      "person: 34%\t(left_x:   56   top_y:  369   width:   26   height:   29)\n",
      "person: 54%\t(left_x:   85   top_y:  276   width:   52   height:   66)\n",
      "person: 44%\t(left_x:  111   top_y:  259   width:   37   height:   47)\n",
      "person: 60%\t(left_x:  173   top_y:  175   width:   51   height:   53)\n",
      "person: 29%\t(left_x:  190   top_y:  171   width:   43   height:   44)\n",
      "person: 43%\t(left_x:  201   top_y:  169   width:   39   height:   37)\n",
      "chair: 71%\t(left_x:  213   top_y:  112   width:  189   height:  148)\n",
      "person: 35%\t(left_x:  225   top_y:  109   width:   43   height:   37)\n",
      "diningtable: 68%\t(left_x:  305   top_y:   71   width:  117   height:  148)\n",
      "diningtable: 38%\t(left_x:  308   top_y:   74   width:  113   height:   62)\n",
      "person: 35%\t(left_x:  363   top_y:   11   width:   20   height:   26)\n",
      "chair: 30%\t(left_x:  368   top_y:   15   width:   51   height:   62)\n",
      "person: 47%\t(left_x:  381   top_y:    6   width:   16   height:   21)\n",
      "chair: 87%\t(left_x:  381   top_y:   34   width:  123   height:  165)\n",
      "chair: 32%\t(left_x:  386   top_y:   13   width:   42   height:   61)\n",
      "chair: 54%\t(left_x:  418   top_y:    4   width:   40   height:   69)\n",
      "chair: 45%\t(left_x:  537   top_y:    3   width:   45   height:   50)\n",
      "chair: 26%\t(left_x:  592   top_y:    5   width:   27   height:   34)\n",
      "chair: 92%\t(left_x:  613   top_y:    3   width:  102   height:  125)\n",
      "diningtable: 84%\t(left_x:  672   top_y:   12   width:  103   height:  112)\n",
      "chair: 26%\t(left_x:  695   top_y:    7   width:   96   height:  106)\n",
      "chair: 84%\t(left_x:  746   top_y:   17   width:   80   height:  106)\n",
      "person: 38%\t(left_x:  797   top_y:    2   width:   42   height:   44)\n",
      "person: 33%\t(left_x:  823   top_y:    6   width:   41   height:   49)\n",
      "person: 26%\t(left_x:  843   top_y:    9   width:   22   height:   22)\n",
      "car: 44%\t(left_x: 1103   top_y:  285   width:   59   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01954_MVL.png: Predicted in 143.418000 milli-seconds.\n",
      "car: 41%\t(left_x:    0   top_y:    0   width: 1235   height:  955)\n",
      "car: 58%\t(left_x:  117   top_y:  278   width:   62   height:   55)\n",
      "truck: 73%\t(left_x:  263   top_y:    2   width:  337   height:  124)\n",
      "car: 87%\t(left_x:  587   top_y:    4   width:  138   height:   56)\n",
      "truck: 79%\t(left_x:  735   top_y:    3   width:  193   height:   79)\n",
      "car: 94%\t(left_x:  799   top_y:   61   width:  171   height:   98)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01798_FV.png: Predicted in 144.709000 milli-seconds.\n",
      "car: 55%\t(left_x:    5   top_y:  497   width: 1278   height:  446)\n",
      "car: 50%\t(left_x:   47   top_y:  445   width:   68   height:   55)\n",
      "bicycle: 73%\t(left_x:  317   top_y:  367   width:   45   height:   46)\n",
      "bicycle: 30%\t(left_x:  339   top_y:  363   width:   45   height:   42)\n",
      "bicycle: 54%\t(left_x:  355   top_y:  361   width:   41   height:   43)\n",
      "bicycle: 37%\t(left_x:  366   top_y:  360   width:   42   height:   42)\n",
      "bicycle: 45%\t(left_x:  390   top_y:  354   width:   39   height:   37)\n",
      "bicycle: 35%\t(left_x:  407   top_y:  350   width:   41   height:   36)\n",
      "bicycle: 64%\t(left_x:  426   top_y:  351   width:   35   height:   34)\n",
      "car: 89%\t(left_x:  490   top_y:  339   width:   63   height:   38)\n",
      "car: 50%\t(left_x:  548   top_y:  344   width:   19   height:   21)\n",
      "car: 60%\t(left_x:  556   top_y:  335   width:   28   height:   27)\n",
      "car: 33%\t(left_x:  624   top_y:  340   width:   18   height:   11)\n",
      "car: 75%\t(left_x:  642   top_y:  335   width:   34   height:   26)\n",
      "car: 26%\t(left_x:  683   top_y:  339   width:   13   height:   19)\n",
      "car: 36%\t(left_x:  690   top_y:  331   width:   25   height:   32)\n",
      "car: 62%\t(left_x:  698   top_y:  330   width:   23   height:   35)\n",
      "car: 81%\t(left_x:  713   top_y:  322   width:   68   height:   54)\n",
      "motorbike: 27%\t(left_x:  851   top_y:  343   width:   47   height:   45)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02589_MVL.png: Predicted in 143.582000 milli-seconds.\n",
      "car: 40%\t(left_x:    2   top_y:   -5   width: 1278   height:  974)\n",
      "car: 70%\t(left_x:  121   top_y:  279   width:   55   height:   53)\n",
      "car: 62%\t(left_x:  196   top_y:  127   width:   68   height:   63)\n",
      "bicycle: 58%\t(left_x:  448   top_y:   33   width:   32   height:   26)\n",
      "person: 30%\t(left_x:  454   top_y:   22   width:   25   height:   35)\n",
      "person: 40%\t(left_x:  460   top_y:   21   width:   18   height:   27)\n",
      "car: 91%\t(left_x:  478   top_y:    2   width:  231   height:   70)\n",
      "person: 51%\t(left_x:  768   top_y:   23   width:   36   height:   39)\n",
      "bicycle: 46%\t(left_x:  943   top_y:  127   width:   26   height:   28)\n",
      "person: 31%\t(left_x:  951   top_y:  113   width:   27   height:   39)\n",
      "person: 27%\t(left_x:  972   top_y:  131   width:   33   height:   43)\n",
      "bicycle: 42%\t(left_x:  972   top_y:  143   width:   32   height:   31)\n",
      "person: 53%\t(left_x:  980   top_y:  122   width:   25   height:   46)\n",
      "car: 50%\t(left_x: 1006   top_y:  169   width:   55   height:   56)\n",
      "car: 28%\t(left_x: 1021   top_y:  169   width:   38   height:   40)\n",
      "person: 27%\t(left_x: 1105   top_y:  206   width:   11   height:   14)\n",
      "person: 37%\t(left_x: 1121   top_y:  293   width:   42   height:   44)\n",
      "bicycle: 29%\t(left_x: 1131   top_y:  331   width:   35   height:   29)\n",
      "car: 90%\t(left_x: 1141   top_y:  361   width:  119   height:  177)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04574_FV.png: Predicted in 145.061000 milli-seconds.\n",
      "bicycle: 35%\t(left_x:   14   top_y:  477   width:   27   height:   50)\n",
      "bicycle: 85%\t(left_x:  125   top_y:  405   width:   76   height:   64)\n",
      "person: 74%\t(left_x:  140   top_y:  371   width:   37   height:   69)\n",
      "traffic light: 44%\t(left_x:  206   top_y:  297   width:   16   height:   32)\n",
      "traffic light: 38%\t(left_x:  209   top_y:  285   width:   21   height:   44)\n",
      "traffic light: 35%\t(left_x:  215   top_y:  276   width:   18   height:   51)\n",
      "person: 41%\t(left_x:  218   top_y:  379   width:   21   height:   63)\n",
      "bicycle: 52%\t(left_x:  327   top_y:  361   width:   45   height:   35)\n",
      "person: 29%\t(left_x:  330   top_y:  359   width:   38   height:   37)\n",
      "person: 71%\t(left_x:  338   top_y:  340   width:   20   height:   48)\n",
      "person: 46%\t(left_x:  396   top_y:  346   width:   11   height:   26)\n",
      "person: 28%\t(left_x:  407   top_y:  350   width:   10   height:   23)\n",
      "bus: 93%\t(left_x:  417   top_y:  275   width:  148   height:   99)\n",
      "car: 89%\t(left_x:  532   top_y:  323   width:   66   height:   44)\n",
      "truck: 40%\t(left_x:  585   top_y:  319   width:   32   height:   34)\n",
      "car: 76%\t(left_x:  627   top_y:  334   width:   18   height:   16)\n",
      "truck: 63%\t(left_x:  656   top_y:  278   width:   78   height:   80)\n",
      "bus: 64%\t(left_x:  656   top_y:  278   width:   78   height:   81)\n",
      "bicycle: 64%\t(left_x:  764   top_y:  337   width:   23   height:   31)\n",
      "person: 60%\t(left_x:  848   top_y:  323   width:   26   height:   51)\n",
      "traffic light: 69%\t(left_x:  877   top_y:  171   width:   22   height:   53)\n",
      "bicycle: 72%\t(left_x:  899   top_y:  353   width:   49   height:   53)\n",
      "bicycle: 29%\t(left_x:  903   top_y:  317   width:   38   height:   80)\n",
      "person: 83%\t(left_x:  903   top_y:  316   width:   36   height:   73)\n",
      "bicycle: 90%\t(left_x:  965   top_y:  358   width:   79   height:   71)\n",
      "person: 28%\t(left_x:  965   top_y:  355   width:   79   height:   74)\n",
      "person: 83%\t(left_x:  994   top_y:  330   width:   38   height:   78)\n",
      "person: 87%\t(left_x: 1080   top_y:  350   width:   36   height:   98)\n",
      "handbag: 50%\t(left_x: 1085   top_y:  370   width:   13   height:   21)\n",
      "person: 75%\t(left_x: 1100   top_y:  371   width:   36   height:   85)\n",
      "person: 87%\t(left_x: 1126   top_y:  353   width:   46   height:  116)\n",
      "car: 37%\t(left_x: 1163   top_y:  431   width:   28   height:   25)\n",
      "bicycle: 78%\t(left_x: 1237   top_y:  472   width:   43   height:   75)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07247_RV.png: Predicted in 146.164000 milli-seconds.\n",
      "person: 47%\t(left_x:   91   top_y:  368   width:   36   height:   42)\n",
      "person: 66%\t(left_x:  107   top_y:  351   width:   36   height:   43)\n",
      "person: 32%\t(left_x:  185   top_y:  295   width:   21   height:   46)\n",
      "person: 40%\t(left_x:  195   top_y:  294   width:   37   height:   43)\n",
      "car: 52%\t(left_x:  220   top_y:  277   width:   54   height:   37)\n",
      "car: 94%\t(left_x:  314   top_y:  183   width:  157   height:  100)\n",
      "car: 88%\t(left_x:  451   top_y:  176   width:   99   height:   50)\n",
      "car: 66%\t(left_x:  528   top_y:  183   width:   54   height:   24)\n",
      "car: 63%\t(left_x:  559   top_y:  180   width:   38   height:   21)\n",
      "car: 35%\t(left_x:  592   top_y:  181   width:   20   height:   16)\n",
      "car: 66%\t(left_x:  678   top_y:  185   width:   28   height:   18)\n",
      "car: 52%\t(left_x:  707   top_y:  186   width:   21   height:   23)\n",
      "truck: 38%\t(left_x:  720   top_y:  183   width:   47   height:   36)\n",
      "car: 51%\t(left_x:  721   top_y:  184   width:   47   height:   36)\n",
      "car: 93%\t(left_x:  761   top_y:  184   width:  150   height:   97)\n",
      "car: 27%\t(left_x:  896   top_y:  230   width:   22   height:   25)\n",
      "car: 91%\t(left_x: 1086   top_y:  378   width:  171   height:  182)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07058_RV.png: Predicted in 146.756000 milli-seconds.\n",
      "car: 58%\t(left_x:   42   top_y:  624   width:   22   height:   18)\n",
      "person: 62%\t(left_x:  143   top_y:  326   width:   40   height:   60)\n",
      "person: 80%\t(left_x:  160   top_y:  315   width:   44   height:   58)\n",
      "person: 27%\t(left_x:  244   top_y:  293   width:   18   height:   31)\n",
      "car: 71%\t(left_x:  430   top_y:  199   width:   39   height:   33)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03597_MVR.png: Predicted in 144.500000 milli-seconds.\n",
      "car: 28%\t(left_x:    6   top_y:   11   width: 1276   height:  936)\n",
      "car: 77%\t(left_x:   35   top_y:    4   width:  504   height:  512)\n",
      "truck: 71%\t(left_x:  698   top_y:    2   width:  117   height:   59)\n",
      "car: 29%\t(left_x: 1108   top_y:  285   width:   51   height:   50)\n",
      "person: 25%\t(left_x: 1136   top_y:  288   width:   18   height:   37)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02678_RV.png: Predicted in 144.382000 milli-seconds.\n",
      "car: 44%\t(left_x:   -3   top_y:  483   width: 1280   height:  471)\n",
      "bus: 31%\t(left_x:   80   top_y:  268   width:  173   height:   91)\n",
      "bicycle: 85%\t(left_x:   95   top_y:  368   width:   99   height:  108)\n",
      "person: 83%\t(left_x:  122   top_y:  310   width:   65   height:  117)\n",
      "backpack: 70%\t(left_x:  147   top_y:  325   width:   36   height:   34)\n",
      "car: 95%\t(left_x:  190   top_y:  232   width:  296   height:  231)\n",
      "car: 92%\t(left_x:  488   top_y:  245   width:   97   height:   60)\n",
      "truck: 31%\t(left_x:  575   top_y:  245   width:   37   height:   36)\n",
      "car: 70%\t(left_x:  575   top_y:  245   width:   37   height:   37)\n",
      "truck: 43%\t(left_x:  582   top_y:  213   width:   45   height:   40)\n",
      "car: 92%\t(left_x:  599   top_y:  239   width:  109   height:   80)\n",
      "car: 33%\t(left_x:  626   top_y:  215   width:   54   height:   30)\n",
      "truck: 38%\t(left_x:  626   top_y:  215   width:   54   height:   30)\n",
      "car: 90%\t(left_x:  742   top_y:  262   width:   62   height:   38)\n",
      "person: 64%\t(left_x: 1184   top_y:  445   width:   60   height:   67)\n",
      "person: 57%\t(left_x: 1195   top_y:  460   width:   56   height:   67)\n",
      "person: 30%\t(left_x: 1242   top_y:  472   width:   27   height:   47)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02958_MVR.png: Predicted in 144.417000 milli-seconds.\n",
      "car: 34%\t(left_x:    3   top_y:  -14   width: 1280   height:  978)\n",
      "person: 29%\t(left_x:   52   top_y:  486   width:   19   height:   14)\n",
      "traffic light: 27%\t(left_x:   99   top_y:  308   width:   28   height:   17)\n",
      "car: 83%\t(left_x:  740   top_y:    3   width:   55   height:   28)\n",
      "person: 48%\t(left_x:  768   top_y:   29   width:   25   height:   48)\n",
      "person: 62%\t(left_x:  777   top_y:    5   width:   47   height:   94)\n",
      "person: 81%\t(left_x:  815   top_y:    3   width:   61   height:  105)\n",
      "person: 29%\t(left_x:  865   top_y:   20   width:   72   height:  122)\n",
      "bicycle: 59%\t(left_x:  868   top_y:   48   width:   64   height:   95)\n",
      "person: 42%\t(left_x:  882   top_y:   16   width:   68   height:   95)\n",
      "car: 89%\t(left_x:  942   top_y:   54   width:  122   height:  122)\n",
      "car: 63%\t(left_x: 1108   top_y:  292   width:   38   height:   43)\n",
      "car: 64%\t(left_x: 1125   top_y:  287   width:   29   height:   32)\n",
      "car: 37%\t(left_x: 1135   top_y:  254   width:   17   height:   14)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00198_FV.png: Predicted in 145.310000 milli-seconds.\n",
      "pottedplant: 26%\t(left_x:   33   top_y:  242   width:   51   height:   60)\n",
      "bicycle: 52%\t(left_x:   37   top_y:  407   width:   62   height:  116)\n",
      "bicycle: 37%\t(left_x:   56   top_y:  410   width:  114   height:  113)\n",
      "bicycle: 30%\t(left_x:   58   top_y:  445   width:   53   height:   77)\n",
      "car: 84%\t(left_x:  104   top_y:  269   width:  363   height:  197)\n",
      "car: 31%\t(left_x:  123   top_y:  232   width:  144   height:  324)\n",
      "person: 92%\t(left_x:  124   top_y:  233   width:  143   height:  320)\n",
      "backpack: 73%\t(left_x:  169   top_y:  272   width:   74   height:   96)\n",
      "bicycle: 37%\t(left_x:  479   top_y:  343   width:   23   height:   29)\n",
      "car: 76%\t(left_x:  518   top_y:  326   width:   63   height:   44)\n",
      "car: 54%\t(left_x:  612   top_y:  340   width:   16   height:   11)\n",
      "bicycle: 26%\t(left_x:  711   top_y:  345   width:   15   height:   21)\n",
      "person: 54%\t(left_x:  711   top_y:  332   width:   16   height:   29)\n",
      "motorbike: 26%\t(left_x:  734   top_y:  342   width:   19   height:   18)\n",
      "bicycle: 47%\t(left_x:  734   top_y:  342   width:   18   height:   18)\n",
      "bicycle: 32%\t(left_x:  751   top_y:  343   width:   15   height:   19)\n",
      "person: 26%\t(left_x:  760   top_y:  328   width:   11   height:   33)\n",
      "person: 73%\t(left_x:  765   top_y:  327   width:   15   height:   39)\n",
      "person: 38%\t(left_x:  786   top_y:  338   width:   15   height:   29)\n",
      "bicycle: 81%\t(left_x:  842   top_y:  347   width:   45   height:   37)\n",
      "bicycle: 45%\t(left_x:  964   top_y:  354   width:   60   height:   93)\n",
      "bicycle: 84%\t(left_x:  973   top_y:  338   width:  145   height:  150)\n",
      "bicycle: 46%\t(left_x: 1098   top_y:  366   width:   91   height:  143)\n",
      "bicycle: 76%\t(left_x: 1149   top_y:  375   width:   70   height:  179)\n",
      "bicycle: 85%\t(left_x: 1187   top_y:  389   width:   93   height:  196)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08043_MVR.png: Predicted in 145.278000 milli-seconds.\n",
      "car: 48%\t(left_x:    9   top_y:  471   width:  175   height:  436)\n",
      "car: 73%\t(left_x:   63   top_y:  348   width:   79   height:  123)\n",
      "car: 43%\t(left_x:  139   top_y:  278   width:  963   height:  669)\n",
      "car: 94%\t(left_x:  247   top_y:    2   width:  722   height:  360)\n",
      "person: 75%\t(left_x:  921   top_y:   42   width:   73   height:  147)\n",
      "skateboard: 38%\t(left_x:  965   top_y:  185   width:   43   height:   34)\n",
      "person: 66%\t(left_x:  965   top_y:  106   width:   99   height:  113)\n",
      "person: 65%\t(left_x:  981   top_y:   92   width:   39   height:   49)\n",
      "car: 84%\t(left_x: 1053   top_y:  208   width:  103   height:   72)\n",
      "person: 28%\t(left_x: 1063   top_y:   30   width:   45   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03534_FV.png: Predicted in 144.381000 milli-seconds.\n",
      "backpack: 26%\t(left_x:  390   top_y:  329   width:   18   height:   26)\n",
      "backpack: 33%\t(left_x:  395   top_y:  290   width:   39   height:   90)\n",
      "person: 76%\t(left_x:  397   top_y:  279   width:   44   height:  117)\n",
      "backpack: 49%\t(left_x:  398   top_y:  310   width:   25   height:   32)\n",
      "person: 52%\t(left_x:  430   top_y:  303   width:   21   height:   79)\n",
      "backpack: 26%\t(left_x:  448   top_y:  301   width:   16   height:   35)\n",
      "person: 84%\t(left_x:  449   top_y:  283   width:   38   height:  104)\n",
      "bicycle: 31%\t(left_x:  450   top_y:  283   width:   38   height:  105)\n",
      "person: 30%\t(left_x:  452   top_y:  286   width:   72   height:   96)\n",
      "bicycle: 28%\t(left_x:  455   top_y:  334   width:   42   height:   47)\n",
      "bicycle: 42%\t(left_x:  470   top_y:  329   width:   30   height:   48)\n",
      "person: 85%\t(left_x:  486   top_y:  285   width:   39   height:   93)\n",
      "handbag: 27%\t(left_x:  510   top_y:  311   width:   12   height:   24)\n",
      "person: 27%\t(left_x:  617   top_y:  325   width:   10   height:   26)\n",
      "person: 30%\t(left_x:  671   top_y:  327   width:    8   height:   23)\n",
      "person: 25%\t(left_x:  705   top_y:  335   width:    9   height:   16)\n",
      "person: 27%\t(left_x:  818   top_y:  329   width:   12   height:   38)\n",
      "bicycle: 25%\t(left_x:  839   top_y:  347   width:   22   height:   23)\n",
      "bicycle: 87%\t(left_x:  857   top_y:  348   width:   67   height:   51)\n",
      "person: 31%\t(left_x:  864   top_y:  345   width:   58   height:   54)\n",
      "bicycle: 51%\t(left_x:  869   top_y:  328   width:   46   height:   68)\n",
      "person: 83%\t(left_x:  876   top_y:  321   width:   34   height:   68)\n",
      "person: 39%\t(left_x:  935   top_y:  363   width:    9   height:   24)\n",
      "person: 33%\t(left_x:  947   top_y:  365   width:   14   height:   24)\n",
      "person: 28%\t(left_x:  955   top_y:  365   width:   11   height:   25)\n",
      "person: 51%\t(left_x:  969   top_y:  369   width:   10   height:   33)\n",
      "person: 25%\t(left_x:  983   top_y:  375   width:   11   height:   24)\n",
      "person: 35%\t(left_x: 1003   top_y:  381   width:   16   height:   29)\n",
      "person: 88%\t(left_x: 1056   top_y:  356   width:   39   height:   88)\n",
      "bicycle: 36%\t(left_x: 1057   top_y:  356   width:   37   height:   90)\n",
      "bicycle: 83%\t(left_x: 1075   top_y:  354   width:  103   height:  135)\n",
      "bicycle: 83%\t(left_x: 1134   top_y:  376   width:  145   height:  209)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04832_MVR.png: Predicted in 143.647000 milli-seconds.\n",
      "person: 92%\t(left_x:   19   top_y:  202   width:  275   height:  211)\n",
      "person: 26%\t(left_x:   27   top_y:  384   width:  102   height:   78)\n",
      "bicycle: 55%\t(left_x:   37   top_y:  328   width:  221   height:  136)\n",
      "bicycle: 25%\t(left_x:   41   top_y:  702   width:   64   height:   73)\n",
      "bicycle: 38%\t(left_x:   43   top_y:  195   width:  335   height:  256)\n",
      "bicycle: 44%\t(left_x:   45   top_y:  682   width:   74   height:   80)\n",
      "car: 74%\t(left_x:   53   top_y:  743   width:  141   height:  210)\n",
      "motorbike: 93%\t(left_x:  618   top_y:    5   width:  380   height:  274)\n",
      "person: 79%\t(left_x:  879   top_y:    8   width:  127   height:  242)\n",
      "person: 59%\t(left_x: 1005   top_y:  129   width:   45   height:   58)\n",
      "car: 73%\t(left_x: 1032   top_y:  171   width:   70   height:   65)\n",
      "car: 37%\t(left_x: 1102   top_y:  285   width:   64   height:   53)\n",
      "car: 37%\t(left_x: 1117   top_y:  216   width:   33   height:   28)\n",
      "person: 28%\t(left_x: 1152   top_y:  148   width:   26   height:   34)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00487_MVR.png: Predicted in 144.581000 milli-seconds.\n",
      "bicycle: 35%\t(left_x:    4   top_y:  517   width:  126   height:  169)\n",
      "bicycle: 27%\t(left_x:    7   top_y:  489   width:  147   height:  127)\n",
      "bicycle: 39%\t(left_x:   54   top_y:  482   width:  119   height:   98)\n",
      "bicycle: 29%\t(left_x:   69   top_y:  466   width:  107   height:   86)\n",
      "bicycle: 28%\t(left_x:   94   top_y:  438   width:   94   height:   76)\n",
      "person: 36%\t(left_x:  109   top_y:  292   width:   94   height:   95)\n",
      "motorbike: 87%\t(left_x:  144   top_y:  154   width:  220   height:  212)\n",
      "car: 35%\t(left_x:  166   top_y:  256   width: 1075   height:  689)\n",
      "person: 83%\t(left_x:  418   top_y:   33   width:   32   height:   58)\n",
      "person: 26%\t(left_x:  444   top_y:   30   width:   31   height:   36)\n",
      "person: 27%\t(left_x:  459   top_y:   29   width:   19   height:   37)\n",
      "car: 78%\t(left_x:  482   top_y:    8   width:  115   height:   72)\n",
      "bicycle: 46%\t(left_x:  552   top_y:   15   width:   87   height:   57)\n",
      "bicycle: 41%\t(left_x:  594   top_y:   15   width:   49   height:   53)\n",
      "bicycle: 36%\t(left_x:  626   top_y:    2   width:   24   height:   44)\n",
      "person: 56%\t(left_x:  627   top_y:    2   width:   23   height:   40)\n",
      "bicycle: 33%\t(left_x:  673   top_y:   12   width:   36   height:   29)\n",
      "bicycle: 72%\t(left_x:  806   top_y:   32   width:   41   height:   47)\n",
      "bicycle: 26%\t(left_x:  839   top_y:   57   width:   45   height:   40)\n",
      "person: 35%\t(left_x:  839   top_y:   50   width:   29   height:   41)\n",
      "person: 75%\t(left_x:  920   top_y:   56   width:   50   height:   82)\n",
      "car: 36%\t(left_x: 1101   top_y:  284   width:   61   height:   52)\n",
      "person: 31%\t(left_x: 1126   top_y:  284   width:   28   height:   44)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01127_MVR.png: Predicted in 144.582000 milli-seconds.\n",
      "person: 68%\t(left_x:   29   top_y:  404   width:   74   height:   60)\n",
      "person: 26%\t(left_x:   76   top_y:  712   width:   58   height:   32)\n",
      "person: 27%\t(left_x:   76   top_y:  705   width:   61   height:   28)\n",
      "skateboard: 35%\t(left_x:   85   top_y:  162   width:  177   height:  155)\n",
      "bicycle: 66%\t(left_x:   87   top_y:  160   width:  175   height:  146)\n",
      "person: 26%\t(left_x:   87   top_y:  159   width:  172   height:  143)\n",
      "person: 54%\t(left_x:   89   top_y:  161   width:   98   height:  120)\n",
      "skateboard: 61%\t(left_x:   89   top_y:  233   width:  178   height:  156)\n",
      "bicycle: 33%\t(left_x:  121   top_y:  334   width:   65   height:   48)\n",
      "person: 40%\t(left_x:  168   top_y:  150   width:   32   height:   35)\n",
      "person: 67%\t(left_x:  255   top_y:   74   width:   65   height:   90)\n",
      "person: 93%\t(left_x:  257   top_y:    4   width:  146   height:  160)\n",
      "skateboard: 32%\t(left_x:  295   top_y:  154   width:   15   height:   11)\n",
      "person: 54%\t(left_x:  377   top_y:    3   width:   57   height:   54)\n",
      "person: 62%\t(left_x:  423   top_y:    4   width:   40   height:   44)\n",
      "person: 56%\t(left_x:  655   top_y:    3   width:   21   height:   34)\n",
      "person: 75%\t(left_x:  668   top_y:    3   width:   24   height:   38)\n",
      "person: 90%\t(left_x:  707   top_y:    3   width:   49   height:   46)\n",
      "bicycle: 70%\t(left_x:  846   top_y:   13   width:   75   height:  108)\n",
      "bicycle: 82%\t(left_x:  856   top_y:   15   width:  108   height:  138)\n",
      "bicycle: 71%\t(left_x:  953   top_y:   74   width:   73   height:   98)\n",
      "bicycle: 45%\t(left_x:  994   top_y:    4   width:  102   height:   61)\n",
      "bicycle: 26%\t(left_x: 1007   top_y:  128   width:   47   height:   45)\n",
      "bicycle: 34%\t(left_x: 1039   top_y:  149   width:   31   height:   41)\n",
      "bicycle: 32%\t(left_x: 1050   top_y:  163   width:   31   height:   39)\n",
      "bicycle: 29%\t(left_x: 1078   top_y:  174   width:   24   height:   38)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00423_MVR.png: Predicted in 144.993000 milli-seconds.\n",
      "traffic light: 62%\t(left_x:    3   top_y:  399   width:   29   height:   30)\n",
      "car: 49%\t(left_x:   11   top_y:    9   width: 1270   height:  940)\n",
      "car: 92%\t(left_x:   57   top_y:    6   width:  575   height:  501)\n",
      "person: 29%\t(left_x:  122   top_y:  187   width:   59   height:  105)\n",
      "person: 43%\t(left_x:  865   top_y:   26   width:   26   height:   33)\n",
      "bicycle: 70%\t(left_x:  876   top_y:   50   width:   37   height:   46)\n",
      "person: 86%\t(left_x:  898   top_y:   28   width:   44   height:   74)\n",
      "car: 70%\t(left_x:  984   top_y:   95   width:   44   height:   36)\n",
      "car: 72%\t(left_x:  985   top_y:  110   width:  114   height:  107)\n",
      "person: 30%\t(left_x: 1060   top_y:  194   width:   27   height:   30)\n",
      "car: 33%\t(left_x: 1100   top_y:  286   width:   66   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06314_FV.png: Predicted in 144.032000 milli-seconds.\n",
      "car: 66%\t(left_x:   26   top_y:  456   width:   41   height:   57)\n",
      "car: 71%\t(left_x:   63   top_y:  435   width:   42   height:   48)\n",
      "car: 26%\t(left_x:   88   top_y:  438   width:   25   height:   23)\n",
      "car: 26%\t(left_x:   93   top_y:  429   width:   27   height:   20)\n",
      "car: 45%\t(left_x:   96   top_y:  434   width:   26   height:   22)\n",
      "car: 28%\t(left_x:   99   top_y:  439   width:   17   height:   20)\n",
      "traffic light: 47%\t(left_x:  118   top_y:  389   width:    9   height:   13)\n",
      "car: 34%\t(left_x:  119   top_y:  417   width:   25   height:   22)\n",
      "car: 87%\t(left_x:  142   top_y:  373   width:   88   height:   88)\n",
      "truck: 79%\t(left_x:  214   top_y:  328   width:   59   height:   91)\n",
      "car: 94%\t(left_x:  265   top_y:  319   width:  155   height:  105)\n",
      "car: 86%\t(left_x:  421   top_y:  328   width:   45   height:   24)\n",
      "car: 92%\t(left_x:  843   top_y:  324   width:  120   height:   62)\n",
      "car: 93%\t(left_x:  949   top_y:  338   width:  204   height:  162)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06763_MVR.png: Predicted in 145.413000 milli-seconds.\n",
      "car: 38%\t(left_x:    6   top_y:  -11   width: 1273   height:  968)\n",
      "car: 65%\t(left_x:  343   top_y:   58   width:   68   height:   46)\n",
      "person: 26%\t(left_x: 1121   top_y:  265   width:   25   height:   43)\n",
      "person: 44%\t(left_x: 1126   top_y:  231   width:   16   height:   18)\n",
      "person: 35%\t(left_x: 1131   top_y:  267   width:   18   height:   39)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01740_MVR.png: Predicted in 145.584000 milli-seconds.\n",
      "car: 27%\t(left_x:   13   top_y:    6   width: 1266   height:  951)\n",
      "bicycle: 30%\t(left_x:  118   top_y:  301   width:   31   height:   35)\n",
      "bicycle: 50%\t(left_x:  178   top_y:  200   width:   40   height:   46)\n",
      "bicycle: 43%\t(left_x:  192   top_y:  165   width:   62   height:   53)\n",
      "bicycle: 44%\t(left_x:  239   top_y:  157   width:   27   height:   40)\n",
      "person: 45%\t(left_x:  706   top_y:    4   width:   25   height:   31)\n",
      "bicycle: 81%\t(left_x:  725   top_y:    3   width:   85   height:   45)\n",
      "person: 50%\t(left_x:  842   top_y:    4   width:   27   height:   49)\n",
      "car: 47%\t(left_x: 1109   top_y:  286   width:   51   height:   49)\n",
      "person: 30%\t(left_x: 1133   top_y:  251   width:   16   height:   17)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06259_RV.png: Predicted in 143.781000 milli-seconds.\n",
      "car: 26%\t(left_x:    1   top_y:  567   width: 1275   height:  383)\n",
      "car: 90%\t(left_x:   34   top_y:  341   width:  183   height:  212)\n",
      "car: 75%\t(left_x:  307   top_y:  242   width:   45   height:   42)\n",
      "truck: 26%\t(left_x:  382   top_y:  212   width:   50   height:   38)\n",
      "car: 42%\t(left_x:  384   top_y:  213   width:   46   height:   36)\n",
      "car: 57%\t(left_x:  553   top_y:  182   width:   51   height:   20)\n",
      "car: 90%\t(left_x:  578   top_y:  172   width:   99   height:   39)\n",
      "car: 60%\t(left_x:  688   top_y:  180   width:   44   height:   26)\n",
      "car: 34%\t(left_x:  729   top_y:  184   width:   31   height:   22)\n",
      "car: 79%\t(left_x:  757   top_y:  190   width:   31   height:   19)\n",
      "car: 32%\t(left_x:  820   top_y:  203   width:   14   height:   12)\n",
      "car: 71%\t(left_x:  838   top_y:  209   width:   28   height:   15)\n",
      "car: 31%\t(left_x:  891   top_y:  223   width:   16   height:   11)\n",
      "car: 34%\t(left_x:  913   top_y:  235   width:   25   height:   13)\n",
      "car: 70%\t(left_x:  922   top_y:  239   width:   50   height:   30)\n",
      "car: 61%\t(left_x:  967   top_y:  256   width:   35   height:   22)\n",
      "car: 30%\t(left_x:  972   top_y:  266   width:   63   height:   26)\n",
      "car: 88%\t(left_x:  979   top_y:  269   width:  110   height:   68)\n",
      "car: 90%\t(left_x: 1064   top_y:  327   width:  150   height:  130)\n",
      "person: 43%\t(left_x: 1093   top_y:  309   width:   26   height:   30)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01904_MVR.png: Predicted in 145.358000 milli-seconds.\n",
      "bicycle: 43%\t(left_x:   25   top_y:  586   width:   91   height:   79)\n",
      "bicycle: 37%\t(left_x:   25   top_y:  611   width:   82   height:   77)\n",
      "bicycle: 51%\t(left_x:   31   top_y:  453   width:   92   height:   84)\n",
      "bicycle: 49%\t(left_x:   35   top_y:  549   width:   92   height:   78)\n",
      "bicycle: 58%\t(left_x:  112   top_y:  283   width:   35   height:   39)\n",
      "bicycle: 31%\t(left_x:  143   top_y:  254   width:   28   height:   21)\n",
      "person: 33%\t(left_x:  190   top_y:  178   width:   31   height:   42)\n",
      "bicycle: 32%\t(left_x:  191   top_y:  177   width:   36   height:   45)\n",
      "bicycle: 30%\t(left_x:  213   top_y:  167   width:   29   height:   32)\n",
      "person: 28%\t(left_x:  214   top_y:  166   width:   27   height:   27)\n",
      "bicycle: 42%\t(left_x:  698   top_y:    2   width:   30   height:   24)\n",
      "bicycle: 34%\t(left_x:  698   top_y:    2   width:   61   height:   25)\n",
      "bicycle: 36%\t(left_x:  725   top_y:    1   width:   39   height:   26)\n",
      "bicycle: 28%\t(left_x:  771   top_y:    2   width:   37   height:   28)\n",
      "bicycle: 67%\t(left_x:  799   top_y:    3   width:   50   height:   48)\n",
      "bicycle: 26%\t(left_x:  903   top_y:   45   width:   14   height:   28)\n",
      "person: 52%\t(left_x:  903   top_y:   44   width:   15   height:   29)\n",
      "bicycle: 61%\t(left_x:  977   top_y:  100   width:   44   height:   51)\n",
      "bicycle: 46%\t(left_x:  995   top_y:  111   width:   49   height:   49)\n",
      "bicycle: 35%\t(left_x: 1015   top_y:  130   width:   41   height:   39)\n",
      "bicycle: 38%\t(left_x: 1026   top_y:  135   width:   43   height:   38)\n",
      "bicycle: 43%\t(left_x: 1028   top_y:   35   width:   50   height:   35)\n",
      "bicycle: 54%\t(left_x: 1037   top_y:  149   width:   44   height:   48)\n",
      "bicycle: 40%\t(left_x: 1055   top_y:  156   width:   45   height:   42)\n",
      "bicycle: 45%\t(left_x: 1071   top_y:  172   width:   34   height:   37)\n",
      "bicycle: 54%\t(left_x: 1084   top_y:   85   width:   49   height:   52)\n",
      "car: 30%\t(left_x: 1112   top_y:  286   width:   48   height:   49)\n",
      "person: 29%\t(left_x: 1119   top_y:  287   width:   27   height:   46)\n",
      "person: 50%\t(left_x: 1126   top_y:  285   width:   29   height:   42)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06034_FV.png: Predicted in 145.097000 milli-seconds.\n",
      "car: 47%\t(left_x:  -15   top_y:  508   width: 1220   height:  436)\n",
      "car: 93%\t(left_x:    6   top_y:  243   width:  432   height:  397)\n",
      "person: 32%\t(left_x:  256   top_y:  292   width:   49   height:   42)\n",
      "person: 55%\t(left_x:  298   top_y:  296   width:   34   height:   36)\n",
      "car: 91%\t(left_x:  526   top_y:  320   width:   69   height:   46)\n",
      "car: 50%\t(left_x:  588   top_y:  330   width:   14   height:   19)\n",
      "car: 92%\t(left_x:  599   top_y:  297   width:   92   height:   81)\n",
      "car: 60%\t(left_x:  712   top_y:  322   width:   27   height:   31)\n",
      "car: 88%\t(left_x:  726   top_y:  318   width:   77   height:   55)\n",
      "traffic light: 28%\t(left_x:  753   top_y:  309   width:    6   height:   11)\n",
      "person: 58%\t(left_x:  807   top_y:  335   width:   17   height:   36)\n",
      "bicycle: 29%\t(left_x:  822   top_y:  351   width:   13   height:   23)\n",
      "person: 63%\t(left_x:  833   top_y:  338   width:   13   height:   38)\n",
      "bicycle: 25%\t(left_x:  846   top_y:  355   width:   25   height:   26)\n",
      "person: 29%\t(left_x:  849   top_y:  341   width:   12   height:   21)\n",
      "bicycle: 65%\t(left_x:  858   top_y:  358   width:   41   height:   32)\n",
      "person: 33%\t(left_x:  865   top_y:  340   width:   11   height:   22)\n",
      "person: 49%\t(left_x:  884   top_y:  345   width:   15   height:   31)\n",
      "person: 55%\t(left_x:  899   top_y:  339   width:   13   height:   39)\n",
      "person: 80%\t(left_x:  906   top_y:  347   width:   20   height:   50)\n",
      "person: 37%\t(left_x:  957   top_y:  347   width:   15   height:   48)\n",
      "person: 76%\t(left_x:  993   top_y:  355   width:   31   height:   69)\n",
      "person: 31%\t(left_x: 1006   top_y:  358   width:   24   height:   66)\n",
      "person: 27%\t(left_x: 1016   top_y:  361   width:   16   height:   37)\n",
      "person: 86%\t(left_x: 1056   top_y:  375   width:   33   height:   74)\n",
      "person: 33%\t(left_x: 1219   top_y:  484   width:   43   height:   58)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00950_FV.png: Predicted in 145.589000 milli-seconds.\n",
      "car: 53%\t(left_x:    7   top_y:  518   width: 1278   height:  407)\n",
      "bicycle: 36%\t(left_x:  130   top_y:  437   width:   29   height:   43)\n",
      "bicycle: 41%\t(left_x:  132   top_y:  430   width:   43   height:   50)\n",
      "bicycle: 59%\t(left_x:  144   top_y:  421   width:   41   height:   53)\n",
      "car: 90%\t(left_x:  216   top_y:  371   width:  134   height:   74)\n",
      "person: 61%\t(left_x:  230   top_y:  377   width:   16   height:   27)\n",
      "person: 68%\t(left_x:  326   top_y:  359   width:   12   height:   19)\n",
      "person: 35%\t(left_x:  330   top_y:  358   width:   15   height:   22)\n",
      "person: 34%\t(left_x:  336   top_y:  357   width:   12   height:   26)\n",
      "person: 61%\t(left_x:  339   top_y:  357   width:   24   height:   46)\n",
      "person: 82%\t(left_x:  366   top_y:  352   width:   17   height:   45)\n",
      "car: 85%\t(left_x:  398   top_y:  349   width:   70   height:   38)\n",
      "car: 52%\t(left_x:  462   top_y:  351   width:   29   height:   20)\n",
      "car: 69%\t(left_x:  481   top_y:  346   width:   23   height:   23)\n",
      "truck: 35%\t(left_x:  505   top_y:  338   width:   46   height:   24)\n",
      "car: 42%\t(left_x:  506   top_y:  338   width:   43   height:   24)\n",
      "car: 34%\t(left_x:  564   top_y:  341   width:   14   height:   12)\n",
      "car: 27%\t(left_x:  573   top_y:  343   width:   18   height:   14)\n",
      "car: 28%\t(left_x:  575   top_y:  342   width:   15   height:    9)\n",
      "car: 31%\t(left_x:  577   top_y:  342   width:   20   height:    7)\n",
      "car: 37%\t(left_x:  589   top_y:  342   width:   12   height:    7)\n",
      "car: 32%\t(left_x:  600   top_y:  342   width:   10   height:    7)\n",
      "car: 52%\t(left_x:  616   top_y:  320   width:   59   height:   50)\n",
      "truck: 46%\t(left_x:  616   top_y:  321   width:   59   height:   49)\n",
      "car: 62%\t(left_x:  672   top_y:  337   width:   14   height:   16)\n",
      "person: 37%\t(left_x:  687   top_y:  333   width:    9   height:   20)\n",
      "person: 49%\t(left_x:  697   top_y:  336   width:    8   height:   18)\n",
      "car: 91%\t(left_x:  737   top_y:  322   width:   95   height:   62)\n",
      "car: 95%\t(left_x:  817   top_y:  310   width:  265   height:  156)\n",
      "bicycle: 88%\t(left_x: 1136   top_y:  361   width:  143   height:  219)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06888_FV.png: Predicted in 145.851000 milli-seconds.\n",
      "car: 89%\t(left_x:    1   top_y:  395   width:  143   height:  133)\n",
      "car: 81%\t(left_x:   62   top_y:  386   width:  117   height:   57)\n",
      "car: 85%\t(left_x:  124   top_y:  371   width:  100   height:   40)\n",
      "car: 84%\t(left_x:  200   top_y:  361   width:   68   height:   28)\n",
      "car: 44%\t(left_x:  237   top_y:  359   width:   39   height:   16)\n",
      "car: 48%\t(left_x:  243   top_y:  358   width:   47   height:   15)\n",
      "car: 60%\t(left_x:  260   top_y:  356   width:   31   height:   15)\n",
      "car: 28%\t(left_x:  379   top_y:  322   width:   39   height:   35)\n",
      "car: 85%\t(left_x:  405   top_y:  282   width:  173   height:   75)\n",
      "car: 50%\t(left_x:  577   top_y:  312   width:   19   height:   17)\n",
      "car: 95%\t(left_x:  590   top_y:  259   width:  253   height:  156)\n",
      "car: 89%\t(left_x:  832   top_y:  329   width:   84   height:   47)\n",
      "car: 85%\t(left_x: 1041   top_y:  399   width:   41   height:   28)\n",
      "car: 34%\t(left_x: 1107   top_y:  423   width:   33   height:   19)\n",
      "car: 87%\t(left_x: 1110   top_y:  410   width:   91   height:  124)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04900_RV.png: Predicted in 144.403000 milli-seconds.\n",
      "bicycle: 36%\t(left_x:   11   top_y:  450   width:   62   height:   73)\n",
      "bicycle: 30%\t(left_x:   38   top_y:  452   width:   35   height:   48)\n",
      "bicycle: 80%\t(left_x:   76   top_y:  356   width:  130   height:  160)\n",
      "person: 25%\t(left_x:   88   top_y:  334   width:   91   height:  163)\n",
      "bicycle: 31%\t(left_x:   92   top_y:  323   width:   84   height:  160)\n",
      "person: 84%\t(left_x:   98   top_y:  309   width:   58   height:  140)\n",
      "backpack: 59%\t(left_x:  132   top_y:  324   width:   47   height:   54)\n",
      "bicycle: 38%\t(left_x:  164   top_y:  371   width:   48   height:   54)\n",
      "person: 49%\t(left_x:  205   top_y:  326   width:   27   height:   44)\n",
      "bicycle: 36%\t(left_x:  226   top_y:  329   width:   34   height:   38)\n",
      "person: 43%\t(left_x:  229   top_y:  307   width:   29   height:   40)\n",
      "person: 33%\t(left_x:  231   top_y:  305   width:   38   height:   54)\n",
      "traffic light: 29%\t(left_x:  245   top_y:  235   width:   28   height:   45)\n",
      "person: 83%\t(left_x:  247   top_y:  287   width:   37   height:   81)\n",
      "person: 83%\t(left_x:  287   top_y:  287   width:   40   height:   62)\n",
      "person: 80%\t(left_x:  319   top_y:  279   width:   29   height:   60)\n",
      "motorbike: 52%\t(left_x:  393   top_y:  254   width:   53   height:   91)\n",
      "person: 59%\t(left_x:  393   top_y:  246   width:   54   height:   97)\n",
      "person: 40%\t(left_x:  425   top_y:  249   width:   36   height:   64)\n",
      "motorbike: 68%\t(left_x:  435   top_y:  271   width:   47   height:   52)\n",
      "person: 77%\t(left_x:  467   top_y:  238   width:   35   height:   69)\n",
      "bicycle: 57%\t(left_x:  481   top_y:  262   width:   41   height:   47)\n",
      "person: 40%\t(left_x:  500   top_y:  246   width:   21   height:   41)\n",
      "bicycle: 26%\t(left_x:  506   top_y:  264   width:   23   height:   28)\n",
      "bicycle: 26%\t(left_x:  517   top_y:  261   width:   14   height:   28)\n",
      "person: 33%\t(left_x:  517   top_y:  257   width:   14   height:   31)\n",
      "person: 39%\t(left_x:  559   top_y:  263   width:    8   height:   19)\n",
      "car: 87%\t(left_x:  612   top_y:  250   width:   58   height:   42)\n",
      "truck: 34%\t(left_x:  641   top_y:  236   width:   33   height:   42)\n",
      "bus: 29%\t(left_x:  642   top_y:  236   width:   32   height:   43)\n",
      "car: 92%\t(left_x:  699   top_y:  259   width:   67   height:   35)\n",
      "person: 31%\t(left_x:  876   top_y:  287   width:   12   height:   21)\n",
      "car: 91%\t(left_x:  900   top_y:  297   width:  123   height:   77)\n",
      "person: 48%\t(left_x: 1043   top_y:  343   width:   15   height:   36)\n",
      "truck: 82%\t(left_x: 1115   top_y:  379   width:   47   height:   52)\n",
      "person: 54%\t(left_x: 1145   top_y:  502   width:  120   height:  119)\n",
      "person: 35%\t(left_x: 1157   top_y:  414   width:   15   height:   21)\n",
      "person: 46%\t(left_x: 1218   top_y:  468   width:   21   height:   26)\n",
      "person: 84%\t(left_x: 1224   top_y:  466   width:   42   height:   54)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04363_RV.png: Predicted in 145.345000 milli-seconds.\n",
      "bicycle: 28%\t(left_x:   46   top_y:  387   width:  156   height:   89)\n",
      "bicycle: 75%\t(left_x:   59   top_y:  396   width:  144   height:  133)\n",
      "bicycle: 74%\t(left_x:   97   top_y:  387   width:  107   height:   68)\n",
      "car: 94%\t(left_x:  169   top_y:  282   width:  219   height:  138)\n",
      "truck: 40%\t(left_x:  334   top_y:  263   width:   73   height:   43)\n",
      "car: 32%\t(left_x:  334   top_y:  263   width:   73   height:   42)\n",
      "car: 79%\t(left_x:  400   top_y:  273   width:   27   height:   26)\n",
      "car: 60%\t(left_x:  417   top_y:  268   width:   32   height:   24)\n",
      "car: 47%\t(left_x:  425   top_y:  258   width:   87   height:   41)\n",
      "car: 56%\t(left_x:  472   top_y:  258   width:   40   height:   38)\n",
      "car: 68%\t(left_x:  505   top_y:  254   width:   35   height:   30)\n",
      "car: 42%\t(left_x:  539   top_y:  258   width:   14   height:   19)\n",
      "car: 67%\t(left_x:  552   top_y:  252   width:   29   height:   21)\n",
      "truck: 84%\t(left_x:  614   top_y:  221   width:   48   height:   63)\n",
      "car: 26%\t(left_x:  664   top_y:  258   width:   16   height:   11)\n",
      "car: 44%\t(left_x:  669   top_y:  259   width:   15   height:   11)\n",
      "car: 53%\t(left_x:  694   top_y:  259   width:   17   height:   18)\n",
      "truck: 47%\t(left_x:  707   top_y:  243   width:   47   height:   40)\n",
      "bus: 25%\t(left_x:  707   top_y:  243   width:   47   height:   40)\n",
      "person: 32%\t(left_x:  723   top_y:  251   width:   29   height:   32)\n",
      "person: 55%\t(left_x:  737   top_y:  256   width:   12   height:   29)\n",
      "motorbike: 27%\t(left_x:  765   top_y:  261   width:   20   height:   23)\n",
      "person: 29%\t(left_x:  766   top_y:  260   width:   19   height:   23)\n",
      "motorbike: 61%\t(left_x:  777   top_y:  280   width:   48   height:   51)\n",
      "person: 26%\t(left_x:  778   top_y:  268   width:   44   height:   62)\n",
      "person: 73%\t(left_x:  779   top_y:  246   width:   42   height:   66)\n",
      "car: 90%\t(left_x: 1036   top_y:  385   width:  241   height:  207)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03221_RV.png: Predicted in 147.602000 milli-seconds.\n",
      "car: 46%\t(left_x:    0   top_y:  490   width: 1278   height:  462)\n",
      "pottedplant: 60%\t(left_x:  201   top_y:  345   width:   28   height:   38)\n",
      "bicycle: 80%\t(left_x:  228   top_y:  283   width:  165   height:  176)\n",
      "person: 66%\t(left_x:  360   top_y:  271   width:   25   height:   52)\n",
      "bicycle: 31%\t(left_x:  447   top_y:  275   width:   25   height:   57)\n",
      "bicycle: 61%\t(left_x:  454   top_y:  269   width:   37   height:   58)\n",
      "bicycle: 58%\t(left_x:  472   top_y:  259   width:   41   height:   62)\n",
      "bicycle: 60%\t(left_x:  504   top_y:  259   width:   33   height:   46)\n",
      "bicycle: 33%\t(left_x:  514   top_y:  257   width:   34   height:   46)\n",
      "bicycle: 33%\t(left_x:  536   top_y:  258   width:   38   height:   29)\n",
      "motorbike: 31%\t(left_x:  537   top_y:  259   width:   37   height:   28)\n",
      "car: 68%\t(left_x:  598   top_y:  253   width:   35   height:   29)\n",
      "car: 59%\t(left_x:  684   top_y:  262   width:   21   height:   12)\n",
      "car: 47%\t(left_x:  703   top_y:  260   width:   24   height:   17)\n",
      "car: 84%\t(left_x:  881   top_y:  292   width:   52   height:   42)\n",
      "bicycle: 26%\t(left_x:  950   top_y:  306   width:   25   height:   40)\n",
      "person: 35%\t(left_x:  951   top_y:  305   width:   23   height:   39)\n",
      "bicycle: 40%\t(left_x:  976   top_y:  340   width:   40   height:   31)\n",
      "bicycle: 51%\t(left_x: 1001   top_y:  346   width:   36   height:   27)\n",
      "bicycle: 41%\t(left_x: 1024   top_y:  357   width:   30   height:   31)\n",
      "bicycle: 58%\t(left_x: 1032   top_y:  360   width:   38   height:   32)\n",
      "bicycle: 53%\t(left_x: 1054   top_y:  374   width:   34   height:   31)\n",
      "bicycle: 40%\t(left_x: 1075   top_y:  388   width:   22   height:   33)\n",
      "bicycle: 44%\t(left_x: 1118   top_y:  414   width:   31   height:   34)\n",
      "person: 31%\t(left_x: 1125   top_y:  395   width:   20   height:   38)\n",
      "bicycle: 73%\t(left_x: 1162   top_y:  444   width:   42   height:   43)\n",
      "bicycle: 64%\t(left_x: 1189   top_y:  467   width:   43   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04681_MVR.png: Predicted in 144.568000 milli-seconds.\n",
      "car: 89%\t(left_x:   47   top_y:  175   width:  271   height:  394)\n",
      "person: 47%\t(left_x:  264   top_y:   64   width:   25   height:   33)\n",
      "bicycle: 41%\t(left_x:  515   top_y:    2   width:   49   height:   62)\n",
      "bicycle: 61%\t(left_x:  590   top_y:    3   width:   91   height:   66)\n",
      "bicycle: 30%\t(left_x:  660   top_y:    3   width:   47   height:   49)\n",
      "bicycle: 61%\t(left_x:  691   top_y:    3   width:   59   height:   60)\n",
      "bicycle: 30%\t(left_x:  742   top_y:    3   width:   43   height:   46)\n",
      "bicycle: 30%\t(left_x:  785   top_y:    3   width:   48   height:   50)\n",
      "bicycle: 59%\t(left_x:  880   top_y:   20   width:   37   height:   59)\n",
      "bicycle: 36%\t(left_x:  959   top_y:   59   width:   42   height:   36)\n",
      "car: 52%\t(left_x: 1110   top_y:  286   width:   48   height:   49)\n",
      "person: 26%\t(left_x: 1136   top_y:  253   width:   17   height:   36)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03023_RV.png: Predicted in 145.482000 milli-seconds.\n",
      "car: 29%\t(left_x:    3   top_y:  519   width: 1275   height:  433)\n",
      "bicycle: 61%\t(left_x:   15   top_y:  463   width:   83   height:  122)\n",
      "bicycle: 56%\t(left_x:   29   top_y:  451   width:  100   height:  107)\n",
      "bicycle: 47%\t(left_x:   51   top_y:  483   width:   92   height:  100)\n",
      "bicycle: 84%\t(left_x:   95   top_y:  349   width:  127   height:  168)\n",
      "bicycle: 81%\t(left_x:  143   top_y:  341   width:  126   height:  134)\n",
      "bicycle: 75%\t(left_x:  209   top_y:  324   width:   94   height:  111)\n",
      "bicycle: 25%\t(left_x:  371   top_y:  287   width:   46   height:   66)\n",
      "bicycle: 54%\t(left_x:  373   top_y:  269   width:   91   height:   81)\n",
      "bicycle: 42%\t(left_x:  402   top_y:  266   width:   71   height:   66)\n",
      "bicycle: 49%\t(left_x:  437   top_y:  272   width:   47   height:   57)\n",
      "bicycle: 50%\t(left_x:  446   top_y:  267   width:   53   height:   52)\n",
      "motorbike: 26%\t(left_x:  448   top_y:  257   width:   56   height:   58)\n",
      "bicycle: 38%\t(left_x:  470   top_y:  277   width:   34   height:   38)\n",
      "motorbike: 65%\t(left_x:  491   top_y:  252   width:   54   height:   53)\n",
      "motorbike: 32%\t(left_x:  526   top_y:  255   width:   34   height:   38)\n",
      "bicycle: 29%\t(left_x:  535   top_y:  257   width:   28   height:   34)\n",
      "motorbike: 36%\t(left_x:  559   top_y:  261   width:   23   height:   24)\n",
      "motorbike: 38%\t(left_x:  563   top_y:  261   width:   29   height:   21)\n",
      "motorbike: 34%\t(left_x:  577   top_y:  263   width:   18   height:   18)\n",
      "car: 41%\t(left_x:  636   top_y:  262   width:   12   height:   10)\n",
      "car: 44%\t(left_x:  653   top_y:  262   width:   11   height:    8)\n",
      "car: 69%\t(left_x:  675   top_y:  256   width:   29   height:   25)\n",
      "car: 93%\t(left_x:  725   top_y:  251   width:  153   height:   95)\n",
      "car: 73%\t(left_x:  896   top_y:  304   width:   36   height:   19)\n",
      "car: 77%\t(left_x:  977   top_y:  337   width:   52   height:   27)\n",
      "person: 27%\t(left_x: 1063   top_y:  368   width:   13   height:   19)\n",
      "car: 45%\t(left_x: 1071   top_y:  377   width:   33   height:   23)\n",
      "truck: 60%\t(left_x: 1076   top_y:  352   width:  127   height:  107)\n",
      "person: 26%\t(left_x: 1182   top_y:  441   width:   28   height:   32)\n",
      "person: 31%\t(left_x: 1235   top_y:  494   width:   12   height:   23)\n",
      "person: 32%\t(left_x: 1242   top_y:  488   width:   31   height:   46)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08193_RV.png: Predicted in 145.823000 milli-seconds.\n",
      "car: 42%\t(left_x:   -1   top_y:    0   width: 1282   height:  954)\n",
      "car: 58%\t(left_x:   35   top_y:  445   width:   49   height:   65)\n",
      "car: 91%\t(left_x:   76   top_y:  285   width:  188   height:  184)\n",
      "car: 25%\t(left_x:  118   top_y:  297   width:   41   height:   43)\n",
      "car: 26%\t(left_x:  147   top_y:  276   width:   34   height:   27)\n",
      "car: 27%\t(left_x:  171   top_y:  245   width:   36   height:   39)\n",
      "car: 64%\t(left_x:  307   top_y:  256   width:   19   height:   19)\n",
      "car: 92%\t(left_x:  820   top_y:  203   width:  158   height:   85)\n",
      "suitcase: 46%\t(left_x: 1126   top_y:  485   width:   83   height:   75)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05402_MVL.png: Predicted in 144.044000 milli-seconds.\n",
      "car: 63%\t(left_x:   -2   top_y:   -6   width: 1256   height:  942)\n",
      "car: 29%\t(left_x:  167   top_y:  185   width:   39   height:   34)\n",
      "car: 86%\t(left_x:  188   top_y:  100   width:  122   height:  111)\n",
      "car: 58%\t(left_x:  267   top_y:   82   width:   59   height:   45)\n",
      "car: 94%\t(left_x:  325   top_y:    2   width:  677   height:  324)\n",
      "car: 44%\t(left_x:  853   top_y:    5   width:  328   height:  396)\n",
      "person: 71%\t(left_x: 1121   top_y:  613   width:   85   height:   73)\n",
      "person: 30%\t(left_x: 1152   top_y:  675   width:   84   height:   30)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01900_MVL.png: Predicted in 145.619000 milli-seconds.\n",
      "car: 50%\t(left_x:  117   top_y:  278   width:   60   height:   55)\n",
      "car: 26%\t(left_x:  131   top_y:  239   width:   23   height:   23)\n",
      "car: 68%\t(left_x:  512   top_y:    3   width:   81   height:   42)\n",
      "person: 30%\t(left_x:  588   top_y:    4   width:   11   height:   23)\n",
      "person: 37%\t(left_x:  605   top_y:    3   width:   13   height:   37)\n",
      "person: 67%\t(left_x:  625   top_y:    4   width:   14   height:   35)\n",
      "bicycle: 62%\t(left_x:  661   top_y:   15   width:   29   height:   32)\n",
      "bicycle: 66%\t(left_x:  683   top_y:   14   width:   45   height:   37)\n",
      "bicycle: 67%\t(left_x:  722   top_y:   18   width:   52   height:   42)\n",
      "bicycle: 75%\t(left_x:  770   top_y:   34   width:   50   height:   38)\n",
      "bicycle: 46%\t(left_x:  805   top_y:   49   width:   33   height:   31)\n",
      "bicycle: 41%\t(left_x:  821   top_y:   52   width:   28   height:   38)\n",
      "bicycle: 53%\t(left_x:  834   top_y:   51   width:   23   height:   43)\n",
      "bicycle: 46%\t(left_x:  836   top_y:   53   width:   34   height:   44)\n",
      "bicycle: 48%\t(left_x:  849   top_y:   68   width:   25   height:   34)\n",
      "bicycle: 39%\t(left_x:  898   top_y:   92   width:   28   height:   30)\n",
      "bicycle: 74%\t(left_x:  943   top_y:  120   width:   41   height:   36)\n",
      "bicycle: 62%\t(left_x:  980   top_y:  152   width:   42   height:   30)\n",
      "bicycle: 37%\t(left_x: 1028   top_y:  187   width:   30   height:   37)\n",
      "bicycle: 62%\t(left_x: 1044   top_y:  199   width:   30   height:   40)\n",
      "car: 42%\t(left_x: 1086   top_y:  214   width:   98   height:   70)\n",
      "bicycle: 49%\t(left_x: 1100   top_y:  280   width:   31   height:   33)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00108_RV.png: Predicted in 143.814000 milli-seconds.\n",
      "bus: 60%\t(left_x:   16   top_y:  189   width:  276   height:  282)\n",
      "person: 41%\t(left_x:  103   top_y:  286   width:   66   height:   98)\n",
      "car: 81%\t(left_x:  289   top_y:  317   width:   31   height:   25)\n",
      "car: 40%\t(left_x:  317   top_y:  314   width:   19   height:   12)\n",
      "car: 65%\t(left_x:  339   top_y:  306   width:   27   height:   15)\n",
      "traffic light: 28%\t(left_x:  404   top_y:  260   width:   16   height:   16)\n",
      "traffic light: 55%\t(left_x:  413   top_y:  258   width:    9   height:   17)\n",
      "person: 44%\t(left_x:  545   top_y:  264   width:   10   height:   20)\n",
      "traffic light: 60%\t(left_x:  568   top_y:  234   width:    9   height:   15)\n",
      "car: 88%\t(left_x:  568   top_y:  260   width:   40   height:   24)\n",
      "car: 43%\t(left_x:  604   top_y:  261   width:   12   height:   13)\n",
      "car: 88%\t(left_x:  616   top_y:  253   width:   50   height:   39)\n",
      "person: 26%\t(left_x:  669   top_y:  263   width:    8   height:   16)\n",
      "person: 27%\t(left_x:  688   top_y:  261   width:   10   height:   20)\n",
      "person: 28%\t(left_x:  807   top_y:  271   width:   11   height:   27)\n",
      "person: 55%\t(left_x:  837   top_y:  278   width:   11   height:   24)\n",
      "person: 61%\t(left_x: 1025   top_y:  336   width:   18   height:   33)\n",
      "person: 55%\t(left_x: 1033   top_y:  349   width:   34   height:   35)\n",
      "person: 77%\t(left_x: 1059   top_y:  353   width:   35   height:   53)\n",
      "person: 31%\t(left_x: 1115   top_y:  389   width:   12   height:   26)\n",
      "person: 42%\t(left_x: 1120   top_y:  392   width:   26   height:   32)\n",
      "person: 53%\t(left_x: 1170   top_y:  416   width:   41   height:   62)\n",
      "person: 73%\t(left_x: 1186   top_y:  411   width:   38   height:   75)\n",
      "person: 45%\t(left_x: 1225   top_y:  453   width:   24   height:   35)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02714_MVL.png: Predicted in 144.920000 milli-seconds.\n",
      "car: 54%\t(left_x:  117   top_y:  279   width:   63   height:   54)\n",
      "car: 29%\t(left_x:  226   top_y:  117   width:   27   height:   32)\n",
      "car: 75%\t(left_x:  304   top_y:   62   width:   71   height:   53)\n",
      "bus: 35%\t(left_x:  373   top_y:    2   width:  169   height:   83)\n",
      "truck: 67%\t(left_x:  375   top_y:    3   width:  169   height:   83)\n",
      "car: 92%\t(left_x:  653   top_y:   15   width:  160   height:   74)\n",
      "person: 30%\t(left_x:  984   top_y:  185   width:   22   height:   28)\n",
      "person: 26%\t(left_x: 1030   top_y:  187   width:   20   height:   27)\n",
      "traffic light: 54%\t(left_x: 1134   top_y:   68   width:   32   height:   31)\n",
      "traffic light: 35%\t(left_x: 1159   top_y:  376   width:   10   height:   16)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04660_RV.png: Predicted in 148.345000 milli-seconds.\n",
      "car: 36%\t(left_x:    3   top_y:  468   width: 1270   height:  484)\n",
      "motorbike: 78%\t(left_x:  193   top_y:  312   width:   76   height:  104)\n",
      "motorbike: 68%\t(left_x:  247   top_y:  304   width:   66   height:   77)\n",
      "bicycle: 83%\t(left_x:  329   top_y:  276   width:   70   height:   69)\n",
      "bicycle: 32%\t(left_x:  383   top_y:  273   width:   46   height:   53)\n",
      "motorbike: 67%\t(left_x:  383   top_y:  274   width:   45   height:   51)\n",
      "motorbike: 37%\t(left_x:  404   top_y:  275   width:   50   height:   42)\n",
      "motorbike: 49%\t(left_x:  420   top_y:  267   width:   51   height:   45)\n",
      "motorbike: 44%\t(left_x:  452   top_y:  261   width:   37   height:   40)\n",
      "bicycle: 35%\t(left_x:  453   top_y:  261   width:   37   height:   40)\n",
      "bicycle: 47%\t(left_x:  470   top_y:  257   width:   38   height:   39)\n",
      "bicycle: 32%\t(left_x:  483   top_y:  257   width:   33   height:   36)\n",
      "bicycle: 29%\t(left_x:  498   top_y:  263   width:   23   height:   28)\n",
      "bicycle: 28%\t(left_x:  505   top_y:  264   width:   24   height:   27)\n",
      "bicycle: 43%\t(left_x:  512   top_y:  258   width:   24   height:   30)\n",
      "bicycle: 28%\t(left_x:  520   top_y:  257   width:   26   height:   28)\n",
      "bicycle: 29%\t(left_x:  546   top_y:  259   width:   22   height:   21)\n",
      "bicycle: 32%\t(left_x:  552   top_y:  257   width:   20   height:   21)\n",
      "car: 53%\t(left_x:  583   top_y:  246   width:   22   height:   22)\n",
      "truck: 28%\t(left_x:  583   top_y:  246   width:   21   height:   22)\n",
      "car: 25%\t(left_x:  606   top_y:  250   width:   12   height:   11)\n",
      "car: 92%\t(left_x:  621   top_y:  243   width:   64   height:   48)\n",
      "car: 34%\t(left_x:  683   top_y:  253   width:   18   height:   10)\n",
      "car: 26%\t(left_x:  714   top_y:  244   width:   26   height:   25)\n",
      "car: 50%\t(left_x:  728   top_y:  255   width:   40   height:   18)\n",
      "car: 42%\t(left_x:  760   top_y:  262   width:   23   height:   15)\n",
      "truck: 59%\t(left_x:  774   top_y:  257   width:   57   height:   27)\n",
      "person: 28%\t(left_x:  899   top_y:  282   width:   23   height:   31)\n",
      "person: 34%\t(left_x:  941   top_y:  299   width:   15   height:   30)\n",
      "motorbike: 66%\t(left_x:  992   top_y:  337   width:   52   height:   48)\n",
      "person: 26%\t(left_x:  994   top_y:  329   width:   50   height:   52)\n",
      "person: 35%\t(left_x: 1000   top_y:  326   width:   41   height:   38)\n",
      "bicycle: 27%\t(left_x: 1053   top_y:  361   width:   23   height:   25)\n",
      "bicycle: 55%\t(left_x: 1137   top_y:  414   width:   43   height:   35)\n",
      "bicycle: 30%\t(left_x: 1159   top_y:  431   width:   29   height:   37)\n",
      "bicycle: 30%\t(left_x: 1174   top_y:  437   width:   39   height:   38)\n",
      "bicycle: 40%\t(left_x: 1194   top_y:  446   width:   31   height:   43)\n",
      "bicycle: 31%\t(left_x: 1219   top_y:  458   width:   39   height:   59)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07252_MVR.png: Predicted in 146.689000 milli-seconds.\n",
      "car: 82%\t(left_x:   71   top_y:  249   width:  109   height:  149)\n",
      "car: 73%\t(left_x:  136   top_y:  205   width:   68   height:   60)\n",
      "car: 84%\t(left_x:  178   top_y:  154   width:   72   height:   66)\n",
      "car: 77%\t(left_x:  233   top_y:   90   width:   78   height:   83)\n",
      "car: 79%\t(left_x:  306   top_y:   54   width:   68   height:   66)\n",
      "car: 68%\t(left_x:  376   top_y:   19   width:   34   height:   56)\n",
      "car: 94%\t(left_x:  400   top_y:    2   width:  305   height:  169)\n",
      "car: 92%\t(left_x:  708   top_y:    3   width:  272   height:  127)\n",
      "car: 52%\t(left_x:  891   top_y:   21   width:   95   height:   89)\n",
      "person: 38%\t(left_x:  938   top_y:   19   width:  160   height:  179)\n",
      "person: 49%\t(left_x:  941   top_y:   77   width:  101   height:  119)\n",
      "car: 27%\t(left_x: 1018   top_y:  135   width:   43   height:   48)\n",
      "car: 57%\t(left_x: 1024   top_y:  128   width:   56   height:   52)\n",
      "bench: 32%\t(left_x: 1091   top_y:  187   width:   28   height:   30)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00630_MVL.png: Predicted in 144.131000 milli-seconds.\n",
      "car: 27%\t(left_x:    3   top_y:   -5   width: 1262   height:  963)\n",
      "car: 61%\t(left_x:  117   top_y:  279   width:   65   height:   53)\n",
      "truck: 45%\t(left_x:  162   top_y:  158   width:   81   height:   83)\n",
      "car: 55%\t(left_x:  162   top_y:  158   width:   80   height:   84)\n",
      "person: 25%\t(left_x:  512   top_y:   11   width:   11   height:   23)\n",
      "person: 30%\t(left_x:  542   top_y:    3   width:   13   height:   32)\n",
      "person: 37%\t(left_x:  552   top_y:    1   width:   11   height:   32)\n",
      "bench: 56%\t(left_x:  969   top_y:  135   width:   86   height:   85)\n",
      "person: 54%\t(left_x: 1072   top_y:  219   width:   32   height:   31)\n",
      "person: 46%\t(left_x: 1090   top_y:  220   width:   36   height:   35)\n",
      "traffic light: 35%\t(left_x: 1232   top_y:  570   width:   14   height:   28)\n",
      "traffic light: 27%\t(left_x: 1232   top_y:  564   width:   24   height:   23)\n",
      "traffic light: 42%\t(left_x: 1237   top_y:  563   width:   27   height:   15)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07693_RV.png: Predicted in 145.498000 milli-seconds.\n",
      "person: 59%\t(left_x:  288   top_y:  283   width:   13   height:   25)\n",
      "fire hydrant: 34%\t(left_x:  288   top_y:  284   width:   13   height:   25)\n",
      "person: 81%\t(left_x:  381   top_y:  228   width:   22   height:   39)\n",
      "skateboard: 28%\t(left_x:  387   top_y:  262   width:   15   height:    9)\n",
      "person: 26%\t(left_x:  434   top_y:  229   width:    7   height:   11)\n",
      "person: 31%\t(left_x:  456   top_y:  217   width:   11   height:   18)\n",
      "truck: 32%\t(left_x:  605   top_y:  190   width:   25   height:   22)\n",
      "car: 45%\t(left_x:  711   top_y:  208   width:   27   height:   13)\n",
      "truck: 29%\t(left_x:  819   top_y:  209   width:   48   height:   32)\n",
      "car: 35%\t(left_x:  919   top_y:  262   width:   27   height:   17)\n",
      "person: 92%\t(left_x:  946   top_y:  240   width:  224   height:  305)\n",
      "person: 89%\t(left_x:  952   top_y:  216   width:  128   height:  194)\n",
      "car: 64%\t(left_x:  959   top_y:  266   width:   43   height:   24)\n",
      "skateboard: 37%\t(left_x:  963   top_y:  470   width:   35   height:   24)\n",
      "car: 48%\t(left_x:  996   top_y:  277   width:   28   height:   23)\n",
      "car: 84%\t(left_x: 1127   top_y:  361   width:   47   height:   57)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04091_MVL.png: Predicted in 146.036000 milli-seconds.\n",
      "car: 53%\t(left_x:   -1   top_y:   -7   width: 1282   height:  966)\n",
      "truck: 71%\t(left_x:  327   top_y:   25   width:  135   height:   84)\n",
      "car: 25%\t(left_x:  327   top_y:   26   width:  137   height:   85)\n",
      "person: 25%\t(left_x:  476   top_y:   19   width:   11   height:   28)\n",
      "person: 40%\t(left_x:  489   top_y:   15   width:   21   height:   40)\n",
      "person: 64%\t(left_x:  567   top_y:    5   width:   17   height:   42)\n",
      "person: 47%\t(left_x:  614   top_y:    3   width:   22   height:   51)\n",
      "person: 33%\t(left_x:  628   top_y:    5   width:   13   height:   49)\n",
      "person: 55%\t(left_x:  691   top_y:   11   width:   23   height:   48)\n",
      "truck: 56%\t(left_x:  842   top_y:   25   width:   85   height:   92)\n",
      "person: 26%\t(left_x: 1004   top_y:  337   width:   41   height:   45)\n",
      "car: 28%\t(left_x: 1063   top_y:  421   width:   57   height:   63)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07649_MVR.png: Predicted in 144.897000 milli-seconds.\n",
      "person: 31%\t(left_x:   88   top_y:  421   width:   10   height:   24)\n",
      "car: 90%\t(left_x:  309   top_y:   51   width:  157   height:   80)\n",
      "person: 26%\t(left_x:  571   top_y:    2   width:  190   height:   79)\n",
      "car: 83%\t(left_x:  571   top_y:    3   width:  193   height:   76)\n",
      "person: 83%\t(left_x:  620   top_y:    2   width:   44   height:   88)\n",
      "car: 81%\t(left_x:  886   top_y:   52   width:  137   height:  126)\n",
      "person: 62%\t(left_x:  975   top_y:  113   width:   50   height:   99)\n",
      "car: 33%\t(left_x:  997   top_y:  148   width:   54   height:   55)\n",
      "person: 43%\t(left_x: 1060   top_y:   50   width:   59   height:   50)\n",
      "person: 33%\t(left_x: 1077   top_y:   61   width:   48   height:   47)\n",
      "person: 41%\t(left_x: 1115   top_y:  241   width:   25   height:   29)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06605_MVR.png: Predicted in 143.564000 milli-seconds.\n",
      "car: 50%\t(left_x:   16   top_y:  326   width:  106   height:  163)\n",
      "person: 87%\t(left_x:  222   top_y:  104   width:   54   height:   68)\n",
      "car: 26%\t(left_x:  397   top_y:   17   width:   49   height:   33)\n",
      "car: 87%\t(left_x:  673   top_y:    3   width:  174   height:   59)\n",
      "car: 80%\t(left_x:  839   top_y:    3   width:   95   height:   81)\n",
      "car: 72%\t(left_x:  919   top_y:   31   width:   63   height:   72)\n",
      "car: 37%\t(left_x:  957   top_y:    4   width:   70   height:   38)\n",
      "car: 40%\t(left_x: 1042   top_y:  128   width:   26   height:   27)\n",
      "person: 30%\t(left_x: 1120   top_y:  232   width:   21   height:   58)\n",
      "person: 53%\t(left_x: 1121   top_y:  233   width:   19   height:   36)\n",
      "person: 29%\t(left_x: 1133   top_y:  279   width:   19   height:   29)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03558_FV.png: Predicted in 144.771000 milli-seconds.\n",
      "car: 48%\t(left_x:    6   top_y:  602   width: 1269   height:  252)\n",
      "bicycle: 84%\t(left_x:   80   top_y:  422   width:   82   height:   79)\n",
      "person: 30%\t(left_x:   81   top_y:  409   width:   77   height:   92)\n",
      "person: 76%\t(left_x:  102   top_y:  386   width:   37   height:   91)\n",
      "person: 92%\t(left_x:  182   top_y:  239   width:  110   height:  280)\n",
      "backpack: 51%\t(left_x:  183   top_y:  271   width:   60   height:   92)\n",
      "person: 83%\t(left_x:  267   top_y:  277   width:   71   height:  192)\n",
      "handbag: 28%\t(left_x:  318   top_y:  355   width:   12   height:   28)\n",
      "bicycle: 77%\t(left_x:  390   top_y:  359   width:   31   height:   29)\n",
      "bicycle: 40%\t(left_x:  393   top_y:  345   width:   25   height:   41)\n",
      "person: 75%\t(left_x:  395   top_y:  335   width:   20   height:   43)\n",
      "bicycle: 35%\t(left_x:  478   top_y:  347   width:   15   height:   19)\n",
      "person: 27%\t(left_x:  480   top_y:  343   width:   13   height:   22)\n",
      "car: 63%\t(left_x:  588   top_y:  336   width:   21   height:   16)\n",
      "person: 32%\t(left_x:  684   top_y:  334   width:    9   height:   19)\n",
      "person: 29%\t(left_x:  697   top_y:  332   width:    8   height:   18)\n",
      "person: 35%\t(left_x:  725   top_y:  345   width:   11   height:   19)\n",
      "person: 81%\t(left_x:  750   top_y:  325   width:   15   height:   41)\n",
      "person: 32%\t(left_x:  768   top_y:  340   width:   13   height:   27)\n",
      "person: 80%\t(left_x:  803   top_y:  312   width:   23   height:   72)\n",
      "person: 71%\t(left_x:  819   top_y:  314   width:   24   height:   77)\n",
      "person: 61%\t(left_x:  844   top_y:  325   width:   17   height:   57)\n",
      "person: 76%\t(left_x:  879   top_y:  321   width:   24   height:   78)\n",
      "person: 51%\t(left_x:  954   top_y:  334   width:   26   height:   28)\n",
      "person: 59%\t(left_x: 1003   top_y:  328   width:   43   height:  124)\n",
      "person: 79%\t(left_x: 1024   top_y:  306   width:   57   height:  159)\n",
      "person: 80%\t(left_x: 1062   top_y:  335   width:   48   height:  139)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06381_MVL.png: Predicted in 143.797000 milli-seconds.\n",
      "car: 65%\t(left_x:  105   top_y:  273   width:   63   height:   48)\n",
      "car: 76%\t(left_x:  402   top_y:   18   width:   47   height:   32)\n",
      "car: 88%\t(left_x:  605   top_y:    2   width:  141   height:   43)\n",
      "car: 87%\t(left_x:  732   top_y:    4   width:   61   height:   50)\n",
      "car: 41%\t(left_x: 1023   top_y:  199   width:   18   height:   15)\n",
      "car: 33%\t(left_x: 1159   top_y:  348   width:   45   height:   47)\n",
      "car: 37%\t(left_x: 1160   top_y:  349   width:   49   height:  111)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01283_MVL.png: Predicted in 144.437000 milli-seconds.\n",
      "car: 39%\t(left_x:   -4   top_y:   -7   width: 1263   height:  960)\n",
      "car: 41%\t(left_x:  117   top_y:  278   width:   62   height:   57)\n",
      "car: 38%\t(left_x:  126   top_y:  230   width:   35   height:   31)\n",
      "bench: 32%\t(left_x:  256   top_y:  103   width:   21   height:   24)\n",
      "person: 31%\t(left_x:  257   top_y:  103   width:   20   height:   24)\n",
      "person: 26%\t(left_x:  292   top_y:   79   width:   11   height:   19)\n",
      "person: 55%\t(left_x:  354   top_y:   41   width:   10   height:   22)\n",
      "car: 70%\t(left_x:  362   top_y:   38   width:   36   height:   22)\n",
      "car: 51%\t(left_x:  425   top_y:   14   width:   30   height:   22)\n",
      "car: 50%\t(left_x:  506   top_y:    3   width:   24   height:   15)\n",
      "car: 49%\t(left_x:  507   top_y:    2   width:   60   height:   15)\n",
      "car: 25%\t(left_x:  550   top_y:    2   width:   26   height:   11)\n",
      "car: 44%\t(left_x:  566   top_y:    1   width:   56   height:    9)\n",
      "car: 72%\t(left_x:  636   top_y:    1   width:   69   height:   13)\n",
      "person: 48%\t(left_x:  702   top_y:    5   width:   17   height:   22)\n",
      "truck: 27%\t(left_x:  718   top_y:    2   width:   70   height:   28)\n",
      "car: 54%\t(left_x:  718   top_y:    2   width:   70   height:   28)\n",
      "bird: 46%\t(left_x:  763   top_y:   60   width:   18   height:   12)\n",
      "car: 44%\t(left_x:  819   top_y:   31   width:   18   height:   15)\n",
      "car: 77%\t(left_x:  827   top_y:   32   width:   63   height:   35)\n",
      "car: 87%\t(left_x:  904   top_y:   70   width:   65   height:   43)\n",
      "car: 86%\t(left_x:  978   top_y:  117   width:   64   height:   52)\n",
      "car: 76%\t(left_x: 1088   top_y:  218   width:   54   height:   60)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06851_MVL.png: Predicted in 144.389000 milli-seconds.\n",
      "car: 37%\t(left_x:    0   top_y:   25   width: 1274   height:  938)\n",
      "motorbike: 30%\t(left_x:    0   top_y:   25   width: 1274   height:  938)\n",
      "car: 38%\t(left_x:   96   top_y:  245   width:   65   height:   85)\n",
      "car: 63%\t(left_x:  237   top_y:  449   width:   64   height:  122)\n",
      "car: 95%\t(left_x:  294   top_y:    4   width:  528   height:  237)\n",
      "car: 34%\t(left_x:  300   top_y:    3   width:  123   height:   96)\n",
      "car: 91%\t(left_x:  777   top_y:    5   width:  440   height:  434)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04549_MVR.png: Predicted in 144.521000 milli-seconds.\n",
      "car: 33%\t(left_x:    6   top_y:  630   width:   24   height:   15)\n",
      "car: 49%\t(left_x:   10   top_y:  643   width:   30   height:   27)\n",
      "car: 86%\t(left_x:   35   top_y:  322   width:  149   height:  208)\n",
      "car: 92%\t(left_x:  169   top_y:   14   width:  319   height:  310)\n",
      "bicycle: 26%\t(left_x:  889   top_y:   28   width:   34   height:   47)\n",
      "person: 76%\t(left_x:  918   top_y:   39   width:   42   height:   57)\n",
      "car: 27%\t(left_x: 1111   top_y:  287   width:   46   height:   47)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06325_MVL.png: Predicted in 146.933000 milli-seconds.\n",
      "car: 61%\t(left_x:  112   top_y:  271   width:   45   height:   49)\n",
      "car: 38%\t(left_x:  122   top_y:  237   width:   17   height:   15)\n",
      "person: 33%\t(left_x:  326   top_y:   58   width:   31   height:   54)\n",
      "car: 47%\t(left_x:  374   top_y:    2   width:  219   height:   79)\n",
      "truck: 54%\t(left_x:  376   top_y:    3   width:  217   height:   79)\n",
      "kite: 80%\t(left_x:  834   top_y:  197   width:  169   height:   89)\n",
      "person: 65%\t(left_x:  869   top_y:   58   width:   28   height:   44)\n",
      "person: 34%\t(left_x:  983   top_y:  114   width:   10   height:   12)\n",
      "car: 27%\t(left_x: 1071   top_y:  206   width:   41   height:   57)\n",
      "bench: 33%\t(left_x: 1071   top_y:  206   width:   42   height:   57)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02671_RV.png: Predicted in 143.992000 milli-seconds.\n",
      "car: 34%\t(left_x:    1   top_y:  468   width: 1279   height:  482)\n",
      "bicycle: 30%\t(left_x:  200   top_y:  274   width:   71   height:  109)\n",
      "person: 89%\t(left_x:  200   top_y:  276   width:   71   height:  100)\n",
      "bicycle: 80%\t(left_x:  202   top_y:  319   width:   64   height:   79)\n",
      "bicycle: 86%\t(left_x:  310   top_y:  278   width:   86   height:   96)\n",
      "person: 87%\t(left_x:  316   top_y:  225   width:   62   height:  120)\n",
      "bicycle: 79%\t(left_x:  416   top_y:  271   width:   44   height:   44)\n",
      "bicycle: 31%\t(left_x:  424   top_y:  246   width:   33   height:   65)\n",
      "person: 75%\t(left_x:  429   top_y:  242   width:   29   height:   59)\n",
      "bicycle: 28%\t(left_x:  472   top_y:  265   width:   31   height:   21)\n",
      "person: 28%\t(left_x:  524   top_y:  260   width:   18   height:   27)\n",
      "bicycle: 40%\t(left_x:  524   top_y:  262   width:   15   height:   25)\n",
      "bicycle: 29%\t(left_x:  533   top_y:  263   width:   11   height:   23)\n",
      "person: 41%\t(left_x:  558   top_y:  255   width:   10   height:   20)\n",
      "car: 56%\t(left_x:  639   top_y:  263   width:   15   height:    8)\n",
      "car: 92%\t(left_x:  796   top_y:  276   width:  157   height:   81)\n",
      "car: 28%\t(left_x:  905   top_y:  300   width:   54   height:   31)\n",
      "person: 62%\t(left_x:  956   top_y:  310   width:   15   height:   37)\n",
      "person: 49%\t(left_x:  977   top_y:  317   width:   12   height:   32)\n",
      "person: 27%\t(left_x: 1028   top_y:  345   width:   16   height:   37)\n",
      "car: 92%\t(left_x: 1051   top_y:  385   width:  174   height:  134)\n",
      "car: 33%\t(left_x: 1212   top_y:  425   width:   63   height:  116)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01544_MVR.png: Predicted in 145.894000 milli-seconds.\n",
      "person: 60%\t(left_x:    8   top_y:  551   width:  102   height:   48)\n",
      "car: 34%\t(left_x:   11   top_y:   -3   width: 1272   height:  961)\n",
      "truck: 46%\t(left_x:   61   top_y:  717   width:   56   height:   68)\n",
      "bench: 41%\t(left_x:  186   top_y:  194   width:   38   height:   35)\n",
      "car: 62%\t(left_x: 1106   top_y:  286   width:   55   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05569_RV.png: Predicted in 144.434000 milli-seconds.\n",
      "bicycle: 71%\t(left_x:   40   top_y:  485   width:  107   height:  138)\n",
      "bicycle: 79%\t(left_x:   80   top_y:  486   width:  122   height:  144)\n",
      "bicycle: 60%\t(left_x:  130   top_y:  397   width:  105   height:  121)\n",
      "bicycle: 66%\t(left_x:  186   top_y:  403   width:  111   height:  107)\n",
      "bicycle: 32%\t(left_x:  214   top_y:  379   width:   96   height:   88)\n",
      "bicycle: 73%\t(left_x:  242   top_y:  367   width:  105   height:   96)\n",
      "motorbike: 78%\t(left_x:  485   top_y:  263   width:   78   height:   57)\n",
      "motorbike: 39%\t(left_x:  543   top_y:  260   width:   33   height:   38)\n",
      "motorbike: 53%\t(left_x:  547   top_y:  257   width:   41   height:   36)\n",
      "motorbike: 37%\t(left_x:  565   top_y:  259   width:   34   height:   31)\n",
      "motorbike: 32%\t(left_x:  578   top_y:  258   width:   26   height:   27)\n",
      "car: 28%\t(left_x:  581   top_y:  246   width:   40   height:   35)\n",
      "truck: 42%\t(left_x:  581   top_y:  246   width:   39   height:   34)\n",
      "car: 28%\t(left_x:  613   top_y:  260   width:   11   height:   15)\n",
      "car: 29%\t(left_x:  627   top_y:  256   width:   18   height:   13)\n",
      "car: 29%\t(left_x:  644   top_y:  259   width:   13   height:    9)\n",
      "car: 41%\t(left_x:  657   top_y:  260   width:   12   height:    9)\n",
      "person: 59%\t(left_x:  762   top_y:  255   width:   18   height:   37)\n",
      "parking meter: 50%\t(left_x:  938   top_y:  306   width:   13   height:   15)\n",
      "person: 41%\t(left_x: 1071   top_y:  304   width:   42   height:   38)\n",
      "person: 48%\t(left_x: 1142   top_y:  548   width:   39   height:   54)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00049_RV.png: Predicted in 144.432000 milli-seconds.\n",
      "bus: 91%\t(left_x:  346   top_y:  235   width:  129   height:   92)\n",
      "car: 74%\t(left_x:  428   top_y:  262   width:   67   height:   40)\n",
      "car: 67%\t(left_x:  534   top_y:  261   width:   15   height:   16)\n",
      "car: 53%\t(left_x:  543   top_y:  256   width:   43   height:   27)\n",
      "truck: 46%\t(left_x:  545   top_y:  256   width:   41   height:   27)\n",
      "car: 78%\t(left_x:  587   top_y:  253   width:   21   height:   19)\n",
      "car: 79%\t(left_x:  603   top_y:  252   width:   41   height:   29)\n",
      "person: 87%\t(left_x:  905   top_y:  264   width:   33   height:   69)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01170_RV.png: Predicted in 144.910000 milli-seconds.\n",
      "car: 44%\t(left_x:   -4   top_y:  502   width: 1282   height:  451)\n",
      "person: 80%\t(left_x:   13   top_y:  451   width:   41   height:   70)\n",
      "person: 38%\t(left_x:   51   top_y:  414   width:   23   height:   46)\n",
      "pottedplant: 41%\t(left_x:  175   top_y:  193   width:  164   height:  215)\n",
      "person: 87%\t(left_x:  345   top_y:  248   width:   24   height:  102)\n",
      "motorbike: 83%\t(left_x:  364   top_y:  247   width:  100   height:   99)\n",
      "person: 36%\t(left_x:  398   top_y:  253   width:   19   height:   42)\n",
      "motorbike: 72%\t(left_x:  443   top_y:  268   width:   77   height:   52)\n",
      "person: 25%\t(left_x:  456   top_y:  261   width:   15   height:   20)\n",
      "person: 44%\t(left_x:  469   top_y:  254   width:   15   height:   22)\n",
      "person: 33%\t(left_x:  487   top_y:  258   width:   11   height:   17)\n",
      "bicycle: 57%\t(left_x:  518   top_y:  268   width:   36   height:   38)\n",
      "bicycle: 37%\t(left_x:  533   top_y:  265   width:   39   height:   37)\n",
      "bicycle: 39%\t(left_x:  550   top_y:  263   width:   26   height:   36)\n",
      "bicycle: 37%\t(left_x:  567   top_y:  264   width:   23   height:   32)\n",
      "car: 60%\t(left_x:  646   top_y:  262   width:   14   height:   11)\n",
      "car: 41%\t(left_x:  661   top_y:  261   width:   14   height:   13)\n",
      "car: 61%\t(left_x:  672   top_y:  263   width:   17   height:   14)\n",
      "car: 87%\t(left_x:  686   top_y:  260   width:   47   height:   33)\n",
      "car: 79%\t(left_x:  730   top_y:  269   width:   45   height:   26)\n",
      "person: 30%\t(left_x:  775   top_y:  268   width:   13   height:   29)\n",
      "car: 83%\t(left_x:  780   top_y:  256   width:  144   height:   87)\n",
      "car: 94%\t(left_x:  889   top_y:  304   width:  238   height:  146)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02633_RV.png: Predicted in 145.325000 milli-seconds.\n",
      "motorbike: 57%\t(left_x:  319   top_y:  293   width:   54   height:   45)\n",
      "truck: 66%\t(left_x:  399   top_y:  194   width:  177   height:  151)\n",
      "car: 37%\t(left_x:  399   top_y:  194   width:  177   height:  151)\n",
      "car: 83%\t(left_x:  574   top_y:  259   width:   28   height:   21)\n",
      "car: 65%\t(left_x:  611   top_y:  259   width:   15   height:   12)\n",
      "car: 46%\t(left_x:  647   top_y:  256   width:   14   height:    8)\n",
      "car: 69%\t(left_x:  657   top_y:  254   width:   47   height:   28)\n",
      "car: 34%\t(left_x:  658   top_y:  251   width:   18   height:   11)\n",
      "car: 28%\t(left_x:  737   top_y:  165   width:  281   height:  211)\n",
      "truck: 70%\t(left_x:  737   top_y:  165   width:  283   height:  211)\n",
      "person: 28%\t(left_x: 1064   top_y:  342   width:   42   height:   72)\n",
      "person: 75%\t(left_x: 1072   top_y:  330   width:   22   height:   31)\n",
      "person: 63%\t(left_x: 1076   top_y:  340   width:   31   height:   36)\n",
      "person: 87%\t(left_x: 1109   top_y:  356   width:   43   height:   86)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01293_FV.png: Predicted in 145.110000 milli-seconds.\n",
      "car: 93%\t(left_x:   20   top_y:  364   width:  215   height:  160)\n",
      "person: 36%\t(left_x:  107   top_y:  390   width:   29   height:   27)\n",
      "person: 30%\t(left_x:  270   top_y:  371   width:   19   height:   36)\n",
      "truck: 71%\t(left_x:  324   top_y:  347   width:   45   height:   35)\n",
      "bicycle: 41%\t(left_x:  386   top_y:  349   width:   23   height:   48)\n",
      "bicycle: 72%\t(left_x:  390   top_y:  333   width:   77   height:   59)\n",
      "bicycle: 41%\t(left_x:  480   top_y:  334   width:   28   height:   21)\n",
      "person: 29%\t(left_x:  480   top_y:  334   width:   24   height:   22)\n",
      "car: 79%\t(left_x:  506   top_y:  329   width:   54   height:   21)\n",
      "car: 72%\t(left_x:  558   top_y:  327   width:   42   height:   19)\n",
      "car: 29%\t(left_x:  649   top_y:  332   width:   21   height:   10)\n",
      "car: 28%\t(left_x:  741   top_y:  334   width:   23   height:   14)\n",
      "car: 63%\t(left_x:  811   top_y:  336   width:   36   height:   27)\n",
      "car: 27%\t(left_x: 1073   top_y:  406   width:   27   height:   19)\n",
      "bicycle: 49%\t(left_x: 1138   top_y:  432   width:   36   height:   29)\n",
      "person: 75%\t(left_x: 1176   top_y:  404   width:   49   height:   93)\n",
      "bicycle: 56%\t(left_x: 1176   top_y:  457   width:   28   height:   43)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03615_RV.png: Predicted in 145.666000 milli-seconds.\n",
      "car: 54%\t(left_x:   -2   top_y:  491   width: 1281   height:  463)\n",
      "person: 42%\t(left_x:   83   top_y:  419   width:   24   height:   36)\n",
      "bicycle: 33%\t(left_x:   83   top_y:  417   width:   25   height:   36)\n",
      "bicycle: 46%\t(left_x:   87   top_y:  401   width:   36   height:   47)\n",
      "bicycle: 58%\t(left_x:   99   top_y:  389   width:   40   height:   48)\n",
      "bicycle: 42%\t(left_x:  112   top_y:  382   width:   42   height:   45)\n",
      "bicycle: 51%\t(left_x:  118   top_y:  370   width:   43   height:   53)\n",
      "bicycle: 28%\t(left_x:  124   top_y:  364   width:   47   height:   43)\n",
      "person: 92%\t(left_x:  149   top_y:  314   width:   76   height:  123)\n",
      "person: 81%\t(left_x:  281   top_y:  276   width:   51   height:   86)\n",
      "person: 68%\t(left_x:  301   top_y:  272   width:   44   height:   79)\n",
      "backpack: 27%\t(left_x:  333   top_y:  333   width:   18   height:   18)\n",
      "handbag: 31%\t(left_x:  363   top_y:  254   width:   38   height:   80)\n",
      "person: 83%\t(left_x:  365   top_y:  254   width:   38   height:   80)\n",
      "handbag: 32%\t(left_x:  369   top_y:  269   width:   24   height:   38)\n",
      "handbag: 25%\t(left_x:  371   top_y:  275   width:   20   height:   18)\n",
      "person: 30%\t(left_x:  516   top_y:  258   width:   13   height:   26)\n",
      "car: 54%\t(left_x:  562   top_y:  259   width:   18   height:   14)\n",
      "car: 50%\t(left_x:  579   top_y:  257   width:   17   height:   11)\n",
      "car: 71%\t(left_x:  619   top_y:  257   width:   26   height:   16)\n",
      "car: 73%\t(left_x:  647   top_y:  257   width:   14   height:   12)\n",
      "motorbike: 46%\t(left_x:  673   top_y:  262   width:   11   height:   16)\n",
      "car: 91%\t(left_x:  693   top_y:  240   width:   94   height:   68)\n",
      "person: 25%\t(left_x: 1116   top_y:  409   width:   37   height:   35)\n",
      "person: 61%\t(left_x: 1141   top_y:  406   width:   26   height:   43)\n",
      "traffic light: 36%\t(left_x: 1154   top_y:  338   width:   22   height:   31)\n",
      "person: 70%\t(left_x: 1170   top_y:  423   width:   33   height:   54)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05331_FV.png: Predicted in 144.792000 milli-seconds.\n",
      "car: 89%\t(left_x:  169   top_y:  332   width:  171   height:  122)\n",
      "car: 87%\t(left_x:  423   top_y:  323   width:   95   height:   57)\n",
      "parking meter: 45%\t(left_x:  449   top_y:  322   width:   16   height:   25)\n",
      "truck: 35%\t(left_x:  512   top_y:  325   width:   37   height:   37)\n",
      "car: 58%\t(left_x:  512   top_y:  325   width:   37   height:   37)\n",
      "car: 31%\t(left_x:  543   top_y:  333   width:   19   height:   21)\n",
      "car: 33%\t(left_x:  547   top_y:  332   width:   23   height:   23)\n",
      "car: 55%\t(left_x:  558   top_y:  330   width:   15   height:   23)\n",
      "truck: 76%\t(left_x:  573   top_y:  325   width:   32   height:   31)\n",
      "car: 77%\t(left_x:  619   top_y:  335   width:   23   height:   16)\n",
      "car: 27%\t(left_x:  662   top_y:  338   width:   19   height:   13)\n",
      "car: 29%\t(left_x:  853   top_y:  348   width:   27   height:   18)\n",
      "traffic light: 82%\t(left_x:  856   top_y:  159   width:   31   height:   56)\n",
      "traffic light: 68%\t(left_x:  879   top_y:  295   width:   12   height:   28)\n",
      "bicycle: 87%\t(left_x:  909   top_y:  332   width:  120   height:  105)\n",
      "person: 88%\t(left_x: 1154   top_y:  344   width:   57   height:  129)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04551_RV.png: Predicted in 144.303000 milli-seconds.\n",
      "car: 38%\t(left_x:    1   top_y:  290   width: 1277   height:  659)\n",
      "car: 88%\t(left_x:    6   top_y:  409   width:  158   height:  185)\n",
      "car: 94%\t(left_x:  192   top_y:  263   width:  249   height:  179)\n",
      "bicycle: 36%\t(left_x:  435   top_y:  267   width:   38   height:   38)\n",
      "bicycle: 37%\t(left_x:  456   top_y:  264   width:   34   height:   39)\n",
      "bicycle: 51%\t(left_x:  477   top_y:  266   width:   31   height:   35)\n",
      "car: 82%\t(left_x:  503   top_y:  249   width:   54   height:   38)\n",
      "car: 66%\t(left_x:  552   top_y:  258   width:   22   height:   19)\n",
      "car: 62%\t(left_x:  635   top_y:  257   width:   14   height:   13)\n",
      "car: 78%\t(left_x:  711   top_y:  260   width:   32   height:   25)\n",
      "car: 90%\t(left_x:  773   top_y:  270   width:   71   height:   43)\n",
      "car: 93%\t(left_x:  838   top_y:  273   width:  152   height:   97)\n",
      "car: 91%\t(left_x: 1006   top_y:  363   width:  257   height:  195)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05565_RV.png: Predicted in 144.894000 milli-seconds.\n",
      "car: 27%\t(left_x:    2   top_y:  634   width: 1278   height:  319)\n",
      "person: 72%\t(left_x:  172   top_y:  313   width:   68   height:  129)\n",
      "handbag: 28%\t(left_x:  172   top_y:  314   width:   66   height:  127)\n",
      "handbag: 45%\t(left_x:  175   top_y:  333   width:   24   height:   55)\n",
      "handbag: 27%\t(left_x:  191   top_y:  347   width:   39   height:   61)\n",
      "handbag: 51%\t(left_x:  199   top_y:  365   width:   27   height:   34)\n",
      "skateboard: 66%\t(left_x:  212   top_y:  429   width:   31   height:   14)\n",
      "person: 92%\t(left_x:  398   top_y:  250   width:   40   height:   91)\n",
      "person: 90%\t(left_x:  442   top_y:  246   width:   29   height:   83)\n",
      "car: 90%\t(left_x:  522   top_y:  255   width:   68   height:   48)\n",
      "car: 75%\t(left_x:  589   top_y:  259   width:   30   height:   23)\n",
      "car: 40%\t(left_x:  619   top_y:  264   width:   15   height:   12)\n",
      "car: 32%\t(left_x:  629   top_y:  266   width:   18   height:    9)\n",
      "car: 40%\t(left_x:  637   top_y:  266   width:   13   height:    8)\n",
      "car: 37%\t(left_x:  648   top_y:  265   width:   14   height:   10)\n",
      "car: 52%\t(left_x:  650   top_y:  265   width:   23   height:   12)\n",
      "car: 34%\t(left_x:  658   top_y:  267   width:   17   height:   11)\n",
      "motorbike: 25%\t(left_x:  675   top_y:  267   width:   19   height:   21)\n",
      "motorbike: 30%\t(left_x:  682   top_y:  266   width:   32   height:   28)\n",
      "motorbike: 50%\t(left_x:  703   top_y:  265   width:   48   height:   42)\n",
      "motorbike: 40%\t(left_x:  720   top_y:  267   width:   49   height:   45)\n",
      "motorbike: 30%\t(left_x:  740   top_y:  273   width:   47   height:   49)\n",
      "bicycle: 53%\t(left_x:  746   top_y:  275   width:   55   height:   51)\n",
      "motorbike: 29%\t(left_x:  748   top_y:  275   width:   71   height:   56)\n",
      "motorbike: 40%\t(left_x:  769   top_y:  281   width:   59   height:   56)\n",
      "bicycle: 36%\t(left_x:  770   top_y:  285   width:   49   height:   52)\n",
      "motorbike: 77%\t(left_x:  794   top_y:  283   width:  138   height:   98)\n",
      "motorbike: 86%\t(left_x:  879   top_y:  294   width:  218   height:  220)\n",
      "motorbike: 58%\t(left_x: 1019   top_y:  344   width:  110   height:   94)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02603_RV.png: Predicted in 145.439000 milli-seconds.\n",
      "person: 26%\t(left_x:   14   top_y:  475   width:   25   height:   37)\n",
      "person: 34%\t(left_x:   22   top_y:  455   width:   29   height:   42)\n",
      "bicycle: 39%\t(left_x:   34   top_y:  460   width:   52   height:   80)\n",
      "person: 75%\t(left_x:   48   top_y:  399   width:   52   height:   83)\n",
      "bicycle: 42%\t(left_x:   91   top_y:  436   width:   48   height:   44)\n",
      "car: 89%\t(left_x:  155   top_y:  359   width:   60   height:   48)\n",
      "traffic light: 70%\t(left_x:  238   top_y:  268   width:   16   height:   32)\n",
      "traffic light: 27%\t(left_x:  245   top_y:  251   width:   10   height:   19)\n",
      "traffic light: 44%\t(left_x:  255   top_y:  276   width:   12   height:   18)\n",
      "person: 32%\t(left_x:  269   top_y:  338   width:   11   height:   24)\n",
      "bicycle: 66%\t(left_x:  326   top_y:  302   width:   50   height:   42)\n",
      "person: 34%\t(left_x:  332   top_y:  291   width:   37   height:   51)\n",
      "person: 67%\t(left_x:  338   top_y:  284   width:   23   height:   48)\n",
      "traffic light: 26%\t(left_x:  390   top_y:  254   width:    9   height:   17)\n",
      "bicycle: 60%\t(left_x:  395   top_y:  288   width:   30   height:   31)\n",
      "bicycle: 30%\t(left_x:  397   top_y:  272   width:   24   height:   45)\n",
      "person: 70%\t(left_x:  398   top_y:  270   width:   22   height:   42)\n",
      "bicycle: 25%\t(left_x:  410   top_y:  289   width:   18   height:   26)\n",
      "truck: 77%\t(left_x:  537   top_y:  228   width:   73   height:   68)\n",
      "car: 64%\t(left_x:  608   top_y:  265   width:   15   height:   15)\n",
      "car: 64%\t(left_x:  634   top_y:  261   width:   31   height:   24)\n",
      "car: 65%\t(left_x:  698   top_y:  268   width:   25   height:   15)\n",
      "car: 83%\t(left_x:  741   top_y:  266   width:   49   height:   33)\n",
      "motorbike: 27%\t(left_x:  819   top_y:  277   width:   25   height:   28)\n",
      "person: 35%\t(left_x:  821   top_y:  273   width:   23   height:   31)\n",
      "car: 93%\t(left_x:  863   top_y:  290   width:  175   height:   93)\n",
      "traffic light: 50%\t(left_x: 1035   top_y:  221   width:   18   height:   27)\n",
      "bicycle: 36%\t(left_x: 1076   top_y:  373   width:   32   height:   40)\n",
      "bicycle: 63%\t(left_x: 1077   top_y:  383   width:   55   height:   48)\n",
      "person: 26%\t(left_x: 1102   top_y:  363   width:   35   height:   46)\n",
      "car: 56%\t(left_x: 1130   top_y:  395   width:   37   height:   30)\n",
      "car: 44%\t(left_x: 1176   top_y:  417   width:   33   height:   27)\n",
      "bicycle: 47%\t(left_x: 1184   top_y:  458   width:   48   height:   34)\n",
      "person: 26%\t(left_x: 1200   top_y:  449   width:   46   height:   48)\n",
      "bicycle: 51%\t(left_x: 1203   top_y:  487   width:   36   height:   33)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06313_FV.png: Predicted in 145.333000 milli-seconds.\n",
      "car: 78%\t(left_x:   45   top_y:  441   width:   30   height:   49)\n",
      "truck: 26%\t(left_x:   66   top_y:  367   width:   69   height:   52)\n",
      "truck: 54%\t(left_x:   66   top_y:  405   width:   86   height:   81)\n",
      "car: 60%\t(left_x:   67   top_y:  404   width:   86   height:   82)\n",
      "truck: 25%\t(left_x:  133   top_y:  379   width:   70   height:   63)\n",
      "car: 77%\t(left_x:  133   top_y:  379   width:   69   height:   64)\n",
      "car: 93%\t(left_x:  193   top_y:  342   width:  135   height:   89)\n",
      "car: 90%\t(left_x:  487   top_y:  313   width:   65   height:   26)\n",
      "car: 80%\t(left_x:  665   top_y:  300   width:   75   height:   38)\n",
      "car: 94%\t(left_x:  680   top_y:  283   width:  236   height:  102)\n",
      "car: 87%\t(left_x:  996   top_y:  365   width:   56   height:   37)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05811_MVR.png: Predicted in 144.853000 milli-seconds.\n",
      "bicycle: 61%\t(left_x:   47   top_y:  399   width:  122   height:  119)\n",
      "person: 25%\t(left_x:   55   top_y:  345   width:   47   height:   35)\n",
      "person: 77%\t(left_x:  108   top_y:  215   width:   63   height:   72)\n",
      "person: 29%\t(left_x:  122   top_y:  163   width:   63   height:   63)\n",
      "person: 57%\t(left_x:  161   top_y:  137   width:   70   height:   68)\n",
      "person: 68%\t(left_x:  218   top_y:   96   width:   58   height:   70)\n",
      "person: 40%\t(left_x:  230   top_y:   88   width:   60   height:   67)\n",
      "person: 54%\t(left_x:  257   top_y:   79   width:   38   height:   53)\n",
      "person: 33%\t(left_x:  270   top_y:   78   width:   29   height:   41)\n",
      "person: 50%\t(left_x:  304   top_y:   22   width:   48   height:   70)\n",
      "person: 49%\t(left_x:  323   top_y:   17   width:   40   height:   71)\n",
      "person: 35%\t(left_x:  340   top_y:   20   width:   43   height:   53)\n",
      "person: 31%\t(left_x:  354   top_y:   30   width:   36   height:   48)\n",
      "person: 51%\t(left_x:  736   top_y:    3   width:   43   height:   41)\n",
      "bicycle: 85%\t(left_x:  754   top_y:    5   width:  138   height:  144)\n",
      "truck: 31%\t(left_x:  936   top_y:   89   width:  110   height:  104)\n",
      "car: 66%\t(left_x:  936   top_y:   89   width:  110   height:  104)\n",
      "person: 31%\t(left_x:  946   top_y:   55   width:   33   height:   37)\n",
      "car: 41%\t(left_x: 1007   top_y:   37   width:   25   height:   15)\n",
      "car: 74%\t(left_x: 1109   top_y:  285   width:   54   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08232_MVR.png: Predicted in 144.161000 milli-seconds.\n",
      "car: 38%\t(left_x:    5   top_y:   20   width: 1278   height:  934)\n",
      "car: 26%\t(left_x:    6   top_y:  382   width:  185   height:  330)\n",
      "car: 92%\t(left_x:   92   top_y:    7   width:  890   height:  509)\n",
      "person: 80%\t(left_x:  950   top_y:   83   width:   77   height:  102)\n",
      "skateboard: 26%\t(left_x:  976   top_y:  174   width:   26   height:   14)\n",
      "person: 89%\t(left_x: 1013   top_y:  153   width:   94   height:  107)\n",
      "person: 37%\t(left_x: 1032   top_y:   12   width:   38   height:   49)\n",
      "person: 29%\t(left_x: 1033   top_y:   23   width:   51   height:   44)\n",
      "person: 29%\t(left_x: 1037   top_y:   37   width:   65   height:   36)\n",
      "person: 74%\t(left_x: 1079   top_y:  196   width:   40   height:   60)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05895_MVL.png: Predicted in 144.409000 milli-seconds.\n",
      "car: 34%\t(left_x:    3   top_y:  -14   width: 1278   height:  993)\n",
      "car: 54%\t(left_x:  117   top_y:  278   width:   62   height:   55)\n",
      "person: 46%\t(left_x:  274   top_y:   87   width:   20   height:   34)\n",
      "car: 88%\t(left_x:  319   top_y:   20   width:  132   height:  102)\n",
      "person: 26%\t(left_x:  441   top_y:   28   width:   33   height:   35)\n",
      "person: 28%\t(left_x:  442   top_y:   26   width:   18   height:   34)\n",
      "person: 29%\t(left_x:  515   top_y:    9   width:   11   height:   28)\n",
      "bicycle: 33%\t(left_x:  533   top_y:   22   width:   34   height:   27)\n",
      "bicycle: 26%\t(left_x:  536   top_y:   11   width:   21   height:   36)\n",
      "person: 49%\t(left_x:  538   top_y:    5   width:   14   height:   37)\n",
      "person: 27%\t(left_x:  538   top_y:    5   width:   14   height:   22)\n",
      "bicycle: 55%\t(left_x:  554   top_y:   16   width:   42   height:   34)\n",
      "person: 50%\t(left_x:  717   top_y:   15   width:   15   height:   33)\n",
      "bicycle: 25%\t(left_x:  822   top_y:   68   width:   43   height:   37)\n",
      "person: 77%\t(left_x:  893   top_y:   74   width:   38   height:   45)\n",
      "person: 52%\t(left_x:  953   top_y:  111   width:   27   height:   35)\n",
      "person: 44%\t(left_x: 1060   top_y:  212   width:   30   height:   31)\n",
      "person: 39%\t(left_x: 1062   top_y:  214   width:   36   height:   43)\n",
      "person: 47%\t(left_x: 1069   top_y:  222   width:   41   height:   48)\n",
      "car: 31%\t(left_x: 1086   top_y:  251   width:   53   height:   37)\n",
      "person: 58%\t(left_x: 1114   top_y:  285   width:   39   height:   32)\n",
      "person: 28%\t(left_x: 1116   top_y:  285   width:   40   height:   53)\n",
      "person: 42%\t(left_x: 1131   top_y:  319   width:   39   height:   43)\n",
      "person: 52%\t(left_x: 1151   top_y:  356   width:   37   height:   29)\n",
      "car: 84%\t(left_x: 1174   top_y:  458   width:   73   height:  123)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06002_MVR.png: Predicted in 144.715000 milli-seconds.\n",
      "person: 72%\t(left_x:    8   top_y:  465   width:  152   height:  111)\n",
      "person: 53%\t(left_x:   10   top_y:  608   width:   89   height:   37)\n",
      "person: 28%\t(left_x:   17   top_y:  457   width:  105   height:   71)\n",
      "person: 49%\t(left_x:   19   top_y:  635   width:  106   height:   75)\n",
      "person: 27%\t(left_x:   19   top_y:  672   width:  108   height:   44)\n",
      "person: 69%\t(left_x:   56   top_y:  751   width:   83   height:   50)\n",
      "person: 78%\t(left_x:  472   top_y:    3   width:   34   height:   75)\n",
      "handbag: 34%\t(left_x:  493   top_y:    9   width:   16   height:   19)\n",
      "person: 83%\t(left_x:  494   top_y:    3   width:   53   height:   65)\n",
      "motorbike: 87%\t(left_x:  726   top_y:    2   width:   75   height:  103)\n",
      "car: 88%\t(left_x:  766   top_y:   35   width:  314   height:  210)\n",
      "car: 42%\t(left_x: 1070   top_y:  224   width:   65   height:   63)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03449_MVR.png: Predicted in 144.563000 milli-seconds.\n",
      "bicycle: 75%\t(left_x:   30   top_y:  374   width:  119   height:  152)\n",
      "bicycle: 71%\t(left_x:   67   top_y:  290   width:  132   height:  144)\n",
      "bicycle: 57%\t(left_x:   80   top_y:  235   width:  122   height:  110)\n",
      "person: 34%\t(left_x:   97   top_y:  195   width:   70   height:   80)\n",
      "bicycle: 43%\t(left_x:  105   top_y:  196   width:  119   height:   91)\n",
      "bicycle: 80%\t(left_x:  158   top_y:  119   width:  180   height:  185)\n",
      "bicycle: 28%\t(left_x:  220   top_y:  109   width:  131   height:  152)\n",
      "bicycle: 79%\t(left_x:  255   top_y:    8   width:  152   height:  247)\n",
      "bicycle: 78%\t(left_x:  406   top_y:    3   width:  119   height:  172)\n",
      "bicycle: 60%\t(left_x:  491   top_y:    4   width:   78   height:  158)\n",
      "bicycle: 79%\t(left_x:  527   top_y:    2   width:  141   height:  183)\n",
      "bicycle: 61%\t(left_x:  658   top_y:    2   width:   52   height:   28)\n",
      "bicycle: 88%\t(left_x:  675   top_y:    4   width:  104   height:   56)\n",
      "person: 63%\t(left_x:  725   top_y:    2   width:   44   height:   38)\n",
      "bicycle: 31%\t(left_x:  886   top_y:   44   width:   45   height:   35)\n",
      "bicycle: 53%\t(left_x:  888   top_y:   44   width:   58   height:   49)\n",
      "bicycle: 38%\t(left_x:  914   top_y:   28   width:   34   height:   62)\n",
      "person: 77%\t(left_x:  914   top_y:   25   width:   32   height:   58)\n",
      "bicycle: 38%\t(left_x:  918   top_y:   57   width:   30   height:   37)\n",
      "person: 25%\t(left_x:  946   top_y:    3   width:   25   height:   22)\n",
      "bicycle: 45%\t(left_x:  954   top_y:   85   width:   54   height:   43)\n",
      "bicycle: 33%\t(left_x:  978   top_y:   98   width:   46   height:   45)\n",
      "bicycle: 32%\t(left_x:  990   top_y:  102   width:   47   height:   48)\n",
      "bicycle: 41%\t(left_x: 1002   top_y:  118   width:   53   height:   47)\n",
      "bicycle: 30%\t(left_x: 1028   top_y:  132   width:   34   height:   56)\n",
      "bicycle: 45%\t(left_x: 1033   top_y:  146   width:   29   height:   51)\n",
      "bicycle: 29%\t(left_x: 1062   top_y:  168   width:   30   height:   33)\n",
      "car: 34%\t(left_x: 1113   top_y:  285   width:   46   height:   46)\n",
      "person: 58%\t(left_x: 1122   top_y:  283   width:   33   height:   44)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03386_RV.png: Predicted in 144.628000 milli-seconds.\n",
      "car: 32%\t(left_x:    2   top_y:  627   width: 1278   height:  324)\n",
      "car: 75%\t(left_x:   39   top_y:  396   width:   46   height:   78)\n",
      "person: 28%\t(left_x:   93   top_y:  388   width:   15   height:   25)\n",
      "bicycle: 36%\t(left_x:  142   top_y:  368   width:   25   height:   27)\n",
      "bicycle: 35%\t(left_x:  153   top_y:  360   width:   28   height:   29)\n",
      "car: 30%\t(left_x:  257   top_y:  264   width:   89   height:   72)\n",
      "truck: 62%\t(left_x:  258   top_y:  264   width:   87   height:   73)\n",
      "person: 34%\t(left_x:  324   top_y:  276   width:   14   height:   14)\n",
      "bicycle: 54%\t(left_x:  348   top_y:  285   width:   31   height:   31)\n",
      "bicycle: 28%\t(left_x:  357   top_y:  284   width:   25   height:   27)\n",
      "person: 57%\t(left_x:  421   top_y:  259   width:   16   height:   40)\n",
      "person: 77%\t(left_x:  495   top_y:  244   width:   18   height:   48)\n",
      "bicycle: 72%\t(left_x:  520   top_y:  258   width:   39   height:   36)\n",
      "bicycle: 53%\t(left_x:  554   top_y:  255   width:   40   height:   36)\n",
      "bicycle: 59%\t(left_x:  584   top_y:  255   width:   37   height:   37)\n",
      "car: 46%\t(left_x:  625   top_y:  225   width:  162   height:   78)\n",
      "truck: 48%\t(left_x:  626   top_y:  224   width:  161   height:   78)\n",
      "car: 88%\t(left_x:  786   top_y:  281   width:   67   height:   35)\n",
      "car: 84%\t(left_x:  853   top_y:  299   width:   59   height:   32)\n",
      "car: 57%\t(left_x:  910   top_y:  313   width:   34   height:   25)\n",
      "person: 33%\t(left_x:  944   top_y:  324   width:   13   height:   26)\n",
      "person: 37%\t(left_x:  965   top_y:  329   width:   10   height:   25)\n",
      "person: 38%\t(left_x: 1045   top_y:  362   width:   16   height:   27)\n",
      "person: 29%\t(left_x: 1061   top_y:  372   width:   15   height:   21)\n",
      "person: 27%\t(left_x: 1090   top_y:  390   width:   12   height:   18)\n",
      "person: 42%\t(left_x: 1103   top_y:  388   width:   12   height:   25)\n",
      "person: 39%\t(left_x: 1106   top_y:  387   width:   18   height:   28)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06085_RV.png: Predicted in 145.861000 milli-seconds.\n",
      "car: 30%\t(left_x:    2   top_y:  559   width: 1279   height:  397)\n",
      "car: 92%\t(left_x:   36   top_y:  432   width:  106   height:  104)\n",
      "car: 89%\t(left_x:   78   top_y:  263   width:  195   height:  202)\n",
      "person: 89%\t(left_x:  402   top_y:  193   width:   43   height:   66)\n",
      "car: 75%\t(left_x:  667   top_y:  173   width:   37   height:   24)\n",
      "car: 86%\t(left_x:  711   top_y:  179   width:   42   height:   20)\n",
      "car: 65%\t(left_x:  776   top_y:  191   width:   37   height:   16)\n",
      "car: 38%\t(left_x:  792   top_y:  192   width:   22   height:   16)\n",
      "truck: 91%\t(left_x:  811   top_y:  167   width:  138   height:   97)\n",
      "car: 90%\t(left_x:  988   top_y:  243   width:  262   height:  311)\n",
      "car: 27%\t(left_x:  999   top_y:  257   width:   20   height:   27)\n",
      "car: 83%\t(left_x: 1004   top_y:  262   width:   44   height:   35)\n",
      "car: 58%\t(left_x: 1055   top_y:  227   width:   28   height:   38)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02975_RV.png: Predicted in 146.039000 milli-seconds.\n",
      "car: 42%\t(left_x:    0   top_y:  481   width: 1278   height:  470)\n",
      "person: 33%\t(left_x:  126   top_y:  382   width:   26   height:   48)\n",
      "bicycle: 70%\t(left_x:  326   top_y:  302   width:   60   height:   46)\n",
      "bicycle: 68%\t(left_x:  363   top_y:  290   width:   46   height:   42)\n",
      "bicycle: 66%\t(left_x:  432   top_y:  278   width:   40   height:   33)\n",
      "person: 59%\t(left_x:  567   top_y:  253   width:   13   height:   37)\n",
      "truck: 80%\t(left_x:  587   top_y:  209   width:   83   height:   95)\n",
      "car: 76%\t(left_x:  667   top_y:  259   width:   24   height:   21)\n",
      "car: 78%\t(left_x:  725   top_y:  237   width:  139   height:  107)\n",
      "person: 68%\t(left_x: 1017   top_y:  338   width:   16   height:   28)\n",
      "person: 25%\t(left_x: 1091   top_y:  379   width:   23   height:   31)\n",
      "person: 45%\t(left_x: 1117   top_y:  405   width:   11   height:   20)\n",
      "car: 34%\t(left_x: 1186   top_y:  414   width:   75   height:  102)\n",
      "truck: 37%\t(left_x: 1186   top_y:  414   width:   76   height:  102)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04502_MVR.png: Predicted in 145.708000 milli-seconds.\n",
      "car: 80%\t(left_x:   42   top_y:  478   width:   68   height:  164)\n",
      "pottedplant: 37%\t(left_x:  196   top_y:  124   width:  127   height:  131)\n",
      "bicycle: 89%\t(left_x:  267   top_y:   48   width:  149   height:  181)\n",
      "bicycle: 61%\t(left_x:  346   top_y:   43   width:   97   height:  131)\n",
      "bicycle: 56%\t(left_x:  387   top_y:   37   width:   71   height:  137)\n",
      "bicycle: 71%\t(left_x:  423   top_y:   12   width:  106   height:  156)\n",
      "motorbike: 90%\t(left_x:  513   top_y:    3   width:  108   height:  127)\n",
      "pottedplant: 72%\t(left_x:  611   top_y:    3   width:   88   height:   84)\n",
      "bicycle: 28%\t(left_x:  739   top_y:    5   width:   51   height:   67)\n",
      "bicycle: 47%\t(left_x:  739   top_y:    5   width:   91   height:   67)\n",
      "bicycle: 47%\t(left_x:  785   top_y:    3   width:   62   height:   59)\n",
      "bicycle: 46%\t(left_x:  808   top_y:    7   width:   89   height:   91)\n",
      "bicycle: 46%\t(left_x:  840   top_y:    8   width:   71   height:  100)\n",
      "bicycle: 39%\t(left_x:  858   top_y:   29   width:   57   height:   86)\n",
      "bicycle: 51%\t(left_x:  875   top_y:   66   width:   42   height:   53)\n",
      "bicycle: 30%\t(left_x:  875   top_y:   10   width:   63   height:  101)\n",
      "bicycle: 34%\t(left_x:  876   top_y:   38   width:   49   height:   80)\n",
      "bicycle: 26%\t(left_x:  911   top_y:   19   width:   46   height:   78)\n",
      "bicycle: 29%\t(left_x:  919   top_y:   46   width:   38   height:   51)\n",
      "person: 40%\t(left_x:  962   top_y:   62   width:   17   height:   30)\n",
      "person: 47%\t(left_x:  968   top_y:   66   width:   20   height:   33)\n",
      "person: 25%\t(left_x: 1031   top_y:  155   width:   34   height:   39)\n",
      "person: 29%\t(left_x: 1033   top_y:  141   width:   26   height:   25)\n",
      "person: 52%\t(left_x: 1037   top_y:  155   width:   43   height:   43)\n",
      "car: 52%\t(left_x: 1111   top_y:  286   width:   47   height:   51)\n",
      "person: 30%\t(left_x: 1123   top_y:  285   width:   32   height:   45)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04114_MVL.png: Predicted in 145.391000 milli-seconds.\n",
      "car: 37%\t(left_x:   -6   top_y:  -13   width: 1255   height:  987)\n",
      "car: 58%\t(left_x:  118   top_y:  278   width:   60   height:   54)\n",
      "person: 31%\t(left_x:  286   top_y:   60   width:  136   height:  110)\n",
      "bicycle: 66%\t(left_x:  287   top_y:   59   width:  137   height:  111)\n",
      "person: 79%\t(left_x:  319   top_y:   23   width:   59   height:  131)\n",
      "handbag: 29%\t(left_x:  372   top_y:    3   width:  111   height:  153)\n",
      "person: 87%\t(left_x:  372   top_y:    3   width:  110   height:  155)\n",
      "handbag: 51%\t(left_x:  406   top_y:   12   width:   47   height:   72)\n",
      "person: 46%\t(left_x:  495   top_y:    1   width:   19   height:   30)\n",
      "person: 52%\t(left_x:  528   top_y:   10   width:   11   height:   22)\n",
      "person: 29%\t(left_x:  528   top_y:   11   width:   19   height:   21)\n",
      "person: 33%\t(left_x:  627   top_y:    3   width:   10   height:   25)\n",
      "person: 65%\t(left_x:  649   top_y:    6   width:   17   height:   27)\n",
      "car: 71%\t(left_x:  672   top_y:    9   width:   20   height:   16)\n",
      "person: 85%\t(left_x:  698   top_y:    2   width:   25   height:   57)\n",
      "person: 60%\t(left_x:  723   top_y:    5   width:   14   height:   43)\n",
      "person: 81%\t(left_x:  802   top_y:   23   width:   27   height:   57)\n",
      "person: 36%\t(left_x:  826   top_y:   38   width:   23   height:   44)\n",
      "person: 66%\t(left_x:  837   top_y:   43   width:   25   height:   43)\n",
      "bird: 46%\t(left_x:  968   top_y:  261   width:   39   height:   50)\n",
      "clock: 40%\t(left_x:  968   top_y:  262   width:   38   height:   47)\n",
      "clock: 59%\t(left_x: 1024   top_y:  336   width:   89   height:  122)\n",
      "person: 26%\t(left_x: 1125   top_y:  313   width:   49   height:   40)\n",
      "person: 34%\t(left_x: 1140   top_y:  339   width:   75   height:   50)\n",
      "person: 31%\t(left_x: 1174   top_y:  400   width:   74   height:   35)\n",
      "person: 49%\t(left_x: 1175   top_y:  339   width:   47   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07517_FV.png: Predicted in 145.336000 milli-seconds.\n",
      "car: 94%\t(left_x:   73   top_y:  316   width:  214   height:  173)\n",
      "car: 83%\t(left_x:  261   top_y:  278   width:  219   height:  170)\n",
      "car: 40%\t(left_x:  512   top_y:  319   width:   13   height:    9)\n",
      "car: 73%\t(left_x:  630   top_y:  285   width:  223   height:  105)\n",
      "car: 48%\t(left_x:  758   top_y:  314   width:   93   height:   75)\n",
      "person: 62%\t(left_x:  828   top_y:  296   width:   37   height:   93)\n",
      "car: 86%\t(left_x:  861   top_y:  332   width:  107   height:   56)\n",
      "car: 81%\t(left_x: 1093   top_y:  416   width:   49   height:   30)\n",
      "car: 87%\t(left_x: 1125   top_y:  411   width:   73   height:   99)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06793_RV.png: Predicted in 145.420000 milli-seconds.\n",
      "car: 38%\t(left_x:   -2   top_y:   10   width: 1282   height:  972)\n",
      "car: 45%\t(left_x:  286   top_y:  257   width:   25   height:   15)\n",
      "car: 92%\t(left_x:  314   top_y:  202   width:  124   height:   74)\n",
      "fire hydrant: 44%\t(left_x:  640   top_y:  209   width:    8   height:   20)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06445_MVL.png: Predicted in 145.007000 milli-seconds.\n",
      "person: 37%\t(left_x:  174   top_y:  161   width:   15   height:   27)\n",
      "car: 83%\t(left_x:  193   top_y:    4   width:  516   height:  336)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07960_MVR.png: Predicted in 146.109000 milli-seconds.\n",
      "car: 61%\t(left_x:   38   top_y:  448   width:   74   height:  118)\n",
      "car: 33%\t(left_x:   69   top_y:  353   width:   53   height:   77)\n",
      "person: 61%\t(left_x:  105   top_y:  326   width:   31   height:   25)\n",
      "person: 52%\t(left_x:  124   top_y:  201   width:   48   height:   49)\n",
      "car: 73%\t(left_x:  231   top_y:  108   width:   79   height:   88)\n",
      "car: 81%\t(left_x:  276   top_y:   61   width:   90   height:   90)\n",
      "person: 94%\t(left_x:  312   top_y:    4   width:  217   height:  281)\n",
      "car: 82%\t(left_x:  441   top_y:    3   width:  264   height:  113)\n",
      "car: 33%\t(left_x:  676   top_y:    3   width:  146   height:  222)\n",
      "person: 91%\t(left_x:  679   top_y:    3   width:  140   height:  222)\n",
      "car: 73%\t(left_x:  778   top_y:    3   width:  209   height:  207)\n",
      "car: 87%\t(left_x:  974   top_y:   99   width:   86   height:   95)\n",
      "car: 39%\t(left_x: 1100   top_y:  232   width:   36   height:   20)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04323_MVL.png: Predicted in 146.136000 milli-seconds.\n",
      "car: 30%\t(left_x:   15   top_y:  248   width: 1111   height:  701)\n",
      "car: 55%\t(left_x:  116   top_y:  278   width:   58   height:   52)\n",
      "person: 88%\t(left_x:  393   top_y:   15   width:   24   height:   53)\n",
      "bicycle: 73%\t(left_x:  572   top_y:    3   width:   45   height:   37)\n",
      "bicycle: 49%\t(left_x:  606   top_y:    5   width:   27   height:   35)\n",
      "bicycle: 37%\t(left_x:  609   top_y:    5   width:   41   height:   37)\n",
      "bicycle: 45%\t(left_x:  626   top_y:    5   width:   43   height:   38)\n",
      "bicycle: 40%\t(left_x:  630   top_y:    4   width:   65   height:   41)\n",
      "bicycle: 54%\t(left_x:  666   top_y:    4   width:   41   height:   43)\n",
      "bicycle: 46%\t(left_x:  708   top_y:    5   width:   38   height:   47)\n",
      "bicycle: 48%\t(left_x:  774   top_y:   20   width:   34   height:   49)\n",
      "bicycle: 38%\t(left_x:  784   top_y:   23   width:   42   height:   49)\n",
      "bicycle: 28%\t(left_x:  800   top_y:   25   width:   43   height:   51)\n",
      "bicycle: 49%\t(left_x:  808   top_y:   41   width:   47   height:   42)\n",
      "bicycle: 27%\t(left_x: 1012   top_y:  173   width:   42   height:   33)\n",
      "bicycle: 34%\t(left_x: 1020   top_y:  182   width:   39   height:   29)\n",
      "bicycle: 39%\t(left_x: 1028   top_y:  187   width:   42   height:   34)\n",
      "bicycle: 49%\t(left_x: 1036   top_y:  193   width:   50   height:   39)\n",
      "bicycle: 27%\t(left_x: 1053   top_y:  203   width:   38   height:   39)\n",
      "bicycle: 39%\t(left_x: 1059   top_y:  213   width:   31   height:   43)\n",
      "bicycle: 55%\t(left_x: 1061   top_y:  216   width:   50   height:   42)\n",
      "person: 59%\t(left_x: 1076   top_y:  227   width:   66   height:   59)\n",
      "person: 66%\t(left_x: 1186   top_y:  541   width:   55   height:   33)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02575_FV.png: Predicted in 145.714000 milli-seconds.\n",
      "car: 44%\t(left_x:    3   top_y:  446   width: 1276   height:  505)\n",
      "car: 72%\t(left_x:  457   top_y:  338   width:   19   height:   34)\n",
      "car: 94%\t(left_x:  464   top_y:  217   width:  328   height:  251)\n",
      "car: 93%\t(left_x:  781   top_y:  309   width:  167   height:  108)\n",
      "bicycle: 85%\t(left_x:  964   top_y:  361   width:   63   height:   57)\n",
      "person: 85%\t(left_x:  984   top_y:  330   width:   41   height:   76)\n",
      "car: 83%\t(left_x: 1067   top_y:  383   width:  212   height:  198)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01672_FV.png: Predicted in 145.466000 milli-seconds.\n",
      "car: 34%\t(left_x:    1   top_y:  439   width: 1278   height:  522)\n",
      "car: 43%\t(left_x:  218   top_y:  372   width:   56   height:   30)\n",
      "bicycle: 40%\t(left_x:  401   top_y:  332   width:   80   height:   51)\n",
      "bicycle: 27%\t(left_x:  427   top_y:  322   width:   78   height:   54)\n",
      "bicycle: 28%\t(left_x:  450   top_y:  330   width:   40   height:   47)\n",
      "bicycle: 59%\t(left_x:  457   top_y:  322   width:   52   height:   50)\n",
      "bicycle: 50%\t(left_x:  485   top_y:  325   width:   35   height:   42)\n",
      "person: 58%\t(left_x:  555   top_y:  314   width:   15   height:   35)\n",
      "car: 29%\t(left_x:  617   top_y:  315   width:   16   height:   14)\n",
      "person: 82%\t(left_x:  652   top_y:  302   width:   16   height:   49)\n",
      "bicycle: 30%\t(left_x:  653   top_y:  307   width:   16   height:   45)\n",
      "bicycle: 41%\t(left_x:  654   top_y:  328   width:   14   height:   24)\n",
      "parking meter: 41%\t(left_x:  985   top_y:  357   width:   35   height:   68)\n",
      "person: 90%\t(left_x: 1183   top_y:  410   width:   48   height:  110)\n",
      "person: 90%\t(left_x: 1204   top_y:  420   width:   53   height:  117)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08153_FV.png: Predicted in 144.645000 milli-seconds.\n",
      "car: 85%\t(left_x:    2   top_y:  319   width:  239   height:  270)\n",
      "car: 86%\t(left_x:  204   top_y:  315   width:  129   height:   77)\n",
      "car: 90%\t(left_x:  324   top_y:  291   width:   96   height:   67)\n",
      "umbrella: 75%\t(left_x:  650   top_y:  111   width:  204   height:  127)\n",
      "person: 95%\t(left_x:  730   top_y:  168   width:  110   height:  245)\n",
      "umbrella: 74%\t(left_x:  928   top_y:  183   width:  120   height:   91)\n",
      "person: 94%\t(left_x:  953   top_y:  223   width:  144   height:  279)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03950_MVR.png: Predicted in 146.643000 milli-seconds.\n",
      "bicycle: 28%\t(left_x:    7   top_y:  372   width:   82   height:  136)\n",
      "bicycle: 66%\t(left_x:   16   top_y:  325   width:  199   height:  170)\n",
      "bicycle: 46%\t(left_x:   20   top_y:  407   width:   81   height:  135)\n",
      "bicycle: 42%\t(left_x:   66   top_y:  423   width:   94   height:  109)\n",
      "bicycle: 46%\t(left_x:   81   top_y:  316   width:  126   height:   76)\n",
      "bicycle: 83%\t(left_x:  139   top_y:  142   width:  202   height:  178)\n",
      "bicycle: 45%\t(left_x:  142   top_y:  167   width:  123   height:  202)\n",
      "bicycle: 51%\t(left_x:  148   top_y:  257   width:  116   height:  113)\n",
      "bicycle: 53%\t(left_x:  247   top_y:   89   width:   95   height:   62)\n",
      "bicycle: 71%\t(left_x:  250   top_y:  101   width:  174   height:  119)\n",
      "bicycle: 26%\t(left_x:  321   top_y:   40   width:  106   height:   75)\n",
      "bicycle: 37%\t(left_x:  323   top_y:   56   width:   53   height:   63)\n",
      "bicycle: 55%\t(left_x:  342   top_y:   36   width:   97   height:   49)\n",
      "pottedplant: 71%\t(left_x:  477   top_y:    2   width:   68   height:   55)\n",
      "car: 94%\t(left_x:  552   top_y:    3   width:  502   height:  238)\n",
      "bicycle: 38%\t(left_x:  580   top_y:    2   width:   97   height:   35)\n",
      "car: 72%\t(left_x: 1108   top_y:  284   width:   51   height:   56)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08226_MVL.png: Predicted in 144.179000 milli-seconds.\n",
      "person: 38%\t(left_x:  129   top_y:   76   width:   40   height:   58)\n",
      "person: 82%\t(left_x:  169   top_y:  141   width:   97   height:  118)\n",
      "person: 74%\t(left_x:  201   top_y:  120   width:   71   height:   76)\n",
      "car: 92%\t(left_x:  244   top_y:    3   width:  791   height:  415)\n",
      "car: 82%\t(left_x:  933   top_y:   83   width:  103   height:   68)\n",
      "car: 67%\t(left_x:  982   top_y:  127   width:  143   height:  180)\n",
      "car: 31%\t(left_x:  986   top_y:  127   width:  108   height:   92)\n",
      "car: 88%\t(left_x: 1046   top_y:  269   width:  233   height:  396)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00268_FV.png: Predicted in 144.157000 milli-seconds.\n",
      "bicycle: 86%\t(left_x:   40   top_y:  312   width:  165   height:  265)\n",
      "bicycle: 74%\t(left_x:  125   top_y:  340   width:   98   height:  183)\n",
      "bicycle: 76%\t(left_x:  184   top_y:  324   width:   87   height:  196)\n",
      "bicycle: 42%\t(left_x:  199   top_y:  323   width:  117   height:  179)\n",
      "bicycle: 47%\t(left_x:  250   top_y:  342   width:   98   height:  126)\n",
      "bicycle: 36%\t(left_x:  279   top_y:  308   width:   79   height:  145)\n",
      "bicycle: 57%\t(left_x:  298   top_y:  355   width:   62   height:   92)\n",
      "bicycle: 48%\t(left_x:  336   top_y:  353   width:   40   height:   39)\n",
      "car: 93%\t(left_x:  373   top_y:  307   width:  172   height:  107)\n",
      "car: 85%\t(left_x:  515   top_y:  318   width:   64   height:   57)\n",
      "car: 49%\t(left_x:  554   top_y:  314   width:   40   height:   50)\n",
      "truck: 39%\t(left_x:  554   top_y:  314   width:   40   height:   50)\n",
      "car: 61%\t(left_x:  592   top_y:  336   width:   16   height:   20)\n",
      "car: 45%\t(left_x:  607   top_y:  339   width:   13   height:    8)\n",
      "person: 60%\t(left_x:  700   top_y:  307   width:   20   height:   60)\n",
      "car: 32%\t(left_x:  718   top_y:  331   width:   17   height:   24)\n",
      "bicycle: 88%\t(left_x:  919   top_y:  328   width:  102   height:   99)\n",
      "bicycle: 86%\t(left_x: 1026   top_y:  349   width:  140   height:  134)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05046_MVR.png: Predicted in 145.453000 milli-seconds.\n",
      "person: 63%\t(left_x:   25   top_y:  520   width:   57   height:   39)\n",
      "person: 30%\t(left_x:   26   top_y:  602   width:   52   height:   25)\n",
      "person: 39%\t(left_x:   27   top_y:  714   width:   29   height:   21)\n",
      "person: 31%\t(left_x:   32   top_y:  642   width:   37   height:   22)\n",
      "person: 32%\t(left_x:  115   top_y:  169   width:   82   height:   85)\n",
      "person: 27%\t(left_x:  141   top_y:  198   width:   57   height:   58)\n",
      "person: 84%\t(left_x:  173   top_y:  176   width:   72   height:   61)\n",
      "bicycle: 51%\t(left_x:  198   top_y:  219   width:   34   height:   39)\n",
      "person: 35%\t(left_x:  890   top_y:   69   width:   17   height:   29)\n",
      "car: 38%\t(left_x: 1006   top_y:  102   width:   53   height:   54)\n",
      "car: 33%\t(left_x: 1044   top_y:   49   width:   22   height:   20)\n",
      "car: 30%\t(left_x: 1070   top_y:  261   width:   15   height:    9)\n",
      "car: 50%\t(left_x: 1100   top_y:  244   width:   35   height:   26)\n",
      "car: 84%\t(left_x: 1110   top_y:  286   width:   44   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07589_RV.png: Predicted in 145.623000 milli-seconds.\n",
      "car: 29%\t(left_x:    1   top_y:   24   width: 1278   height:  941)\n",
      "person: 55%\t(left_x:  449   top_y:  225   width:   17   height:   40)\n",
      "fire hydrant: 41%\t(left_x:  450   top_y:  225   width:   18   height:   40)\n",
      "truck: 76%\t(left_x:  478   top_y:  161   width:  155   height:   70)\n",
      "person: 31%\t(left_x:  678   top_y:  188   width:   10   height:   20)\n",
      "car: 42%\t(left_x:  780   top_y:  196   width:   15   height:    9)\n",
      "car: 50%\t(left_x:  834   top_y:  201   width:   17   height:   14)\n",
      "car: 49%\t(left_x:  854   top_y:  212   width:   26   height:   28)\n",
      "skateboard: 73%\t(left_x:  855   top_y:  301   width:   40   height:   22)\n",
      "person: 92%\t(left_x:  856   top_y:  144   width:   79   height:  177)\n",
      "person: 53%\t(left_x: 1032   top_y:  286   width:   30   height:   44)\n",
      "person: 46%\t(left_x: 1132   top_y:  368   width:   59   height:   48)\n",
      "person: 68%\t(left_x: 1148   top_y:  378   width:   55   height:   52)\n",
      "person: 39%\t(left_x: 1153   top_y:  330   width:    9   height:   16)\n",
      "car: 32%\t(left_x: 1212   top_y:  477   width:   38   height:   39)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03626_MVL.png: Predicted in 145.963000 milli-seconds.\n",
      "car: 35%\t(left_x:    8   top_y:  -15   width: 1278   height:  990)\n",
      "car: 83%\t(left_x:  117   top_y:  279   width:   64   height:   53)\n",
      "person: 26%\t(left_x:  135   top_y:  224   width:   17   height:   37)\n",
      "car: 63%\t(left_x:  155   top_y:  234   width:   48   height:   45)\n",
      "car: 26%\t(left_x:  166   top_y:  205   width:   13   height:   11)\n",
      "car: 78%\t(left_x:  203   top_y:  108   width:   99   height:   90)\n",
      "car: 90%\t(left_x:  356   top_y:   32   width:   89   height:   55)\n",
      "person: 34%\t(left_x:  565   top_y:    6   width:   13   height:   24)\n",
      "person: 41%\t(left_x:  597   top_y:   10   width:    8   height:   22)\n",
      "person: 26%\t(left_x:  604   top_y:   11   width:   15   height:   19)\n",
      "car: 93%\t(left_x:  802   top_y:   50   width:  156   height:   89)\n",
      "person: 26%\t(left_x:  964   top_y:  124   width:   18   height:   20)\n",
      "person: 27%\t(left_x:  979   top_y:  133   width:   21   height:   26)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07594_RV.png: Predicted in 145.396000 milli-seconds.\n",
      "aeroplane: 59%\t(left_x:   -1   top_y:   70   width: 1280   height:  876)\n",
      "aeroplane: 34%\t(left_x:    1   top_y:  502   width: 1277   height:  458)\n",
      "person: 80%\t(left_x:  332   top_y:  270   width:   20   height:   34)\n",
      "truck: 29%\t(left_x:  351   top_y:  201   width:  104   height:   58)\n",
      "person: 76%\t(left_x:  518   top_y:  192   width:   24   height:   63)\n",
      "car: 26%\t(left_x:  631   top_y:  190   width:   19   height:    8)\n",
      "person: 87%\t(left_x:  877   top_y:  186   width:   39   height:  101)\n",
      "person: 84%\t(left_x:  911   top_y:  215   width:   32   height:   69)\n",
      "person: 78%\t(left_x:  995   top_y:  239   width:   64   height:   82)\n",
      "car: 77%\t(left_x: 1037   top_y:  309   width:  143   height:  107)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02951_RV.png: Predicted in 143.845000 milli-seconds.\n",
      "bicycle: 45%\t(left_x:   15   top_y:  471   width:   54   height:   44)\n",
      "bicycle: 32%\t(left_x:   25   top_y:  417   width:   67   height:   77)\n",
      "bicycle: 54%\t(left_x:   44   top_y:  398   width:   56   height:   93)\n",
      "car: 94%\t(left_x:   94   top_y:  243   width:  362   height:  296)\n",
      "bicycle: 35%\t(left_x:   99   top_y:  369   width:   40   height:   45)\n",
      "car: 92%\t(left_x:  438   top_y:  244   width:  105   height:   80)\n",
      "car: 88%\t(left_x:  529   top_y:  248   width:   45   height:   47)\n",
      "car: 80%\t(left_x:  573   top_y:  253   width:   36   height:   25)\n",
      "car: 60%\t(left_x:  607   top_y:  256   width:   14   height:   12)\n",
      "car: 63%\t(left_x:  615   top_y:  250   width:   41   height:   33)\n",
      "truck: 32%\t(left_x:  615   top_y:  250   width:   41   height:   33)\n",
      "truck: 79%\t(left_x:  660   top_y:  239   width:   38   height:   37)\n",
      "car: 35%\t(left_x:  710   top_y:  259   width:   15   height:   15)\n",
      "car: 27%\t(left_x:  736   top_y:  264   width:   28   height:   19)\n",
      "car: 59%\t(left_x:  741   top_y:  266   width:   30   height:   20)\n",
      "car: 67%\t(left_x:  764   top_y:  270   width:   37   height:   21)\n",
      "car: 89%\t(left_x:  789   top_y:  274   width:   60   height:   34)\n",
      "car: 87%\t(left_x:  835   top_y:  286   width:   79   height:   49)\n",
      "car: 92%\t(left_x:  938   top_y:  328   width:  163   height:   90)\n",
      "car: 93%\t(left_x: 1104   top_y:  420   width:  174   height:  149)\n",
      "car: 52%\t(left_x: 1211   top_y:  423   width:   56   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05283_FV.png: Predicted in 145.099000 milli-seconds.\n",
      "bicycle: 53%\t(left_x:  288   top_y:  370   width:   42   height:   58)\n",
      "bicycle: 62%\t(left_x:  301   top_y:  368   width:   62   height:   53)\n",
      "bicycle: 40%\t(left_x:  320   top_y:  366   width:   50   height:   46)\n",
      "bicycle: 55%\t(left_x:  340   top_y:  369   width:   38   height:   42)\n",
      "bicycle: 58%\t(left_x:  359   top_y:  360   width:   40   height:   43)\n",
      "motorbike: 29%\t(left_x:  418   top_y:  357   width:   41   height:   24)\n",
      "truck: 50%\t(left_x:  439   top_y:  339   width:   37   height:   30)\n",
      "truck: 73%\t(left_x:  484   top_y:  338   width:   30   height:   32)\n",
      "car: 76%\t(left_x:  540   top_y:  334   width:   67   height:   44)\n",
      "traffic light: 43%\t(left_x:  558   top_y:  304   width:   10   height:   10)\n",
      "bicycle: 50%\t(left_x:  676   top_y:  344   width:   14   height:   24)\n",
      "person: 38%\t(left_x: 1036   top_y:  395   width:   11   height:   29)\n",
      "car: 56%\t(left_x: 1061   top_y:  407   width:   28   height:   36)\n",
      "car: 72%\t(left_x: 1070   top_y:  404   width:   36   height:   57)\n",
      "truck: 30%\t(left_x: 1079   top_y:  300   width:   52   height:  129)\n",
      "truck: 56%\t(left_x: 1096   top_y:  204   width:  184   height:  366)\n",
      "car: 28%\t(left_x: 1180   top_y:  512   width:   54   height:   50)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00716_RV.png: Predicted in 144.903000 milli-seconds.\n",
      "car: 27%\t(left_x:   -0   top_y:  531   width: 1274   height:  423)\n",
      "car: 93%\t(left_x:   22   top_y:  276   width:  334   height:  346)\n",
      "bicycle: 84%\t(left_x:  348   top_y:  278   width:   93   height:   69)\n",
      "car: 92%\t(left_x:  458   top_y:  254   width:   92   height:   59)\n",
      "car: 86%\t(left_x:  545   top_y:  252   width:   42   height:   37)\n",
      "car: 79%\t(left_x:  628   top_y:  257   width:   23   height:   19)\n",
      "car: 29%\t(left_x:  655   top_y:  259   width:   11   height:    7)\n",
      "car: 46%\t(left_x:  726   top_y:  266   width:   28   height:   16)\n",
      "car: 41%\t(left_x:  726   top_y:  268   width:   44   height:   17)\n",
      "car: 68%\t(left_x:  745   top_y:  269   width:   30   height:   19)\n",
      "car: 78%\t(left_x:  773   top_y:  274   width:   43   height:   21)\n",
      "car: 94%\t(left_x:  934   top_y:  321   width:  202   height:  133)\n",
      "person: 45%\t(left_x: 1140   top_y:  392   width:   39   height:   70)\n",
      "person: 42%\t(left_x: 1151   top_y:  392   width:   47   height:   72)\n",
      "bicycle: 58%\t(left_x: 1160   top_y:  434   width:   40   height:   59)\n",
      "person: 26%\t(left_x: 1166   top_y:  415   width:   58   height:   80)\n",
      "person: 76%\t(left_x: 1184   top_y:  433   width:   45   height:   70)\n",
      "person: 68%\t(left_x: 1217   top_y:  460   width:   45   height:   64)\n",
      "person: 27%\t(left_x: 1218   top_y:  483   width:   48   height:   55)\n",
      "person: 41%\t(left_x: 1239   top_y:  482   width:   29   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03240_MVL.png: Predicted in 143.777000 milli-seconds.\n",
      "car: 42%\t(left_x:   -8   top_y:   27   width: 1248   height:  934)\n",
      "car: 37%\t(left_x:  119   top_y:  278   width:   59   height:   55)\n",
      "car: 90%\t(left_x:  360   top_y:   27   width:  115   height:   68)\n",
      "car: 27%\t(left_x:  462   top_y:   20   width:   27   height:   12)\n",
      "truck: 40%\t(left_x:  465   top_y:   18   width:  107   height:   49)\n",
      "truck: 62%\t(left_x:  487   top_y:    2   width:  162   height:   56)\n",
      "car: 93%\t(left_x:  691   top_y:   16   width:  149   height:   76)\n",
      "bicycle: 72%\t(left_x:  866   top_y:   67   width:   53   height:   45)\n",
      "bicycle: 53%\t(left_x:  901   top_y:   98   width:   33   height:   37)\n",
      "bicycle: 60%\t(left_x:  906   top_y:  101   width:   49   height:   48)\n",
      "bicycle: 31%\t(left_x:  927   top_y:  104   width:   27   height:   48)\n",
      "bicycle: 49%\t(left_x:  959   top_y:  125   width:   36   height:   30)\n",
      "car: 54%\t(left_x:  997   top_y:  176   width:   75   height:   61)\n",
      "car: 75%\t(left_x:  998   top_y:  178   width:  129   height:  122)\n",
      "car: 90%\t(left_x: 1092   top_y:  286   width:  126   height:  154)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07250_MVL.png: Predicted in 144.310000 milli-seconds.\n",
      "car: 94%\t(left_x:  456   top_y:    3   width:  410   height:  145)\n",
      "person: 30%\t(left_x:  980   top_y:  111   width:   25   height:   28)\n",
      "car: 37%\t(left_x: 1097   top_y:  741   width:  101   height:  208)\n",
      "car: 57%\t(left_x: 1150   top_y:  330   width:   67   height:   89)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02174_MVL.png: Predicted in 145.134000 milli-seconds.\n",
      "car: 65%\t(left_x:    4   top_y:   43   width: 1263   height:  908)\n",
      "car: 35%\t(left_x:  119   top_y:  278   width:   60   height:   52)\n",
      "car: 28%\t(left_x:  235   top_y:  108   width:   33   height:   33)\n",
      "car: 27%\t(left_x:  266   top_y:   96   width:   40   height:   33)\n",
      "car: 77%\t(left_x:  278   top_y:   65   width:   70   height:   52)\n",
      "car: 58%\t(left_x:  327   top_y:   44   width:   52   height:   34)\n",
      "car: 92%\t(left_x:  457   top_y:    2   width:  203   height:   60)\n",
      "bicycle: 26%\t(left_x:  675   top_y:    3   width:   46   height:   34)\n",
      "bicycle: 64%\t(left_x:  686   top_y:    4   width:   85   height:   48)\n",
      "bicycle: 26%\t(left_x:  761   top_y:    9   width:   41   height:   44)\n",
      "bicycle: 72%\t(left_x:  797   top_y:   29   width:   95   height:   63)\n",
      "car: 48%\t(left_x: 1012   top_y:  182   width:  109   height:   87)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00148_MVR.png: Predicted in 144.797000 milli-seconds.\n",
      "bicycle: 29%\t(left_x:   67   top_y:  285   width:  141   height:  107)\n",
      "car: 45%\t(left_x:  217   top_y:  217   width:   38   height:   29)\n",
      "person: 36%\t(left_x:  391   top_y:   60   width:   22   height:   34)\n",
      "car: 82%\t(left_x:  508   top_y:    1   width:  152   height:   62)\n",
      "person: 88%\t(left_x:  848   top_y:    3   width:   44   height:   96)\n",
      "person: 35%\t(left_x:  925   top_y:   28   width:   20   height:   30)\n",
      "car: 33%\t(left_x:  995   top_y:    9   width:   62   height:   49)\n",
      "person: 26%\t(left_x: 1110   top_y:  199   width:   15   height:   21)\n",
      "person: 34%\t(left_x: 1127   top_y:  286   width:   27   height:   41)\n",
      "person: 25%\t(left_x: 1133   top_y:  252   width:   13   height:   16)\n",
      "person: 28%\t(left_x: 1138   top_y:  265   width:   22   height:   34)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00702_MVL.png: Predicted in 143.620000 milli-seconds.\n",
      "car: 42%\t(left_x:    4   top_y:   45   width: 1217   height:  902)\n",
      "car: 40%\t(left_x:  117   top_y:  278   width:   61   height:   53)\n",
      "car: 93%\t(left_x:  372   top_y:    3   width:  186   height:   99)\n",
      "bicycle: 58%\t(left_x:  636   top_y:    5   width:   33   height:   50)\n",
      "person: 54%\t(left_x:  637   top_y:    4   width:   32   height:   48)\n",
      "person: 73%\t(left_x:  703   top_y:    2   width:   29   height:   50)\n",
      "car: 28%\t(left_x:  729   top_y:    5   width:   32   height:   35)\n",
      "person: 86%\t(left_x:  745   top_y:    2   width:   33   height:   59)\n",
      "person: 46%\t(left_x:  775   top_y:    2   width:   22   height:   57)\n",
      "person: 48%\t(left_x:  778   top_y:   22   width:   19   height:   40)\n",
      "person: 46%\t(left_x:  794   top_y:   15   width:   18   height:   42)\n",
      "bicycle: 26%\t(left_x:  817   top_y:   52   width:   16   height:   27)\n",
      "bicycle: 67%\t(left_x:  850   top_y:   71   width:   63   height:   48)\n",
      "bicycle: 44%\t(left_x:  890   top_y:   86   width:   32   height:   43)\n",
      "bicycle: 50%\t(left_x:  903   top_y:   92   width:   43   height:   49)\n",
      "bicycle: 50%\t(left_x:  930   top_y:  100   width:   40   height:   48)\n",
      "bicycle: 60%\t(left_x:  951   top_y:  122   width:   39   height:   44)\n",
      "bicycle: 41%\t(left_x:  959   top_y:  130   width:   43   height:   44)\n",
      "bicycle: 58%\t(left_x:  972   top_y:  142   width:   51   height:   50)\n",
      "car: 87%\t(left_x: 1110   top_y:  323   width:  115   height:  177)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05629_MVR.png: Predicted in 144.580000 milli-seconds.\n",
      "person: 76%\t(left_x:   -0   top_y:  540   width:  173   height:  151)\n",
      "person: 89%\t(left_x:    1   top_y:  386   width:  206   height:  174)\n",
      "person: 31%\t(left_x:    3   top_y:  488   width:  148   height:   68)\n",
      "person: 36%\t(left_x:   26   top_y:  667   width:  162   height:   99)\n",
      "person: 86%\t(left_x:   26   top_y:  293   width:  187   height:  139)\n",
      "person: 60%\t(left_x:   30   top_y:  365   width:  143   height:   95)\n",
      "person: 93%\t(left_x:   65   top_y:  164   width:  199   height:  195)\n",
      "person: 35%\t(left_x:   90   top_y:   98   width:   42   height:   38)\n",
      "person: 30%\t(left_x:  102   top_y:  155   width:   51   height:   55)\n",
      "person: 90%\t(left_x:  130   top_y:   99   width:  189   height:  199)\n",
      "person: 57%\t(left_x:  208   top_y:  102   width:   98   height:  116)\n",
      "handbag: 29%\t(left_x:  214   top_y:   97   width:   69   height:   59)\n",
      "person: 67%\t(left_x:  235   top_y:   59   width:   75   height:   95)\n",
      "car: 93%\t(left_x:  298   top_y:    3   width:  561   height:  218)\n",
      "car: 74%\t(left_x:  846   top_y:    4   width:   50   height:   68)\n",
      "car: 85%\t(left_x:  854   top_y:   25   width:  170   height:  156)\n",
      "car: 75%\t(left_x: 1013   top_y:  138   width:   63   height:   48)\n",
      "car: 33%\t(left_x: 1039   top_y:  160   width:   43   height:   53)\n",
      "car: 27%\t(left_x: 1040   top_y:  169   width:   84   height:   87)\n",
      "car: 77%\t(left_x: 1058   top_y:  228   width:   59   height:   70)\n",
      "car: 82%\t(left_x: 1106   top_y:  285   width:   55   height:   50)\n",
      "car: 29%\t(left_x: 1172   top_y:  186   width:   21   height:   22)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02880_RV.png: Predicted in 143.986000 milli-seconds.\n",
      "car: 87%\t(left_x:   23   top_y:  409   width:   84   height:  103)\n",
      "car: 83%\t(left_x:  126   top_y:  333   width:  113   height:   76)\n",
      "person: 31%\t(left_x:  451   top_y:  253   width:   10   height:   36)\n",
      "person: 74%\t(left_x:  459   top_y:  251   width:   16   height:   41)\n",
      "person: 38%\t(left_x:  539   top_y:  249   width:   14   height:   29)\n",
      "bicycle: 26%\t(left_x:  544   top_y:  262   width:   26   height:   22)\n",
      "motorbike: 29%\t(left_x:  547   top_y:  260   width:   24   height:   24)\n",
      "traffic light: 32%\t(left_x:  705   top_y:  207   width:   16   height:   33)\n",
      "car: 41%\t(left_x:  722   top_y:  268   width:   15   height:    9)\n",
      "car: 39%\t(left_x:  740   top_y:  267   width:   24   height:   12)\n",
      "car: 71%\t(left_x:  807   top_y:  282   width:   35   height:   20)\n",
      "traffic light: 28%\t(left_x:  883   top_y:  186   width:   12   height:   22)\n",
      "person: 49%\t(left_x:  904   top_y:  303   width:   13   height:   28)\n",
      "bicycle: 31%\t(left_x: 1025   top_y:  350   width:   35   height:   37)\n",
      "bicycle: 26%\t(left_x: 1034   top_y:  356   width:   30   height:   37)\n",
      "person: 35%\t(left_x: 1059   top_y:  361   width:   28   height:   43)\n",
      "bicycle: 33%\t(left_x: 1060   top_y:  361   width:   27   height:   42)\n",
      "car: 62%\t(left_x: 1158   top_y:  431   width:   37   height:   45)\n",
      "car: 77%\t(left_x: 1197   top_y:  464   width:   82   height:  100)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03484_MVR.png: Predicted in 144.706000 milli-seconds.\n",
      "car: 92%\t(left_x:   55   top_y:  100   width:  313   height:  360)\n",
      "car: 92%\t(left_x:  380   top_y:    2   width:  417   height:  217)\n",
      "bicycle: 78%\t(left_x:  756   top_y:    3   width:   73   height:   93)\n",
      "car: 85%\t(left_x:  804   top_y:    4   width:  183   height:  140)\n",
      "car: 52%\t(left_x:  983   top_y:  119   width:   46   height:   54)\n",
      "car: 29%\t(left_x:  989   top_y:  116   width:   82   height:   74)\n",
      "car: 26%\t(left_x: 1032   top_y:  142   width:   81   height:   65)\n",
      "car: 32%\t(left_x: 1060   top_y:  154   width:   52   height:   52)\n",
      "car: 50%\t(left_x: 1103   top_y:  285   width:   61   height:   54)\n",
      "person: 34%\t(left_x: 1130   top_y:  241   width:   14   height:   28)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03922_MVL.png: Predicted in 145.317000 milli-seconds.\n",
      "car: 36%\t(left_x:   -6   top_y:   26   width: 1270   height:  930)\n",
      "car: 66%\t(left_x:  120   top_y:  275   width:   59   height:   60)\n",
      "car: 85%\t(left_x:  175   top_y:  163   width:   57   height:   57)\n",
      "car: 68%\t(left_x:  200   top_y:  147   width:   35   height:   26)\n",
      "car: 92%\t(left_x:  269   top_y:   74   width:  104   height:   73)\n",
      "bicycle: 52%\t(left_x:  466   top_y:    6   width:   37   height:   67)\n",
      "car: 94%\t(left_x:  483   top_y:    3   width:  356   height:  118)\n",
      "bicycle: 40%\t(left_x:  955   top_y:  140   width:   62   height:   73)\n",
      "bicycle: 62%\t(left_x:  973   top_y:  137   width:   87   height:   85)\n",
      "bicycle: 26%\t(left_x:  994   top_y:  157   width:   75   height:   85)\n",
      "bicycle: 25%\t(left_x: 1008   top_y:  189   width:   65   height:   68)\n",
      "bicycle: 54%\t(left_x: 1014   top_y:  164   width:   95   height:   96)\n",
      "bicycle: 46%\t(left_x: 1039   top_y:  187   width:   93   height:   92)\n",
      "bicycle: 57%\t(left_x: 1054   top_y:  210   width:   92   height:   84)\n",
      "bicycle: 58%\t(left_x: 1077   top_y:  229   width:   72   height:   76)\n",
      "bicycle: 61%\t(left_x: 1090   top_y:  294   width:   82   height:   77)\n",
      "bicycle: 43%\t(left_x: 1093   top_y:  270   width:   70   height:   60)\n",
      "bicycle: 31%\t(left_x: 1095   top_y:  248   width:   61   height:   61)\n",
      "bicycle: 41%\t(left_x: 1126   top_y:  311   width:   59   height:   69)\n",
      "bicycle: 40%\t(left_x: 1134   top_y:  335   width:   49   height:   49)\n",
      "bicycle: 30%\t(left_x: 1138   top_y:  391   width:   70   height:   45)\n",
      "bicycle: 34%\t(left_x: 1176   top_y:  470   width:   54   height:   50)\n",
      "tvmonitor: 32%\t(left_x: 1203   top_y:  170   width:   38   height:   55)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08075_FV.png: Predicted in 145.664000 milli-seconds.\n",
      "car: 35%\t(left_x:    1   top_y:  -32   width: 1278   height: 1010)\n",
      "car: 26%\t(left_x:  171   top_y:  361   width:   25   height:   15)\n",
      "car: 88%\t(left_x:  249   top_y:  304   width:  119   height:   79)\n",
      "car: 91%\t(left_x:  320   top_y:  287   width:  139   height:   85)\n",
      "car: 94%\t(left_x:  431   top_y:  274   width:  144   height:   89)\n",
      "car: 80%\t(left_x:  562   top_y:  284   width:   30   height:   49)\n",
      "car: 83%\t(left_x:  587   top_y:  234   width:  127   height:  130)\n",
      "car: 79%\t(left_x:  711   top_y:  293   width:   30   height:   47)\n",
      "car: 93%\t(left_x:  729   top_y:  279   width:  160   height:  106)\n",
      "car: 33%\t(left_x:  886   top_y:  325   width:   44   height:   23)\n",
      "car: 81%\t(left_x:  905   top_y:  331   width:  152   height:   76)\n",
      "car: 74%\t(left_x:  991   top_y:  352   width:  196   height:  170)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/04094_MVL.png: Predicted in 144.790000 milli-seconds.\n",
      "car: 26%\t(left_x:  117   top_y:  277   width:   62   height:   54)\n",
      "person: 81%\t(left_x:  305   top_y:   44   width:   81   height:  141)\n",
      "car: 82%\t(left_x:  353   top_y:   29   width:   69   height:   70)\n",
      "person: 34%\t(left_x:  469   top_y:   13   width:   16   height:   37)\n",
      "bicycle: 26%\t(left_x:  489   top_y:   23   width:   25   height:   19)\n",
      "bicycle: 58%\t(left_x:  653   top_y:   16   width:   52   height:   31)\n",
      "person: 48%\t(left_x:  784   top_y:   24   width:   19   height:   34)\n",
      "car: 78%\t(left_x:  836   top_y:   65   width:  176   height:  105)\n",
      "truck: 28%\t(left_x:  837   top_y:   65   width:  175   height:  105)\n",
      "person: 25%\t(left_x: 1018   top_y:  163   width:   36   height:   38)\n",
      "traffic light: 37%\t(left_x: 1057   top_y:  221   width:   35   height:   37)\n",
      "traffic light: 30%\t(left_x: 1080   top_y:  293   width:   22   height:   22)\n",
      "traffic light: 25%\t(left_x: 1156   top_y:  232   width:   24   height:   29)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02163_MVL.png: Predicted in 144.242000 milli-seconds.\n",
      "car: 79%\t(left_x:  121   top_y:  279   width:   52   height:   52)\n",
      "motorbike: 29%\t(left_x:  129   top_y:  240   width:   26   height:   19)\n",
      "car: 76%\t(left_x:  267   top_y:   67   width:   87   height:   68)\n",
      "car: 26%\t(left_x:  268   top_y:   85   width:   45   height:   47)\n",
      "car: 29%\t(left_x:  272   top_y:   83   width:   41   height:   31)\n",
      "bicycle: 57%\t(left_x:  410   top_y:   26   width:   42   height:   33)\n",
      "bicycle: 36%\t(left_x:  411   top_y:   30   width:   23   height:   30)\n",
      "truck: 61%\t(left_x:  454   top_y:    1   width:  202   height:   69)\n",
      "car: 51%\t(left_x:  455   top_y:    2   width:  200   height:   68)\n",
      "truck: 52%\t(left_x:  721   top_y:   13   width:  269   height:  146)\n",
      "car: 52%\t(left_x:  721   top_y:   13   width:  269   height:  146)\n",
      "person: 84%\t(left_x:  996   top_y:  130   width:   51   height:   59)\n",
      "car: 83%\t(left_x: 1036   top_y:  200   width:  163   height:  189)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06413_RV.png: Predicted in 145.585000 milli-seconds.\n",
      "person: 25%\t(left_x:  157   top_y:  335   width:   12   height:   22)\n",
      "person: 31%\t(left_x:  304   top_y:  283   width:   10   height:   17)\n",
      "car: 26%\t(left_x:  724   top_y:  214   width:   14   height:    7)\n",
      "car: 34%\t(left_x: 1038   top_y:  294   width:   10   height:   10)\n",
      "car: 43%\t(left_x: 1066   top_y:  310   width:   23   height:   18)\n",
      "car: 33%\t(left_x: 1068   top_y:  314   width:   43   height:   28)\n",
      "car: 60%\t(left_x: 1077   top_y:  316   width:   40   height:   33)\n",
      "car: 65%\t(left_x: 1129   top_y:  349   width:   34   height:   33)\n",
      "car: 56%\t(left_x: 1144   top_y:  381   width:   43   height:   39)\n",
      "car: 61%\t(left_x: 1161   top_y:  398   width:   69   height:   78)\n",
      "car: 38%\t(left_x: 1183   top_y:  400   width:   50   height:   53)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00466_RV.png: Predicted in 147.798000 milli-seconds.\n",
      "car: 37%\t(left_x:    4   top_y:  223   width: 1274   height:  725)\n",
      "person: 30%\t(left_x:  104   top_y:  425   width:   17   height:   24)\n",
      "car: 93%\t(left_x:  282   top_y:  260   width:  182   height:  113)\n",
      "car: 90%\t(left_x:  455   top_y:  257   width:   81   height:   51)\n",
      "person: 56%\t(left_x:  588   top_y:  243   width:   18   height:   38)\n",
      "motorbike: 72%\t(left_x:  588   top_y:  265   width:   15   height:   24)\n",
      "person: 36%\t(left_x:  613   top_y:  253   width:    7   height:   19)\n",
      "person: 39%\t(left_x:  860   top_y:  285   width:   10   height:   23)\n",
      "bicycle: 33%\t(left_x:  861   top_y:  286   width:   11   height:   24)\n",
      "bicycle: 38%\t(left_x:  870   top_y:  296   width:   15   height:   20)\n",
      "bicycle: 30%\t(left_x:  875   top_y:  298   width:   20   height:   20)\n",
      "bicycle: 28%\t(left_x:  903   top_y:  305   width:   25   height:   26)\n",
      "bicycle: 28%\t(left_x:  909   top_y:  310   width:   28   height:   25)\n",
      "bicycle: 31%\t(left_x:  921   top_y:  315   width:   19   height:   23)\n",
      "bicycle: 26%\t(left_x:  929   top_y:  316   width:   21   height:   23)\n",
      "bicycle: 57%\t(left_x:  939   top_y:  320   width:   25   height:   28)\n",
      "bicycle: 30%\t(left_x:  947   top_y:  323   width:   33   height:   29)\n",
      "bicycle: 40%\t(left_x:  958   top_y:  330   width:   26   height:   26)\n",
      "bicycle: 29%\t(left_x:  963   top_y:  331   width:   31   height:   28)\n",
      "bicycle: 35%\t(left_x:  976   top_y:  334   width:   28   height:   31)\n",
      "bicycle: 39%\t(left_x:  996   top_y:  340   width:   44   height:   47)\n",
      "bicycle: 50%\t(left_x: 1020   top_y:  355   width:   52   height:   52)\n",
      "car: 92%\t(left_x: 1067   top_y:  377   width:  212   height:  193)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03294_FV.png: Predicted in 145.315000 milli-seconds.\n",
      "car: 85%\t(left_x:   11   top_y:  450   width:   53   height:  105)\n",
      "car: 26%\t(left_x:   17   top_y:  514   width: 1259   height:  434)\n",
      "bicycle: 55%\t(left_x:   78   top_y:  456   width:   33   height:   35)\n",
      "bicycle: 59%\t(left_x:   93   top_y:  432   width:   58   height:   39)\n",
      "bicycle: 53%\t(left_x:  122   top_y:  430   width:   32   height:   36)\n",
      "bicycle: 43%\t(left_x:  287   top_y:  375   width:   40   height:   32)\n",
      "bicycle: 26%\t(left_x:  311   top_y:  369   width:   36   height:   36)\n",
      "bicycle: 45%\t(left_x:  331   top_y:  366   width:   38   height:   37)\n",
      "bicycle: 51%\t(left_x:  373   top_y:  356   width:   40   height:   32)\n",
      "bicycle: 28%\t(left_x:  390   top_y:  353   width:   24   height:   34)\n",
      "person: 36%\t(left_x:  398   top_y:  340   width:   12   height:   23)\n",
      "bicycle: 33%\t(left_x:  406   top_y:  352   width:   33   height:   30)\n",
      "person: 26%\t(left_x:  407   top_y:  340   width:   12   height:   23)\n",
      "bicycle: 27%\t(left_x:  422   top_y:  349   width:   28   height:   32)\n",
      "car: 84%\t(left_x:  441   top_y:  343   width:   63   height:   32)\n",
      "car: 52%\t(left_x:  497   top_y:  343   width:   26   height:   22)\n",
      "car: 48%\t(left_x:  504   top_y:  343   width:   24   height:   21)\n",
      "car: 69%\t(left_x:  523   top_y:  342   width:   22   height:   19)\n",
      "traffic light: 27%\t(left_x:  542   top_y:  250   width:   18   height:   65)\n",
      "car: 77%\t(left_x:  565   top_y:  340   width:   26   height:   16)\n",
      "car: 27%\t(left_x:  598   top_y:  343   width:   11   height:    7)\n",
      "car: 36%\t(left_x:  607   top_y:  342   width:   14   height:    8)\n",
      "truck: 43%\t(left_x:  631   top_y:  334   width:   28   height:   24)\n",
      "car: 50%\t(left_x:  631   top_y:  333   width:   27   height:   24)\n",
      "car: 41%\t(left_x:  673   top_y:  338   width:   18   height:   16)\n",
      "car: 54%\t(left_x:  689   top_y:  338   width:   22   height:   21)\n",
      "car: 27%\t(left_x:  704   top_y:  337   width:   28   height:   25)\n",
      "motorbike: 33%\t(left_x:  705   top_y:  336   width:   30   height:   27)\n",
      "bicycle: 42%\t(left_x:  728   top_y:  336   width:   37   height:   29)\n",
      "car: 45%\t(left_x:  830   top_y:  287   width:  300   height:  191)\n",
      "truck: 55%\t(left_x:  830   top_y:  286   width:  300   height:  191)\n",
      "car: 84%\t(left_x: 1146   top_y:  420   width:  133   height:  196)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05270_RV.png: Predicted in 144.640000 milli-seconds.\n",
      "person: 63%\t(left_x:  139   top_y:  337   width:   46   height:   64)\n",
      "person: 44%\t(left_x:  142   top_y:  337   width:   27   height:   44)\n",
      "person: 31%\t(left_x:  154   top_y:  302   width:   13   height:   36)\n",
      "bicycle: 78%\t(left_x:  262   top_y:  307   width:   41   height:   79)\n",
      "bicycle: 68%\t(left_x:  285   top_y:  306   width:   48   height:   57)\n",
      "bicycle: 53%\t(left_x:  309   top_y:  304   width:   37   height:   46)\n",
      "bicycle: 64%\t(left_x:  325   top_y:  301   width:   34   height:   44)\n",
      "bicycle: 63%\t(left_x:  338   top_y:  289   width:   36   height:   46)\n",
      "person: 39%\t(left_x:  471   top_y:  267   width:   11   height:   23)\n",
      "person: 27%\t(left_x:  511   top_y:  260   width:   11   height:   24)\n",
      "car: 29%\t(left_x:  628   top_y:  251   width:   31   height:   31)\n",
      "truck: 54%\t(left_x:  629   top_y:  251   width:   31   height:   30)\n",
      "car: 25%\t(left_x:  658   top_y:  264   width:   10   height:    9)\n",
      "car: 49%\t(left_x:  668   top_y:  266   width:   14   height:    9)\n",
      "car: 54%\t(left_x:  682   top_y:  268   width:   16   height:   10)\n",
      "car: 67%\t(left_x:  704   top_y:  269   width:   22   height:   18)\n",
      "car: 77%\t(left_x:  722   top_y:  271   width:   37   height:   22)\n",
      "car: 65%\t(left_x:  772   top_y:  272   width:   65   height:   41)\n",
      "truck: 38%\t(left_x:  772   top_y:  273   width:   65   height:   40)\n",
      "person: 32%\t(left_x:  842   top_y:  285   width:   10   height:   22)\n",
      "truck: 65%\t(left_x:  847   top_y:  283   width:  104   height:   66)\n",
      "car: 32%\t(left_x:  848   top_y:  285   width:  102   height:   62)\n",
      "person: 25%\t(left_x:  983   top_y:  343   width:   11   height:   25)\n",
      "person: 29%\t(left_x: 1011   top_y:  351   width:   18   height:   26)\n",
      "car: 44%\t(left_x: 1085   top_y:  395   width:   27   height:   30)\n",
      "person: 31%\t(left_x: 1108   top_y:  390   width:   20   height:   32)\n",
      "car: 71%\t(left_x: 1114   top_y:  415   width:   29   height:   30)\n",
      "person: 81%\t(left_x: 1151   top_y:  447   width:   43   height:   55)\n",
      "person: 37%\t(left_x: 1179   top_y:  506   width:   48   height:   69)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02255_MVR.png: Predicted in 145.095000 milli-seconds.\n",
      "car: 88%\t(left_x:   13   top_y:  333   width:  175   height:  290)\n",
      "person: 31%\t(left_x:   97   top_y:  158   width:   25   height:   31)\n",
      "bicycle: 67%\t(left_x:  111   top_y:  281   width:   58   height:   66)\n",
      "bicycle: 32%\t(left_x:  155   top_y:  252   width:   51   height:   48)\n",
      "bicycle: 36%\t(left_x:  171   top_y:  213   width:   58   height:   75)\n",
      "car: 94%\t(left_x:  221   top_y:    4   width:  630   height:  329)\n",
      "bicycle: 50%\t(left_x:  228   top_y:  145   width:   41   height:   62)\n",
      "pottedplant: 65%\t(left_x:  249   top_y:   66   width:   84   height:   87)\n",
      "car: 89%\t(left_x:  842   top_y:   44   width:  197   height:  136)\n",
      "car: 73%\t(left_x: 1102   top_y:  286   width:   62   height:   52)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03010_MVL.png: Predicted in 144.844000 milli-seconds.\n",
      "car: 37%\t(left_x:    1   top_y:   -7   width: 1280   height:  974)\n",
      "car: 29%\t(left_x:  119   top_y:  278   width:   60   height:   54)\n",
      "car: 28%\t(left_x:  195   top_y:  174   width:   35   height:   35)\n",
      "car: 84%\t(left_x:  208   top_y:  111   width:  107   height:   96)\n",
      "car: 45%\t(left_x:  414   top_y:   34   width:   33   height:   18)\n",
      "car: 28%\t(left_x:  421   top_y:   33   width:   34   height:   16)\n",
      "car: 30%\t(left_x:  430   top_y:   31   width:   32   height:   15)\n",
      "car: 43%\t(left_x:  441   top_y:   31   width:   23   height:   13)\n",
      "car: 31%\t(left_x:  513   top_y:   11   width:   55   height:   19)\n",
      "car: 62%\t(left_x:  932   top_y:  110   width:   82   height:   60)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/08032_RV.png: Predicted in 144.653000 milli-seconds.\n",
      "car: 54%\t(left_x:   36   top_y:  450   width:   65   height:   72)\n",
      "car: 36%\t(left_x:   70   top_y:  416   width:   45   height:   53)\n",
      "person: 77%\t(left_x:   72   top_y:  357   width:   99   height:  143)\n",
      "person: 90%\t(left_x:  108   top_y:  315   width:   89   height:  130)\n",
      "skateboard: 53%\t(left_x:  127   top_y:  438   width:   53   height:   40)\n",
      "car: 89%\t(left_x:  155   top_y:  319   width:   76   height:   66)\n",
      "car: 83%\t(left_x:  208   top_y:  289   width:   53   height:   32)\n",
      "car: 79%\t(left_x:  246   top_y:  277   width:   43   height:   24)\n",
      "car: 91%\t(left_x:  285   top_y:  216   width:  142   height:   82)\n",
      "car: 38%\t(left_x:  379   top_y:  214   width:   53   height:   31)\n",
      "car: 73%\t(left_x:  383   top_y:  210   width:   77   height:   34)\n",
      "car: 85%\t(left_x:  426   top_y:  196   width:   74   height:   25)\n",
      "car: 72%\t(left_x:  476   top_y:  189   width:   54   height:   21)\n",
      "car: 79%\t(left_x:  537   top_y:  186   width:   33   height:   15)\n",
      "car: 59%\t(left_x:  620   top_y:  179   width:   34   height:   16)\n",
      "truck: 78%\t(left_x:  651   top_y:  168   width:   67   height:   38)\n",
      "car: 93%\t(left_x:  681   top_y:  176   width:  148   height:   62)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00241_MVR.png: Predicted in 144.869000 milli-seconds.\n",
      "car: 44%\t(left_x:   39   top_y:  495   width:   22   height:   61)\n",
      "car: 47%\t(left_x:   48   top_y:  492   width:   38   height:   78)\n",
      "car: 42%\t(left_x:   56   top_y:  385   width:   80   height:  112)\n",
      "person: 48%\t(left_x:   95   top_y:  314   width:   47   height:   38)\n",
      "car: 70%\t(left_x:  195   top_y:   47   width:  166   height:  167)\n",
      "truck: 27%\t(left_x:  196   top_y:   47   width:  166   height:  166)\n",
      "bicycle: 58%\t(left_x:  624   top_y:    3   width:   71   height:   29)\n",
      "bicycle: 32%\t(left_x:  665   top_y:    3   width:   35   height:   30)\n",
      "bicycle: 28%\t(left_x:  675   top_y:    3   width:   39   height:   30)\n",
      "bicycle: 36%\t(left_x:  698   top_y:    3   width:   27   height:   30)\n",
      "bicycle: 41%\t(left_x:  723   top_y:    3   width:   37   height:   32)\n",
      "bicycle: 29%\t(left_x:  761   top_y:    6   width:   23   height:   31)\n",
      "bicycle: 31%\t(left_x:  782   top_y:    5   width:   17   height:   31)\n",
      "car: 70%\t(left_x:  871   top_y:   36   width:   42   height:   30)\n",
      "bench: 41%\t(left_x: 1013   top_y:  145   width:   30   height:   29)\n",
      "car: 53%\t(left_x: 1101   top_y:  285   width:   64   height:   53)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06789_MVR.png: Predicted in 145.591000 milli-seconds.\n",
      "car: 79%\t(left_x:  137   top_y:  188   width:   69   height:  111)\n",
      "car: 52%\t(left_x:  165   top_y:   17   width: 1097   height:  930)\n",
      "car: 85%\t(left_x:  178   top_y:    4   width:  269   height:  264)\n",
      "car: 30%\t(left_x:  181   top_y:  151   width:   85   height:  109)\n",
      "car: 29%\t(left_x:  239   top_y:   89   width:   48   height:   64)\n",
      "car: 93%\t(left_x:  432   top_y:    3   width:  278   height:  114)\n",
      "car: 94%\t(left_x:  775   top_y:    3   width:  225   height:  172)\n",
      "car: 68%\t(left_x: 1058   top_y:  167   width:   91   height:   88)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05635_FV.png: Predicted in 145.549000 milli-seconds.\n",
      "bicycle: 84%\t(left_x:   41   top_y:  397   width:   90   height:  162)\n",
      "pottedplant: 61%\t(left_x:  124   top_y:  156   width:   51   height:   40)\n",
      "bicycle: 80%\t(left_x:  127   top_y:  349   width:   85   height:  163)\n",
      "pottedplant: 53%\t(left_x:  173   top_y:  155   width:   46   height:   44)\n",
      "bicycle: 73%\t(left_x:  206   top_y:  368   width:   62   height:  114)\n",
      "bicycle: 67%\t(left_x:  239   top_y:  348   width:   72   height:  111)\n",
      "pottedplant: 60%\t(left_x:  268   top_y:  182   width:   46   height:   35)\n",
      "bicycle: 73%\t(left_x:  274   top_y:  337   width:   81   height:  103)\n",
      "pottedplant: 38%\t(left_x:  315   top_y:  196   width:   46   height:   32)\n",
      "motorbike: 84%\t(left_x:  369   top_y:  307   width:   63   height:  110)\n",
      "truck: 82%\t(left_x:  547   top_y:  316   width:   52   height:   46)\n",
      "car: 44%\t(left_x:  594   top_y:  331   width:   21   height:   22)\n",
      "car: 35%\t(left_x:  634   top_y:  336   width:   11   height:   11)\n",
      "car: 35%\t(left_x:  650   top_y:  337   width:   11   height:   13)\n",
      "car: 35%\t(left_x:  654   top_y:  336   width:   14   height:   15)\n",
      "car: 51%\t(left_x:  658   top_y:  336   width:   15   height:   16)\n",
      "truck: 67%\t(left_x:  670   top_y:  330   width:   31   height:   29)\n",
      "traffic light: 40%\t(left_x:  702   top_y:  293   width:    8   height:   17)\n",
      "person: 73%\t(left_x:  911   top_y:  319   width:   49   height:  107)\n",
      "handbag: 62%\t(left_x:  949   top_y:  338   width:   19   height:   47)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02879_RV.png: Predicted in 144.448000 milli-seconds.\n",
      "car: 90%\t(left_x:    9   top_y:  351   width:  236   height:  232)\n",
      "fire hydrant: 55%\t(left_x:  216   top_y:  353   width:   28   height:   47)\n",
      "car: 88%\t(left_x:  254   top_y:  231   width:  219   height:  157)\n",
      "bicycle: 84%\t(left_x:  452   top_y:  268   width:   53   height:   73)\n",
      "person: 83%\t(left_x:  460   top_y:  217   width:   42   height:  100)\n",
      "car: 85%\t(left_x:  494   top_y:  244   width:   54   height:   54)\n",
      "car: 86%\t(left_x:  543   top_y:  254   width:   34   height:   30)\n",
      "car: 74%\t(left_x:  571   top_y:  258   width:   20   height:   18)\n",
      "car: 38%\t(left_x:  580   top_y:  257   width:   21   height:   17)\n",
      "car: 55%\t(left_x:  587   top_y:  257   width:   16   height:   15)\n",
      "car: 44%\t(left_x:  602   top_y:  258   width:   17   height:   11)\n",
      "car: 30%\t(left_x:  613   top_y:  257   width:   16   height:    9)\n",
      "car: 30%\t(left_x:  617   top_y:  257   width:   16   height:    8)\n",
      "person: 35%\t(left_x:  733   top_y:  257   width:   11   height:   26)\n",
      "person: 56%\t(left_x:  925   top_y:  291   width:   25   height:   39)\n",
      "bicycle: 52%\t(left_x:  930   top_y:  311   width:   29   height:   33)\n",
      "person: 36%\t(left_x:  931   top_y:  292   width:   24   height:   48)\n",
      "person: 29%\t(left_x:  938   top_y:  304   width:   21   height:   38)\n",
      "person: 33%\t(left_x: 1100   top_y:  374   width:   27   height:   33)\n",
      "person: 27%\t(left_x: 1117   top_y:  388   width:   20   height:   29)\n",
      "person: 40%\t(left_x: 1201   top_y:  445   width:   40   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03454_RV.png: Predicted in 150.286000 milli-seconds.\n",
      "car: 32%\t(left_x:    0   top_y:  210   width: 1280   height:  749)\n",
      "car: 84%\t(left_x:   11   top_y:  441   width:   67   height:   85)\n",
      "car: 67%\t(left_x:  117   top_y:  333   width:  106   height:   95)\n",
      "car: 93%\t(left_x:  196   top_y:  277   width:  190   height:  136)\n",
      "person: 28%\t(left_x:  245   top_y:  277   width:   14   height:   23)\n",
      "person: 27%\t(left_x:  271   top_y:  272   width:   14   height:   22)\n",
      "person: 57%\t(left_x:  283   top_y:  263   width:   19   height:   27)\n",
      "car: 85%\t(left_x:  362   top_y:  279   width:   51   height:   29)\n",
      "car: 53%\t(left_x:  395   top_y:  267   width:   29   height:   31)\n",
      "car: 64%\t(left_x:  444   top_y:  268   width:   24   height:   21)\n",
      "car: 54%\t(left_x:  465   top_y:  245   width:   73   height:   49)\n",
      "truck: 42%\t(left_x:  466   top_y:  245   width:   73   height:   50)\n",
      "car: 39%\t(left_x:  542   top_y:  257   width:   33   height:   19)\n",
      "car: 48%\t(left_x:  553   top_y:  255   width:   26   height:   19)\n",
      "car: 33%\t(left_x:  581   top_y:  258   width:   14   height:   13)\n",
      "car: 27%\t(left_x:  584   top_y:  259   width:   22   height:   10)\n",
      "car: 37%\t(left_x:  597   top_y:  259   width:   12   height:    9)\n",
      "car: 66%\t(left_x:  627   top_y:  259   width:   19   height:   12)\n",
      "car: 54%\t(left_x:  658   top_y:  259   width:   19   height:   12)\n",
      "car: 68%\t(left_x:  691   top_y:  256   width:   58   height:   39)\n",
      "truck: 75%\t(left_x:  740   top_y:  252   width:   54   height:   41)\n",
      "car: 89%\t(left_x:  766   top_y:  268   width:   81   height:   47)\n",
      "person: 75%\t(left_x:  866   top_y:  279   width:   13   height:   33)\n",
      "person: 81%\t(left_x:  965   top_y:  306   width:   27   height:   50)\n",
      "bicycle: 47%\t(left_x:  968   top_y:  332   width:   22   height:   29)\n",
      "bicycle: 38%\t(left_x:  995   top_y:  340   width:   43   height:   39)\n",
      "bicycle: 32%\t(left_x: 1009   top_y:  340   width:   36   height:   43)\n",
      "bicycle: 70%\t(left_x: 1022   top_y:  351   width:   57   height:   53)\n",
      "person: 47%\t(left_x: 1069   top_y:  373   width:   43   height:   47)\n",
      "traffic light: 28%\t(left_x: 1095   top_y:  262   width:   19   height:   29)\n",
      "person: 40%\t(left_x: 1098   top_y:  391   width:   41   height:   44)\n",
      "person: 56%\t(left_x: 1143   top_y:  420   width:   29   height:   46)\n",
      "person: 68%\t(left_x: 1173   top_y:  431   width:   51   height:   62)\n",
      "person: 48%\t(left_x: 1186   top_y:  449   width:   44   height:   55)\n",
      "person: 51%\t(left_x: 1202   top_y:  467   width:   50   height:   62)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00418_MVL.png: Predicted in 145.521000 milli-seconds.\n",
      "car: 28%\t(left_x:   11   top_y:   30   width: 1145   height:  922)\n",
      "car: 36%\t(left_x:  122   top_y:  277   width:   56   height:   54)\n",
      "person: 42%\t(left_x:  128   top_y:  274   width:   33   height:   48)\n",
      "car: 44%\t(left_x:  434   top_y:   21   width:   57   height:   28)\n",
      "truck: 26%\t(left_x:  435   top_y:   20   width:   56   height:   29)\n",
      "person: 27%\t(left_x:  595   top_y:    4   width:   15   height:   23)\n",
      "person: 37%\t(left_x:  682   top_y:    4   width:   15   height:   26)\n",
      "car: 71%\t(left_x:  777   top_y:   40   width:   71   height:   36)\n",
      "car: 94%\t(left_x:  825   top_y:   39   width:  269   height:  280)\n",
      "person: 25%\t(left_x: 1189   top_y:  442   width:   25   height:   45)\n",
      "traffic light: 35%\t(left_x: 1244   top_y:  605   width:   11   height:   10)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07564_MVR.png: Predicted in 144.075000 milli-seconds.\n",
      "person: 87%\t(left_x:   -0   top_y:  433   width:  203   height:  117)\n",
      "person: 31%\t(left_x:   26   top_y:  378   width:   49   height:   53)\n",
      "car: 28%\t(left_x:   33   top_y:  420   width:  113   height:   46)\n",
      "car: 29%\t(left_x:  162   top_y:  262   width:  996   height:  651)\n",
      "skateboard: 45%\t(left_x:  182   top_y:  480   width:   22   height:   45)\n",
      "person: 94%\t(left_x:  298   top_y:   29   width:   93   height:  148)\n",
      "skateboard: 31%\t(left_x:  405   top_y:  141   width:   19   height:   22)\n",
      "car: 54%\t(left_x:  576   top_y:    3   width:   96   height:   75)\n",
      "car: 93%\t(left_x:  639   top_y:    4   width:  458   height:  263)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07970_MVL.png: Predicted in 145.611000 milli-seconds.\n",
      "car: 53%\t(left_x:    5   top_y:   -4   width: 1272   height:  956)\n",
      "car: 92%\t(left_x:  208   top_y:   59   width:  135   height:  104)\n",
      "car: 65%\t(left_x:  294   top_y:   31   width:   70   height:   45)\n",
      "car: 31%\t(left_x:  321   top_y:   29   width:   43   height:   43)\n",
      "car: 51%\t(left_x:  354   top_y:   32   width:   28   height:   25)\n",
      "car: 58%\t(left_x:  364   top_y:   25   width:   29   height:   22)\n",
      "car: 36%\t(left_x:  384   top_y:   21   width:   19   height:   17)\n",
      "person: 67%\t(left_x:  424   top_y:    3   width:   48   height:   62)\n",
      "person: 88%\t(left_x:  474   top_y:    3   width:   64   height:  111)\n",
      "car: 76%\t(left_x:  550   top_y:    2   width:  100   height:   22)\n",
      "car: 47%\t(left_x:  640   top_y:    3   width:   76   height:   44)\n",
      "car: 87%\t(left_x:  682   top_y:    3   width:  248   height:   81)\n",
      "car: 95%\t(left_x:  743   top_y:   31   width:  348   height:  235)\n",
      "car: 37%\t(left_x: 1096   top_y:  232   width:   26   height:   33)\n",
      "car: 82%\t(left_x: 1099   top_y:  290   width:   97   height:  128)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02439_MVL.png: Predicted in 146.221000 milli-seconds.\n",
      "person: 34%\t(left_x:  122   top_y:  277   width:   58   height:   54)\n",
      "person: 29%\t(left_x:  219   top_y:  309   width:   10   height:   27)\n",
      "car: 88%\t(left_x:  546   top_y:    7   width:  684   height:  543)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00750_RV.png: Predicted in 145.571000 milli-seconds.\n",
      "suitcase: 57%\t(left_x:  281   top_y:  343   width:   39   height:   43)\n",
      "person: 69%\t(left_x:  306   top_y:  248   width:   61   height:  107)\n",
      "suitcase: 69%\t(left_x:  321   top_y:  331   width:   32   height:   41)\n",
      "backpack: 62%\t(left_x:  344   top_y:  248   width:   29   height:   46)\n",
      "person: 82%\t(left_x:  348   top_y:  230   width:   58   height:  122)\n",
      "person: 31%\t(left_x:  377   top_y:  230   width:   52   height:  111)\n",
      "person: 69%\t(left_x:  404   top_y:  233   width:   24   height:   91)\n",
      "person: 45%\t(left_x:  416   top_y:  238   width:   36   height:   88)\n",
      "person: 65%\t(left_x:  428   top_y:  240   width:   32   height:   83)\n",
      "person: 90%\t(left_x:  520   top_y:  191   width:   53   height:  146)\n",
      "bicycle: 78%\t(left_x:  521   top_y:  250   width:   46   height:  113)\n",
      "person: 65%\t(left_x:  573   top_y:  252   width:   13   height:   29)\n",
      "person: 32%\t(left_x:  606   top_y:  256   width:    9   height:   22)\n",
      "person: 42%\t(left_x:  627   top_y:  262   width:   10   height:   19)\n",
      "car: 71%\t(left_x:  647   top_y:  263   width:   21   height:   12)\n",
      "car: 34%\t(left_x:  751   top_y:  271   width:   29   height:   18)\n",
      "car: 54%\t(left_x:  786   top_y:  259   width:   65   height:   43)\n",
      "bus: 35%\t(left_x:  947   top_y:  279   width:  269   height:  150)\n",
      "car: 87%\t(left_x: 1034   top_y:  370   width:  108   height:   76)\n",
      "bicycle: 27%\t(left_x: 1122   top_y:  434   width:   63   height:   41)\n",
      "person: 31%\t(left_x: 1124   top_y:  434   width:   68   height:   44)\n",
      "car: 78%\t(left_x: 1137   top_y:  486   width:   93   height:   96)\n",
      "bicycle: 35%\t(left_x: 1141   top_y:  458   width:   47   height:   42)\n",
      "person: 32%\t(left_x: 1154   top_y:  435   width:   41   height:   41)\n",
      "car: 55%\t(left_x: 1186   top_y:  462   width:   90   height:   86)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02963_FV.png: Predicted in 144.979000 milli-seconds.\n",
      "person: 31%\t(left_x:   41   top_y:  436   width:   31   height:   56)\n",
      "person: 40%\t(left_x:   66   top_y:  410   width:   21   height:   56)\n",
      "person: 33%\t(left_x:   69   top_y:  436   width:   17   height:   37)\n",
      "person: 76%\t(left_x:   82   top_y:  413   width:   21   height:   47)\n",
      "car: 31%\t(left_x:  163   top_y:  395   width:   55   height:   39)\n",
      "car: 95%\t(left_x:  213   top_y:  305   width:  297   height:  146)\n",
      "truck: 38%\t(left_x:  572   top_y:  327   width:   38   height:   32)\n",
      "car: 52%\t(left_x:  572   top_y:  328   width:   38   height:   32)\n",
      "car: 37%\t(left_x:  610   top_y:  344   width:    9   height:   10)\n",
      "car: 35%\t(left_x:  612   top_y:  342   width:   19   height:   11)\n",
      "car: 36%\t(left_x:  617   top_y:  341   width:   15   height:   11)\n",
      "car: 48%\t(left_x:  637   top_y:  336   width:   20   height:   18)\n",
      "truck: 40%\t(left_x:  637   top_y:  336   width:   20   height:   18)\n",
      "bus: 75%\t(left_x:  680   top_y:  318   width:   40   height:   39)\n",
      "bicycle: 52%\t(left_x:  815   top_y:  349   width:   25   height:   28)\n",
      "bicycle: 36%\t(left_x:  817   top_y:  350   width:   51   height:   32)\n",
      "bicycle: 58%\t(left_x:  829   top_y:  351   width:   52   height:   35)\n",
      "bicycle: 66%\t(left_x:  908   top_y:  339   width:   56   height:   67)\n",
      "bicycle: 59%\t(left_x:  941   top_y:  354   width:   47   height:   63)\n",
      "bicycle: 51%\t(left_x:  968   top_y:  353   width:   42   height:   69)\n",
      "bicycle: 73%\t(left_x: 1001   top_y:  349   width:   52   height:   95)\n",
      "bicycle: 29%\t(left_x: 1032   top_y:  384   width:   42   height:   60)\n",
      "skateboard: 27%\t(left_x: 1037   top_y:  456   width:   45   height:   19)\n",
      "bicycle: 54%\t(left_x: 1062   top_y:  360   width:   49   height:  107)\n",
      "skateboard: 39%\t(left_x: 1160   top_y:  462   width:   22   height:   10)\n",
      "person: 81%\t(left_x: 1162   top_y:  389   width:   30   height:   81)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02737_MVL.png: Predicted in 145.454000 milli-seconds.\n",
      "car: 27%\t(left_x:    1   top_y:  -25   width: 1282   height: 1005)\n",
      "car: 33%\t(left_x:  117   top_y:  278   width:   64   height:   53)\n",
      "truck: 84%\t(left_x:  387   top_y:    4   width:  173   height:   77)\n",
      "car: 90%\t(left_x:  584   top_y:    3   width:  106   height:   36)\n",
      "person: 37%\t(left_x:  781   top_y:   28   width:   30   height:   39)\n",
      "skateboard: 32%\t(left_x: 1116   top_y:  482   width:   36   height:   23)\n",
      "person: 80%\t(left_x: 1119   top_y:  420   width:  154   height:   96)\n",
      "person: 53%\t(left_x: 1188   top_y:  394   width:   63   height:   42)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/02317_RV.png: Predicted in 145.640000 milli-seconds.\n",
      "person: 26%\t(left_x:  356   top_y:  222   width:  156   height:  156)\n",
      "car: 83%\t(left_x:  361   top_y:  221   width:  147   height:  167)\n",
      "person: 74%\t(left_x:  404   top_y:  247   width:   35   height:   51)\n",
      "person: 75%\t(left_x:  524   top_y:  237   width:   28   height:   55)\n",
      "bicycle: 77%\t(left_x:  527   top_y:  260   width:   24   height:   47)\n",
      "car: 92%\t(left_x:  582   top_y:  235   width:   91   height:   72)\n",
      "bus: 68%\t(left_x:  659   top_y:   34   width:  620   height:  764)\n",
      "person: 74%\t(left_x: 1054   top_y:  206   width:   90   height:  120)\n",
      "person: 36%\t(left_x: 1150   top_y:  264   width:   71   height:  110)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00441_MVR.png: Predicted in 145.475000 milli-seconds.\n",
      "bicycle: 32%\t(left_x:   46   top_y:  422   width:   63   height:   38)\n",
      "bicycle: 57%\t(left_x:   52   top_y:  453   width:   45   height:   44)\n",
      "person: 32%\t(left_x:  127   top_y:  269   width:   21   height:   28)\n",
      "bench: 57%\t(left_x:  686   top_y:   12   width:   64   height:   31)\n",
      "bicycle: 80%\t(left_x:  791   top_y:   11   width:   84   height:   94)\n",
      "person: 31%\t(left_x:  967   top_y:   87   width:   23   height:   33)\n",
      "person: 28%\t(left_x:  976   top_y:   90   width:   25   height:   32)\n",
      "bicycle: 45%\t(left_x:  984   top_y:  142   width:   36   height:   40)\n",
      "person: 30%\t(left_x:  984   top_y:  140   width:   36   height:   42)\n",
      "person: 25%\t(left_x:  989   top_y:  111   width:   40   height:   34)\n",
      "person: 34%\t(left_x: 1057   top_y:  155   width:   29   height:   32)\n",
      "traffic light: 53%\t(left_x: 1068   top_y:   57   width:   49   height:   49)\n",
      "car: 61%\t(left_x: 1110   top_y:  286   width:   51   height:   51)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03651_FV.png: Predicted in 145.279000 milli-seconds.\n",
      "bicycle: 55%\t(left_x:   34   top_y:  402   width:   67   height:  103)\n",
      "bicycle: 64%\t(left_x:  159   top_y:  382   width:   38   height:   77)\n",
      "bicycle: 71%\t(left_x:  202   top_y:  385   width:   35   height:   54)\n",
      "bicycle: 33%\t(left_x:  223   top_y:  373   width:   31   height:   58)\n",
      "bicycle: 48%\t(left_x:  232   top_y:  371   width:   36   height:   57)\n",
      "bicycle: 39%\t(left_x:  241   top_y:  369   width:   38   height:   56)\n",
      "bicycle: 50%\t(left_x:  261   top_y:  368   width:   45   height:   53)\n",
      "bicycle: 85%\t(left_x:  290   top_y:  360   width:   87   height:   83)\n",
      "bicycle: 35%\t(left_x:  316   top_y:  331   width:   45   height:   98)\n",
      "person: 80%\t(left_x:  321   top_y:  330   width:   40   height:   92)\n",
      "car: 76%\t(left_x:  566   top_y:  341   width:   24   height:   17)\n",
      "car: 68%\t(left_x:  589   top_y:  344   width:   16   height:   11)\n",
      "car: 46%\t(left_x:  667   top_y:  339   width:   19   height:   15)\n",
      "car: 54%\t(left_x:  683   top_y:  335   width:   25   height:   22)\n",
      "motorbike: 34%\t(left_x:  709   top_y:  342   width:   17   height:   30)\n",
      "bicycle: 33%\t(left_x:  709   top_y:  343   width:   17   height:   29)\n",
      "person: 65%\t(left_x:  710   top_y:  319   width:   15   height:   41)\n",
      "car: 36%\t(left_x:  731   top_y:  342   width:   26   height:   16)\n",
      "bicycle: 37%\t(left_x:  784   top_y:  346   width:   17   height:   21)\n",
      "person: 64%\t(left_x:  799   top_y:  331   width:   14   height:   34)\n",
      "car: 95%\t(left_x:  805   top_y:  312   width:  218   height:  136)\n",
      "bicycle: 70%\t(left_x: 1019   top_y:  358   width:   48   height:   75)\n",
      "bicycle: 73%\t(left_x: 1075   top_y:  359   width:   38   height:   91)\n",
      "bicycle: 28%\t(left_x: 1149   top_y:  384   width:   31   height:   95)\n",
      "bicycle: 65%\t(left_x: 1158   top_y:  381   width:   55   height:  106)\n",
      "car: 84%\t(left_x: 1163   top_y:  455   width:  117   height:  167)\n",
      "bicycle: 66%\t(left_x: 1196   top_y:  406   width:   69   height:   56)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/01074_MVR.png: Predicted in 144.461000 milli-seconds.\n",
      "person: 28%\t(left_x:   26   top_y:  393   width:   63   height:   42)\n",
      "person: 29%\t(left_x:   47   top_y:  393   width:   49   height:   38)\n",
      "person: 51%\t(left_x:   56   top_y:  372   width:   54   height:   42)\n",
      "person: 48%\t(left_x:   91   top_y:  303   width:   41   height:   41)\n",
      "person: 64%\t(left_x:   99   top_y:  274   width:   64   height:   60)\n",
      "person: 72%\t(left_x:  116   top_y:  248   width:   64   height:   55)\n",
      "person: 40%\t(left_x:  149   top_y:  194   width:   53   height:   64)\n",
      "person: 33%\t(left_x:  382   top_y:   29   width:   17   height:   26)\n",
      "chair: 34%\t(left_x:  400   top_y:   12   width:   36   height:   55)\n",
      "chair: 53%\t(left_x:  413   top_y:   10   width:   50   height:   65)\n",
      "chair: 80%\t(left_x:  453   top_y:   10   width:   50   height:   62)\n",
      "diningtable: 27%\t(left_x:  486   top_y:   11   width:   35   height:   48)\n",
      "chair: 34%\t(left_x:  486   top_y:   10   width:   34   height:   49)\n",
      "chair: 70%\t(left_x:  512   top_y:    8   width:   43   height:   48)\n",
      "chair: 29%\t(left_x:  542   top_y:    2   width:   24   height:   45)\n",
      "chair: 31%\t(left_x:  559   top_y:    2   width:   22   height:   32)\n",
      "chair: 55%\t(left_x:  577   top_y:    3   width:   27   height:   40)\n",
      "chair: 50%\t(left_x:  601   top_y:    3   width:   35   height:   44)\n",
      "chair: 68%\t(left_x:  646   top_y:    2   width:   33   height:   38)\n",
      "chair: 60%\t(left_x:  693   top_y:    2   width:   38   height:   39)\n",
      "chair: 57%\t(left_x:  733   top_y:    3   width:   45   height:   43)\n",
      "chair: 39%\t(left_x:  766   top_y:    4   width:   34   height:   41)\n",
      "chair: 69%\t(left_x:  792   top_y:    6   width:   36   height:   45)\n",
      "chair: 40%\t(left_x:  816   top_y:   10   width:   36   height:   45)\n",
      "chair: 40%\t(left_x:  829   top_y:   18   width:   66   height:   71)\n",
      "bicycle: 79%\t(left_x:  870   top_y:   46   width:   71   height:   84)\n",
      "person: 31%\t(left_x:  871   top_y:   45   width:   69   height:   85)\n",
      "person: 70%\t(left_x:  883   top_y:    4   width:   44   height:   96)\n",
      "person: 55%\t(left_x:  939   top_y:   39   width:   30   height:   67)\n",
      "person: 32%\t(left_x:  949   top_y:   74   width:   39   height:   40)\n",
      "person: 46%\t(left_x:  964   top_y:   86   width:   35   height:   39)\n",
      "car: 78%\t(left_x: 1110   top_y:  286   width:   53   height:   50)\n",
      "car: 47%\t(left_x: 1133   top_y:  243   width:   30   height:   25)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06308_MVR.png: Predicted in 144.475000 milli-seconds.\n",
      "car: 74%\t(left_x:   10   top_y:  386   width:  117   height:  180)\n",
      "car: 82%\t(left_x:   33   top_y:  610   width:   84   height:  192)\n",
      "car: 37%\t(left_x:   85   top_y:  334   width:   40   height:   55)\n",
      "car: 49%\t(left_x:  116   top_y:  270   width:   45   height:   48)\n",
      "car: 92%\t(left_x:  151   top_y:  137   width:  137   height:  131)\n",
      "car: 89%\t(left_x:  266   top_y:   49   width:  165   height:  115)\n",
      "car: 91%\t(left_x:  424   top_y:    3   width:  117   height:   68)\n",
      "car: 85%\t(left_x:  532   top_y:    2   width:   95   height:   33)\n",
      "car: 77%\t(left_x:  638   top_y:    2   width:  146   height:   41)\n",
      "person: 39%\t(left_x:  663   top_y:    2   width:   88   height:   38)\n",
      "person: 71%\t(left_x:  694   top_y:    3   width:   20   height:   35)\n",
      "car: 67%\t(left_x:  782   top_y:    3   width:   45   height:   27)\n",
      "car: 27%\t(left_x:  813   top_y:   14   width:   21   height:   15)\n",
      "person: 40%\t(left_x:  844   top_y:   22   width:   10   height:   23)\n",
      "person: 42%\t(left_x:  844   top_y:   20   width:   18   height:   25)\n",
      "person: 32%\t(left_x:  852   top_y:   21   width:   11   height:   27)\n",
      "car: 40%\t(left_x:  857   top_y:   27   width:   25   height:   22)\n",
      "car: 34%\t(left_x:  882   top_y:   34   width:   18   height:   16)\n",
      "car: 39%\t(left_x:  884   top_y:   36   width:   25   height:   18)\n",
      "car: 43%\t(left_x:  892   top_y:   40   width:   20   height:   18)\n",
      "car: 40%\t(left_x:  894   top_y:   43   width:   24   height:   17)\n",
      "car: 39%\t(left_x:  901   top_y:   51   width:   32   height:   19)\n",
      "car: 55%\t(left_x:  901   top_y:   51   width:   22   height:   13)\n",
      "car: 56%\t(left_x:  917   top_y:   55   width:   23   height:   20)\n",
      "car: 38%\t(left_x:  954   top_y:   73   width:   49   height:   32)\n",
      "car: 86%\t(left_x: 1049   top_y:  168   width:   84   height:   76)\n",
      "car: 52%\t(left_x: 1098   top_y:  267   width:   61   height:   50)\n",
      "car: 34%\t(left_x: 1123   top_y:  221   width:   27   height:   23)\n",
      "car: 65%\t(left_x: 1124   top_y:  241   width:   37   height:   32)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/06474_FV.png: Predicted in 146.107000 milli-seconds.\n",
      "car: 87%\t(left_x:    0   top_y:  413   width:  177   height:  208)\n",
      "car: 53%\t(left_x:  118   top_y:  399   width:   24   height:   17)\n",
      "person: 92%\t(left_x:  189   top_y:  164   width:  123   height:  319)\n",
      "person: 34%\t(left_x:  763   top_y:  306   width:    9   height:   24)\n",
      "person: 28%\t(left_x:  764   top_y:  307   width:   17   height:   23)\n",
      "person: 35%\t(left_x:  772   top_y:  307   width:   10   height:   24)\n",
      "car: 84%\t(left_x:  922   top_y:  389   width:  278   height:  304)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00744_MVR.png: Predicted in 145.313000 milli-seconds.\n",
      "car: 30%\t(left_x:   28   top_y:   17   width: 1252   height:  936)\n",
      "person: 33%\t(left_x:   51   top_y:  701   width:   61   height:   20)\n",
      "car: 93%\t(left_x:   86   top_y:    7   width:  824   height:  494)\n",
      "person: 78%\t(left_x:  907   top_y:   21   width:   42   height:   80)\n",
      "person: 63%\t(left_x:  916   top_y:   58   width:   39   height:   58)\n",
      "person: 46%\t(left_x:  938   top_y:   78   width:   34   height:   45)\n",
      "person: 44%\t(left_x: 1026   top_y:  118   width:   24   height:   29)\n",
      "person: 33%\t(left_x: 1057   top_y:  154   width:   24   height:   25)\n",
      "person: 75%\t(left_x: 1065   top_y:  195   width:   60   height:   60)\n",
      "person: 28%\t(left_x: 1073   top_y:  164   width:   21   height:   25)\n",
      "car: 49%\t(left_x: 1109   top_y:  287   width:   51   height:   50)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/05724_MVL.png: Predicted in 144.967000 milli-seconds.\n",
      "car: 55%\t(left_x:   13   top_y:  256   width: 1101   height:  693)\n",
      "car: 29%\t(left_x:   77   top_y:  231   width:   16   height:   29)\n",
      "car: 85%\t(left_x:  119   top_y:  277   width:   61   height:   54)\n",
      "car: 52%\t(left_x:  150   top_y:  221   width:   38   height:   41)\n",
      "car: 43%\t(left_x:  168   top_y:   81   width:   41   height:   49)\n",
      "car: 42%\t(left_x:  188   top_y:  153   width:   36   height:   47)\n",
      "car: 42%\t(left_x:  214   top_y:  138   width:   49   height:   44)\n",
      "car: 81%\t(left_x:  242   top_y:   76   width:  101   height:   95)\n",
      "motorbike: 73%\t(left_x:  655   top_y:    4   width:   81   height:   59)\n",
      "motorbike: 44%\t(left_x:  699   top_y:    3   width:   60   height:   57)\n",
      "car: 82%\t(left_x:  759   top_y:   28   width:   96   height:   66)\n",
      "car: 58%\t(left_x:  851   top_y:   50   width:   25   height:   29)\n",
      "truck: 29%\t(left_x:  875   top_y:   50   width:   65   height:   54)\n",
      "car: 48%\t(left_x:  875   top_y:   50   width:   64   height:   55)\n",
      "bicycle: 51%\t(left_x:  878   top_y:   94   width:   60   height:   53)\n",
      "person: 76%\t(left_x:  950   top_y:  115   width:   60   height:   62)\n",
      "person: 63%\t(left_x:  975   top_y:  124   width:   44   height:   60)\n",
      "person: 79%\t(left_x:  991   top_y:  136   width:   62   height:   69)\n",
      "person: 88%\t(left_x: 1016   top_y:  189   width:   99   height:   90)\n",
      "person: 63%\t(left_x: 1071   top_y:  245   width:   50   height:   51)\n",
      "person: 87%\t(left_x: 1094   top_y:  312   width:   88   height:   67)\n",
      "person: 83%\t(left_x: 1115   top_y:  365   width:  116   height:   67)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/00616_RV.png: Predicted in 145.795000 milli-seconds.\n",
      "person: 76%\t(left_x:   45   top_y:  345   width:  126   height:  205)\n",
      "bicycle: 63%\t(left_x:  113   top_y:  395   width:  119   height:  151)\n",
      "person: 42%\t(left_x:  265   top_y:  303   width:   36   height:   50)\n",
      "person: 38%\t(left_x:  266   top_y:  303   width:   25   height:   32)\n",
      "person: 38%\t(left_x:  269   top_y:  301   width:   53   height:   62)\n",
      "person: 49%\t(left_x:  289   top_y:  291   width:   37   height:   71)\n",
      "person: 47%\t(left_x:  317   top_y:  286   width:   28   height:   69)\n",
      "person: 46%\t(left_x:  320   top_y:  287   width:   22   height:   24)\n",
      "bicycle: 56%\t(left_x:  346   top_y:  273   width:   34   height:   79)\n",
      "bicycle: 54%\t(left_x:  437   top_y:  281   width:   30   height:   45)\n",
      "person: 27%\t(left_x:  458   top_y:  265   width:   18   height:   35)\n",
      "traffic light: 80%\t(left_x:  461   top_y:  186   width:   25   height:   45)\n",
      "person: 29%\t(left_x:  497   top_y:  257   width:   17   height:   41)\n",
      "person: 29%\t(left_x:  527   top_y:  257   width:   14   height:   33)\n",
      "person: 47%\t(left_x:  545   top_y:  257   width:   11   height:   28)\n",
      "car: 29%\t(left_x:  599   top_y:  263   width:   13   height:   10)\n",
      "car: 33%\t(left_x:  616   top_y:  261   width:    9   height:   10)\n",
      "car: 75%\t(left_x:  622   top_y:  256   width:   40   height:   33)\n",
      "car: 62%\t(left_x:  661   top_y:  260   width:   18   height:   16)\n",
      "car: 73%\t(left_x:  678   top_y:  262   width:   23   height:   18)\n",
      "car: 71%\t(left_x:  706   top_y:  257   width:   56   height:   39)\n",
      "car: 33%\t(left_x:  898   top_y:  295   width:   39   height:   23)\n",
      "person: 30%\t(left_x:  945   top_y:  300   width:   19   height:   44)\n",
      "traffic light: 41%\t(left_x:  956   top_y:  241   width:   14   height:   22)\n",
      "person: 42%\t(left_x:  959   top_y:  301   width:   27   height:   49)\n",
      "person: 30%\t(left_x:  963   top_y:  311   width:   41   height:   41)\n",
      "traffic light: 68%\t(left_x:  968   top_y:  236   width:   20   height:   36)\n",
      "traffic light: 31%\t(left_x:  968   top_y:  197   width:   14   height:   30)\n",
      "person: 40%\t(left_x:  986   top_y:  316   width:   20   height:   38)\n",
      "car: 85%\t(left_x: 1040   top_y:  355   width:  238   height:  195)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/07955_MVL.png: Predicted in 144.600000 milli-seconds.\n",
      "car: 29%\t(left_x:   -9   top_y:   -3   width: 1269   height:  951)\n",
      "car: 27%\t(left_x:   99   top_y:  261   width:   73   height:   66)\n",
      "car: 86%\t(left_x:  187   top_y:  119   width:   63   height:   57)\n",
      "car: 90%\t(left_x:  234   top_y:    3   width:  859   height:  383)\n",
      "car: 88%\t(left_x: 1085   top_y:  208   width:   49   height:   80)\n",
      "car: 54%\t(left_x: 1152   top_y:  420   width:   93   height:  181)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03075_MVR.png: Predicted in 146.063000 milli-seconds.\n",
      "person: 42%\t(left_x:  124   top_y:  530   width:   27   height:   67)\n",
      "fire hydrant: 32%\t(left_x:  361   top_y:   58   width:   32   height:   67)\n",
      "fire hydrant: 54%\t(left_x:  514   top_y:  178   width:   84   height:   56)\n",
      "car: 54%\t(left_x:  942   top_y:   51   width:   51   height:   42)\n",
      "person: 41%\t(left_x: 1013   top_y:  108   width:   29   height:   35)\n",
      "bench: 26%\t(left_x: 1013   top_y:  112   width:   27   height:   31)\n",
      "car: 68%\t(left_x: 1111   top_y:  287   width:   49   height:   49)\n",
      "Enter Image Path:  Detection layer: 292 - type = 28 \n",
      " Detection layer: 296 - type = 28 \n",
      " Detection layer: 300 - type = 28 \n",
      " Detection layer: 304 - type = 28 \n",
      "/content/WoodScape/rgb_images/03928_FV.png: Predicted in 145.727000 milli-seconds.\n",
      "car: 86%\t(left_x:   11   top_y:  414   width:  123   height:  105)\n",
      "car: 26%\t(left_x:   24   top_y:  635   width: 1260   height:  224)\n",
      "car: 93%\t(left_x:  203   top_y:  358   width:  139   height:   87)\n",
      "bicycle: 37%\t(left_x:  334   top_y:  348   width:   26   height:   44)\n",
      "bicycle: 31%\t(left_x:  340   top_y:  355   width:   35   height:   36)\n",
      "bicycle: 35%\t(left_x:  360   top_y:  350   width:   32   height:   38)\n",
      "bicycle: 54%\t(left_x:  381   top_y:  347   width:   33   height:   38)\n",
      "bicycle: 35%\t(left_x:  399   top_y:  352   width:   30   height:   27)\n",
      "car: 77%\t(left_x:  481   top_y:  340   width:   45   height:   26)\n",
      "car: 75%\t(left_x:  523   top_y:  341   width:   25   height:   19)\n",
      "car: 56%\t(left_x:  537   top_y:  330   width:   34   height:   26)\n",
      "truck: 31%\t(left_x:  537   top_y:  331   width:   34   height:   26)\n",
      "car: 65%\t(left_x:  574   top_y:  340   width:   20   height:   12)\n",
      "car: 42%\t(left_x:  598   top_y:  341   width:   11   height:    9)\n",
      "car: 27%\t(left_x:  600   top_y:  341   width:   16   height:    8)\n",
      "car: 64%\t(left_x:  631   top_y:  332   width:   32   height:   27)\n",
      "car: 43%\t(left_x:  663   top_y:  338   width:   11   height:   14)\n",
      "car: 53%\t(left_x:  666   top_y:  338   width:   16   height:   15)\n",
      "car: 60%\t(left_x:  679   top_y:  338   width:   15   height:   19)\n",
      "car: 87%\t(left_x:  690   top_y:  336   width:   34   height:   27)\n",
      "bicycle: 51%\t(left_x:  736   top_y:  336   width:   35   height:   35)\n",
      "car: 28%\t(left_x:  762   top_y:  336   width:   49   height:   40)\n",
      "bicycle: 50%\t(left_x:  763   top_y:  337   width:   57   height:   45)\n",
      "bicycle: 59%\t(left_x:  783   top_y:  337   width:   48   height:   49)\n",
      "bicycle: 59%\t(left_x:  787   top_y:  345   width:   69   height:   46)\n",
      "bicycle: 41%\t(left_x:  834   top_y:  351   width:   28   height:   54)\n",
      "bicycle: 55%\t(left_x:  868   top_y:  334   width:   99   height:   94)\n",
      "bicycle: 31%\t(left_x:  869   top_y:  342   width:   57   height:   75)\n",
      "bicycle: 58%\t(left_x:  899   top_y:  331   width:   82   height:  115)\n",
      "bicycle: 75%\t(left_x:  975   top_y:  335   width:   96   height:  115)\n",
      "bicycle: 34%\t(left_x: 1026   top_y:  366   width:   73   height:  113)\n",
      "bicycle: 80%\t(left_x: 1037   top_y:  367   width:  115   height:  119)\n",
      "bicycle: 58%\t(left_x: 1092   top_y:  371   width:  128   height:  148)\n",
      "bicycle: 61%\t(left_x: 1155   top_y:  388   width:  100   height:  148)\n",
      "bicycle: 68%\t(left_x: 1167   top_y:  397   width:  112   height:  212)\n",
      "Enter Image Path: \n",
      "real\t37m50.451s\n",
      "user\t17m42.665s\n",
      "sys\t7m58.061s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CWPWB_yICGlL"
   },
   "source": [
    "download(\"result.json\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}